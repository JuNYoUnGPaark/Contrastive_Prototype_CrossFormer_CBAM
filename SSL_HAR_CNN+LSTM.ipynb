{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WNDGeHJt_igc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"ì‹¤í—˜ ì„¤ì •\"\"\"\n",
        "    mode: str = \"self_supervised_transition\"\n",
        "    data_dir: str = \"/content/drive/MyDrive/Colab Notebooks/UCI-HAR/data\"\n",
        "    save_dir: str = \"/content/drive/MyDrive/Colab Notebooks/UCI-HAR/ssl_transition\"\n",
        "\n",
        "    # í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "    epochs: int = 30\n",
        "    batch_size: int = 128\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    grad_clip: float = 1.0\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    # Augmentation íŒŒë¼ë¯¸í„°\n",
        "    train_augment_prob: float = 0.4  # ì „ì´ ìƒì„± í™•ë¥  ì¦ê°€\n",
        "    train_augment_mix: float = 0.35\n",
        "\n",
        "    # ëª¨ë¸ íŒŒë¼ë¯¸í„°\n",
        "    d_model: int = 128\n",
        "    use_hyperbolic: bool = False\n",
        "    hyperbolic_c: float = 1.0\n",
        "\n",
        "    # SSL íŒŒë¼ë¯¸í„°\n",
        "    ssl_weight: float = 0.3  # ì „ì´ íƒì§€ ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
        "    consistency_weight: float = 0.2  # ì‹œê°„ì  ì¼ê´€ì„± ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
        "    transition_threshold: float = 0.5  # ì „ì´ íƒì§€ ì„ê³„ê°’\n",
        "\n",
        "    # ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers: int = 2"
      ],
      "metadata": {
        "id": "d68uwfnj_vf4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INERTIAL_SIGNALS_FOLDER = \"Inertial Signals\"\n",
        "RAW_CHANNELS = [\n",
        "    (\"total_acc_x_\", \"txt\"), (\"total_acc_y_\", \"txt\"), (\"total_acc_z_\", \"txt\"),\n",
        "    (\"body_acc_x_\", \"txt\"), (\"body_acc_y_\", \"txt\"), (\"body_acc_z_\", \"txt\"),\n",
        "    (\"body_gyro_x_\", \"txt\"), (\"body_gyro_y_\", \"txt\"), (\"body_gyro_z_\", \"txt\"),\n",
        "]\n",
        "_LABEL_MAP = {1:\"WALKING\", 2:\"WALKING_UPSTAIRS\", 3:\"WALKING_DOWNSTAIRS\", 4:\"SITTING\", 5:\"STANDING\", 6:\"LAYING\"}\n",
        "_CODE_TO_LABEL_NAME = {i-1: _LABEL_MAP[i] for i in _LABEL_MAP}\n",
        "LABEL_NAME_TO_CODE = {v: k for k, v in _CODE_TO_LABEL_NAME.items()}"
      ],
      "metadata": {
        "id": "9Iw2wJcV_wB6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split_raw(root: str, split: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    assert split in (\"train\", \"test\")\n",
        "    inertial_path = os.path.join(root, split, INERTIAL_SIGNALS_FOLDER)\n",
        "\n",
        "    X_list = [\n",
        "        np.loadtxt(os.path.join(inertial_path, p + split + \".\" + e))[..., None]\n",
        "        for p, e in RAW_CHANNELS\n",
        "    ]\n",
        "\n",
        "    X = np.concatenate(X_list, axis=-1).transpose(0, 2, 1)\n",
        "    y = np.loadtxt(os.path.join(root, split, f\"y_{split}.txt\")).astype(int)\n",
        "\n",
        "    # â­ï¸ ì¤‘ìš”: UCI-HAR ë¼ë²¨ì€ 1~6ì´ë¯€ë¡œ, 0~5ë¡œ ë³€í™˜\n",
        "    y = y - 1\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Mo9CchAP_0sO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UCIHARInertial(Dataset):\n",
        "    def __init__(self, root: str, split: str, mean=None, std=None,\n",
        "                 preloaded_data: Tuple[np.ndarray, np.ndarray] | None = None):\n",
        "        super().__init__()\n",
        "\n",
        "        if preloaded_data is not None:\n",
        "            X, y = preloaded_data\n",
        "        else:\n",
        "            X, y = load_split_raw(root, split)\n",
        "\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = (y - 1).astype(np.int64) if y.min() >= 1 else y.astype(np.int64)\n",
        "\n",
        "        if mean is not None and std is not None:\n",
        "            self.mean, self.std = mean, std\n",
        "        else:\n",
        "            self.mean = self.X.mean(axis=(0,2), keepdims=True)\n",
        "            self.std = self.X.std(axis=(0,2), keepdims=True) + 1e-6\n",
        "\n",
        "        if preloaded_data is None:\n",
        "             self.X = (self.X - self.mean) / self.std\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.from_numpy(self.X[idx]),\n",
        "            torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "f7iAXYZm_1EA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transition_batch(x: torch.Tensor, y: torch.Tensor, mix_ratio: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    ì „ì´ êµ¬ê°„ì„ ìƒì„±í•˜ê³  ground truth ë ˆì´ë¸” ë°˜í™˜\n",
        "\n",
        "    Returns:\n",
        "        x_aug: ì „ì´ê°€ í¬í•¨ëœ ë°ì´í„°\n",
        "        transition_labels: ê° timestepë³„ ì „ì´ ì—¬ë¶€ (B, T)\n",
        "    \"\"\"\n",
        "    B, C, T = x.shape\n",
        "    device = x.device\n",
        "\n",
        "    x_aug = x.clone()\n",
        "    transition_labels = torch.zeros(B, T, dtype=torch.float32, device=device)\n",
        "    mix_pts = int(T * mix_ratio)\n",
        "\n",
        "    for i in range(B):\n",
        "        if random.random() < 0.5:  # 50% í™•ë¥ ë¡œ ì „ì´ ìƒì„±\n",
        "            other_class_indices = (y != y[i]).nonzero(as_tuple=True)[0]\n",
        "            if len(other_class_indices) > 0:\n",
        "                j = other_class_indices[random.randint(0, len(other_class_indices)-1)]\n",
        "                x_aug[i, :, -mix_pts:] = x[j, :, :mix_pts].clone()\n",
        "                transition_labels[i, -mix_pts:] = 1.0  # ì „ì´ êµ¬ê°„ í‘œì‹œ\n",
        "\n",
        "    return x_aug, transition_labels"
      ],
      "metadata": {
        "id": "8p7Y6gpK_3Ew"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k, s=1, p=None, g=1):\n",
        "        super().__init__()\n",
        "        self.c = nn.Conv1d(c_in, c_out, k, s, k//2 if p is None else p, groups=g, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(c_out)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.c(x)))\n",
        "\n",
        "class MultiPathCNN(nn.Module):\n",
        "    def __init__(self, in_ch=9, d_model=128, branches=(3,5,9,15), stride=2):\n",
        "        super().__init__()\n",
        "        h = d_model // 2\n",
        "        self.pre = ConvBNAct(in_ch, h, 1)\n",
        "        self.branches = nn.ModuleList([\n",
        "            nn.Sequential(ConvBNAct(h, h, k, stride, g=h), ConvBNAct(h, h, 1))\n",
        "            for k in branches\n",
        "        ])\n",
        "        self.post = ConvBNAct(len(branches)*h, d_model, 1)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_pre = self.pre(x)\n",
        "        x_branches = [b(x_pre) for b in self.branches]\n",
        "        return self.post(torch.cat(x_branches, dim=1))"
      ],
      "metadata": {
        "id": "FawZF1KA_7RZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, n_features=9, d_model=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stride = 2\n",
        "\n",
        "        self.cnn_extractor = nn.Sequential(\n",
        "            nn.Conv1d(n_features, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=512,\n",
        "            hidden_size=d_model,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_extractor(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # ë§ˆì§€ë§‰ ì€ë‹‰ ìƒíƒœ(hn) ëŒ€ì‹ , ëª¨ë“  ì‹œê°„ ë‹¨ê³„ì˜ ì¶œë ¥(lstm_out)ì„ ë°›ìŠµë‹ˆë‹¤.\n",
        "        lstm_out, _ = self.lstm(x) # lstm_out shape: (B, T_down, d_model)\n",
        "\n",
        "        # Headê°€ ê¸°ëŒ€í•˜ëŠ” (B, d_model, T_down) í˜•íƒœë¡œ ì¶•ì„ ë‹¤ì‹œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
        "        fmap = lstm_out.permute(0, 2, 1)\n",
        "\n",
        "        return fmap"
      ],
      "metadata": {
        "id": "2W7fp4Vb_8cl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransitionDetectionHead(nn.Module):\n",
        "    \"\"\"ì „ì´ êµ¬ê°„ íƒì§€ë¥¼ ìœ„í•œ Self-Supervised Head\"\"\"\n",
        "    def __init__(self, d_model: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBNAct(d_model, d_model // 2, 3)\n",
        "        self.conv2 = nn.Conv1d(d_model // 2, 1, 1)  # Binary classification per timestep\n",
        "\n",
        "    def forward(self, fmap):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            fmap: (B, d_model, T_down)\n",
        "        Returns:\n",
        "            transition_logits: (B, T_down)\n",
        "        \"\"\"\n",
        "        h = self.conv1(fmap)\n",
        "        logits = self.conv2(h).squeeze(1)  # (B, T_down)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "rrR7HVjr_804"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    \"\"\"í–‰ë™ ë¶„ë¥˜ë¥¼ ìœ„í•œ Main Head\"\"\"\n",
        "    def __init__(self, d_model: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, fmap):\n",
        "        pooled = self.gap(fmap).squeeze(-1)\n",
        "        logits = self.fc(pooled)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "7z4kfCR1_-v0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperbolicProjection(nn.Module):\n",
        "    def __init__(self, c=1.0):\n",
        "        super().__init__()\n",
        "        self.c = c\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = torch.clamp(torch.norm(x, dim=-1, keepdim=True), min=1e-8)\n",
        "        max_norm = (1.0 / math.sqrt(self.c)) - 1e-4\n",
        "        scale = torch.clamp(norm, max=max_norm) / norm\n",
        "        return x * scale"
      ],
      "metadata": {
        "id": "BiRsMr7QABs1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperbolicClassificationHead(nn.Module):\n",
        "    \"\"\"ìŒê³¡ ê³µê°„ ê¸°ë°˜ ë¶„ë¥˜ Head\"\"\"\n",
        "    def __init__(self, d_model: int, num_classes: int, c: float = 1.0):\n",
        "        super().__init__()\n",
        "        self.c = c\n",
        "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
        "        self.pre_proj = nn.Linear(d_model, d_model)\n",
        "        self.hyperbolic_proj = HyperbolicProjection(c=c)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, fmap):\n",
        "        pooled = self.gap(fmap).squeeze(-1)\n",
        "        h = self.pre_proj(pooled)\n",
        "        h_hyp = self.hyperbolic_proj(h)\n",
        "        logits = self.fc(h_hyp)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "XlM3fM-UADCf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SSLHARModel(nn.Module):\n",
        "    \"\"\"Self-Supervised Learning HAR Model\"\"\"\n",
        "    def __init__(self, d_model=128, num_classes=6, use_hyperbolic=False, hyperbolic_c=1.0):\n",
        "        super().__init__()\n",
        "        self.backbone = CNN_LSTM(d_model=d_model)\n",
        "\n",
        "        # Main task: í–‰ë™ ë¶„ë¥˜\n",
        "        if use_hyperbolic:\n",
        "            self.classification_head = HyperbolicClassificationHead(d_model, num_classes, c=hyperbolic_c)\n",
        "        else:\n",
        "            self.classification_head = ClassificationHead(d_model, num_classes)\n",
        "\n",
        "        # Pretext task: ì „ì´ íƒì§€\n",
        "        self.transition_head = TransitionDetectionHead(d_model)\n",
        "\n",
        "        self.stride = self.backbone.stride\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (B, C, T)\n",
        "            return_features: Trueë©´ intermediate features ë°˜í™˜\n",
        "        Returns:\n",
        "            class_logits: (B, num_classes)\n",
        "            transition_logits: (B, T_down)\n",
        "            features: (B, d_model, T_down) if return_features\n",
        "        \"\"\"\n",
        "        fmap = self.backbone(x)  # (B, d_model, T_down)\n",
        "\n",
        "        class_logits = self.classification_head(fmap)\n",
        "        transition_logits = self.transition_head(fmap)\n",
        "\n",
        "        if return_features:\n",
        "            return class_logits, transition_logits, fmap\n",
        "        return class_logits, transition_logits"
      ],
      "metadata": {
        "id": "3dvU8SD6AFFJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def temporal_consistency_loss(features: torch.Tensor, transition_probs: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    ì‹œê°„ì  ì¼ê´€ì„± ì†ì‹¤: ë¹„ì „ì´ êµ¬ê°„ì—ì„œ featureê°€ ì¼ê´€ë˜ë„ë¡ ìœ ë„\n",
        "\n",
        "    Args:\n",
        "        features: (B, d_model, T)\n",
        "        transition_probs: (B, T) - sigmoidëœ ì „ì´ í™•ë¥ \n",
        "    \"\"\"\n",
        "    B, D, T = features.shape\n",
        "\n",
        "    # ë¹„ì „ì´ êµ¬ê°„ ê°€ì¤‘ì¹˜ (ì „ì´ í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)\n",
        "    consistency_weights = 1.0 - transition_probs.unsqueeze(1)  # (B, 1, T)\n",
        "\n",
        "    # ì¸ì ‘ timestep ê°„ ì°¨ì´\n",
        "    diff = features[:, :, 1:] - features[:, :, :-1]  # (B, D, T-1)\n",
        "    diff_norm = torch.norm(diff, dim=1)  # (B, T-1)\n",
        "\n",
        "    # ë¹„ì „ì´ êµ¬ê°„ì—ì„œë§Œ ì¼ê´€ì„± ìš”êµ¬\n",
        "    weighted_diff = diff_norm * consistency_weights[:, 0, :-1]\n",
        "\n",
        "    return weighted_diff.mean()"
      ],
      "metadata": {
        "id": "rgrHR6dkAFcG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_detection_loss(pred_logits: torch.Tensor, target_labels: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    ì „ì´ íƒì§€ ì†ì‹¤ (Binary Cross Entropy)\n",
        "\n",
        "    Args:\n",
        "        pred_logits: (B, T_down)\n",
        "        target_labels: (B, T_orig) - downsampling í•„ìš”\n",
        "    \"\"\"\n",
        "    B, T_down = pred_logits.shape\n",
        "    T_orig = target_labels.shape[1]\n",
        "    stride = T_orig // T_down\n",
        "\n",
        "    # Targetì„ downsampling (max pooling: í•˜ë‚˜ë¼ë„ ì „ì´ë©´ ì „ì´ë¡œ ê°„ì£¼)\n",
        "    target_down = F.max_pool1d(\n",
        "        target_labels.unsqueeze(1),\n",
        "        kernel_size=stride,\n",
        "        stride=stride\n",
        "    ).squeeze(1)  # (B, T_down)\n",
        "\n",
        "    # BCE Loss with logits\n",
        "    loss = F.binary_cross_entropy_with_logits(pred_logits, target_down)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "3V3d0NfYAIL2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch_ssl(model: SSLHARModel, loader: DataLoader, opt: torch.optim.Optimizer, cfg: Config):\n",
        "    model.train()\n",
        "    total_loss, total_cls_loss, total_ssl_loss, total_cons_loss = 0.0, 0.0, 0.0, 0.0\n",
        "    total_correct, total_samples = 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device), y.to(cfg.device)\n",
        "\n",
        "        # Self-supervised augmentation\n",
        "        if random.random() < cfg.train_augment_prob:\n",
        "            x_aug, transition_gt = create_transition_batch(x, y, cfg.train_augment_mix)\n",
        "        else:\n",
        "            x_aug = x\n",
        "            transition_gt = torch.zeros(x.shape[0], x.shape[2], device=cfg.device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass\n",
        "        class_logits, transition_logits, features = model(x_aug, return_features=True)\n",
        "\n",
        "        # Loss ê³„ì‚°\n",
        "        # 1. Main task: í–‰ë™ ë¶„ë¥˜\n",
        "        cls_loss = F.cross_entropy(class_logits, y, label_smoothing=cfg.label_smoothing)\n",
        "\n",
        "        # 2. Pretext task: ì „ì´ íƒì§€\n",
        "        ssl_loss = transition_detection_loss(transition_logits, transition_gt)\n",
        "\n",
        "        # 3. Temporal consistency\n",
        "        transition_probs = torch.sigmoid(transition_logits)\n",
        "        cons_loss = temporal_consistency_loss(features, transition_probs)\n",
        "\n",
        "        # Total loss\n",
        "        loss = cls_loss + cfg.ssl_weight * ssl_loss + cfg.consistency_weight * cons_loss\n",
        "\n",
        "        if torch.isnan(loss):\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        opt.step()\n",
        "\n",
        "        # Metrics\n",
        "        pred = class_logits.argmax(dim=-1)\n",
        "        total_correct += (pred == y).sum().item()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        total_cls_loss += cls_loss.item() * y.size(0)\n",
        "        total_ssl_loss += ssl_loss.item() * y.size(0)\n",
        "        total_cons_loss += cons_loss.item() * y.size(0)\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / total_samples,\n",
        "        \"cls_loss\": total_cls_loss / total_samples,\n",
        "        \"ssl_loss\": total_ssl_loss / total_samples,\n",
        "        \"cons_loss\": total_cons_loss / total_samples,\n",
        "        \"acc\": total_correct / total_samples\n",
        "    }"
      ],
      "metadata": {
        "id": "W6YPw9ZBAMtN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_ssl(model: SSLHARModel, loader: DataLoader, cfg: Config):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    transition_probs_all = []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device), y.to(cfg.device)\n",
        "        class_logits, transition_logits = model(x)\n",
        "\n",
        "        y_pred.append(class_logits.argmax(dim=-1).cpu().numpy())\n",
        "        y_true.append(y.cpu().numpy())\n",
        "        transition_probs_all.append(torch.sigmoid(transition_logits).cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true)\n",
        "    y_pred = np.concatenate(y_pred)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # ì „ì´ íƒì§€ ëŠ¥ë ¥ ì¸¡ì • (í‰ê·  confidence)\n",
        "    avg_transition_conf = np.concatenate(transition_probs_all).mean()\n",
        "\n",
        "    return acc, f1, avg_transition_conf"
      ],
      "metadata": {
        "id": "3DbG5B64ARVD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transitional_test_set_with_gt(\n",
        "    orig_dataset: UCIHARInertial, class_A: str, class_B: str, p: float, mix: float\n",
        ") -> Tuple[UCIHARInertial, np.ndarray, dict]:\n",
        "    \"\"\"\n",
        "    ì „ì´ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± + ground truth ë°˜í™˜\n",
        "\n",
        "    Returns:\n",
        "        mod_dataset: ì „ì´ê°€ í¬í•¨ëœ ë°ì´í„°ì…‹\n",
        "        transition_gt: (N, T) ì „ì´ êµ¬ê°„ ground truth\n",
        "        info: í†µê³„ ì •ë³´\n",
        "    \"\"\"\n",
        "    X, y = orig_dataset.X.copy(), orig_dataset.y.copy()\n",
        "    N, C, T = X.shape\n",
        "    transition_gt = np.zeros((N, T), dtype=np.float32)\n",
        "\n",
        "    code_A, code_B = LABEL_NAME_TO_CODE[class_A], LABEL_NAME_TO_CODE[class_B]\n",
        "    idx_A, idx_B = np.where(y == code_A)[0], np.where(y == code_B)[0]\n",
        "    mix_pts = int(T * mix)\n",
        "\n",
        "    # A â†’ B ì „ì´\n",
        "    targets_A = np.random.choice(idx_A, max(1, int(len(idx_A) * p)), replace=False)\n",
        "    sources_B = np.random.choice(idx_B, len(targets_A), replace=True)\n",
        "    for t, s in zip(targets_A, sources_B):\n",
        "        X[t, :, -mix_pts:] = orig_dataset.X[s, :, :mix_pts]\n",
        "        transition_gt[t, -mix_pts:] = 1.0\n",
        "\n",
        "    # B â†’ A ì „ì´\n",
        "    targets_B = np.random.choice(idx_B, max(1, int(len(idx_B) * p)), replace=False)\n",
        "    sources_A = np.random.choice(idx_A, len(targets_B), replace=True)\n",
        "    for t, s in zip(targets_B, sources_A):\n",
        "        X[t, :, -mix_pts:] = orig_dataset.X[s, :, :mix_pts]\n",
        "        transition_gt[t, -mix_pts:] = 1.0\n",
        "\n",
        "    mod_dataset = UCIHARInertial(\n",
        "        root=\"\", split=\"test\", mean=orig_dataset.mean, std=orig_dataset.std,\n",
        "        preloaded_data=(X, y)\n",
        "    )\n",
        "\n",
        "    info = {\n",
        "        'modified_samples': len(targets_A) + len(targets_B),\n",
        "        'modified_ratio': (len(targets_A) + len(targets_B)) / N,\n",
        "    }\n",
        "    return mod_dataset, transition_gt, info"
      ],
      "metadata": {
        "id": "Kq3pB-0lATpM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_transition_detection(\n",
        "    model: SSLHARModel, dataset: UCIHARInertial, transition_gt: np.ndarray, cfg: Config\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"ì „ì´ íƒì§€ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "    all_probs, all_labels = [], []\n",
        "\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x = x.to(cfg.device)\n",
        "        _, transition_logits = model(x)\n",
        "        transition_probs = torch.sigmoid(transition_logits).cpu().numpy()  # (B, T_down)\n",
        "\n",
        "        # Ground truth downsampling\n",
        "        batch_start = i * cfg.batch_size\n",
        "        batch_end = min(batch_start + cfg.batch_size, len(dataset))\n",
        "        gt_batch = transition_gt[batch_start:batch_end]\n",
        "\n",
        "        T_down = transition_probs.shape[1]\n",
        "        stride = gt_batch.shape[1] // T_down\n",
        "        gt_down = gt_batch.reshape(gt_batch.shape[0], T_down, stride).max(axis=2)\n",
        "\n",
        "        all_probs.append(transition_probs)\n",
        "        all_labels.append(gt_down)\n",
        "\n",
        "    all_probs = np.concatenate(all_probs).flatten()\n",
        "    all_labels = np.concatenate(all_labels).flatten()\n",
        "\n",
        "    # AUC-ROC ê³„ì‚°\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # Binary accuracy (threshold=0.5)\n",
        "    pred_binary = (all_probs > cfg.transition_threshold).astype(int)\n",
        "    acc = accuracy_score(all_labels, pred_binary)\n",
        "\n",
        "    # Precision, Recall\n",
        "    tp = ((pred_binary == 1) & (all_labels == 1)).sum()\n",
        "    fp = ((pred_binary == 1) & (all_labels == 0)).sum()\n",
        "    fn = ((pred_binary == 0) & (all_labels == 1)).sum()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'auc': auc,\n",
        "        'acc': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "kr65olrtAV9_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NumpyEncoder, self).default(obj)"
      ],
      "metadata": {
        "id": "VLc66TQAAXru"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ssl_experiment(cfg: Config):\n",
        "    os.makedirs(cfg.save_dir, exist_ok=True)\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "    train_set = UCIHARInertial(cfg.data_dir, \"train\")\n",
        "    test_set_orig = UCIHARInertial(cfg.data_dir, \"test\", mean=train_set.mean, std=train_set.std)\n",
        "\n",
        "    # ì „ì´ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤\n",
        "    scenarios = [\n",
        "        (\"STANDING\", \"SITTING\", 0.60, 0.50),\n",
        "        (\"STANDING\", \"SITTING\", 0.70, 0.55),\n",
        "        (\"WALKING\", \"WALKING_UPSTAIRS\", 0.65, 0.52),\n",
        "        (\"SITTING\", \"LAYING\", 0.75, 0.58),\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"    ğŸ”¬ TRANSITIONAL TEST SETS ìƒì„± (Ground Truth í¬í•¨)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    transition_test_data = []\n",
        "    for clsA, clsB, p, mix in scenarios:\n",
        "        test_set_mod, transition_gt, info = create_transitional_test_set_with_gt(\n",
        "            test_set_orig, clsA, clsB, p=p, mix=mix\n",
        "        )\n",
        "        transition_test_data.append((test_set_mod, transition_gt, info))\n",
        "        print(f\"   - {clsA}â†”{clsB} (p={p:.2f}, mix={mix:.2f}): {info['modified_samples']}ê°œ ìƒ˜í”Œ ë³€í˜•\")\n",
        "\n",
        "    # ë¹„êµ ëª¨ë¸\n",
        "    ssl_configs = [\n",
        "        {\"name\": \"SSL_Euclidean\", \"use_hyperbolic\": False},\n",
        "        {\"name\": \"SSL_Hyperbolic\", \"use_hyperbolic\": True},\n",
        "    ]\n",
        "\n",
        "    results_table = []\n",
        "\n",
        "    for ssl_cfg in ssl_configs:\n",
        "        print(f\"\\n{'='*70}\\n   ì‹¤í—˜: {ssl_cfg['name']}\\n{'='*70}\")\n",
        "\n",
        "        random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "        cfg.use_hyperbolic = ssl_cfg[\"use_hyperbolic\"]\n",
        "        train_loader = DataLoader(train_set, cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
        "        test_loader_orig = DataLoader(test_set_orig, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "        model = SSLHARModel(\n",
        "            d_model=cfg.d_model, use_hyperbolic=cfg.use_hyperbolic, hyperbolic_c=cfg.hyperbolic_c\n",
        "        ).to(cfg.device)\n",
        "\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "        best_acc, best_wts = 0.0, None\n",
        "        print(f\"Training {ssl_cfg['name']} for {cfg.epochs} epochs...\")\n",
        "\n",
        "        for epoch in range(1, cfg.epochs + 1):\n",
        "            stats = train_one_epoch_ssl(model, train_loader, opt, cfg)\n",
        "            te_acc, te_f1, te_trans_conf = evaluate_ssl(model, test_loader_orig, cfg)\n",
        "\n",
        "            if te_acc > best_acc:\n",
        "                best_acc = te_acc\n",
        "                best_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            if epoch % 5 == 0 or epoch == 1:\n",
        "                print(f\"[{epoch:02d}/{cfg.epochs}] Train L:{stats['loss']:.4f} (Cls:{stats['cls_loss']:.4f} \"\n",
        "                      f\"SSL:{stats['ssl_loss']:.4f} Cons:{stats['cons_loss']:.4f}) A:{stats['acc']:.4f} | \"\n",
        "                      f\"Test A:{te_acc:.4f} F1:{te_f1:.4f} TransConf:{te_trans_conf:.4f}\")\n",
        "\n",
        "        if best_wts:\n",
        "            model.load_state_dict(best_wts)\n",
        "        print(f\"âœ… Best Original Test Acc: {best_acc:.4f}\")\n",
        "\n",
        "        # ì›ë³¸ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€\n",
        "        acc_orig, f1_orig, _ = evaluate_ssl(model, test_loader_orig, cfg)\n",
        "\n",
        "        # ì „ì´ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€\n",
        "        transition_results = []\n",
        "        print(\"\\n   ğŸ” ì „ì´ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ (Self-Supervised Detection)...\")\n",
        "\n",
        "        for i, (test_set_mod, transition_gt, info) in enumerate(transition_test_data):\n",
        "            test_loader_mod = DataLoader(test_set_mod, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "            # ë¶„ë¥˜ ì„±ëŠ¥\n",
        "            acc_trans, f1_trans, _ = evaluate_ssl(model, test_loader_mod, cfg)\n",
        "            drop = acc_orig - acc_trans\n",
        "\n",
        "            # ì „ì´ íƒì§€ ì„±ëŠ¥\n",
        "            detection_metrics = evaluate_transition_detection(model, test_set_mod, transition_gt, cfg)\n",
        "\n",
        "            transition_results.append({\n",
        "                'scenario': i+1,\n",
        "                'class_acc': acc_trans,\n",
        "                'class_drop': drop,\n",
        "                'detection_auc': detection_metrics['auc'],\n",
        "                'detection_acc': detection_metrics['acc'],\n",
        "                'detection_f1': detection_metrics['f1'],\n",
        "                'detection_precision': detection_metrics['precision'],\n",
        "                'detection_recall': detection_metrics['recall']\n",
        "            })\n",
        "\n",
        "            print(f\"     - Scenario {i+1}: ClassAcc={acc_trans:.4f} (Drop={drop:.4f}) | \"\n",
        "                  f\"DetAUC={detection_metrics['auc']:.4f} DetF1={detection_metrics['f1']:.4f}\")\n",
        "\n",
        "        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°\n",
        "        avg_trans_acc = np.mean([r['class_acc'] for r in transition_results])\n",
        "        avg_drop = acc_orig - avg_trans_acc\n",
        "        retention = (1 - avg_drop / acc_orig) * 100 if acc_orig > 0 else 0\n",
        "        avg_det_auc = np.mean([r['detection_auc'] for r in transition_results])\n",
        "        avg_det_f1 = np.mean([r['detection_f1'] for r in transition_results])\n",
        "\n",
        "        results_table.append({\n",
        "            \"config\": ssl_cfg[\"name\"],\n",
        "            \"orig_acc\": acc_orig,\n",
        "            \"orig_f1\": f1_orig,\n",
        "            \"avg_trans_acc\": avg_trans_acc,\n",
        "            \"avg_drop\": avg_drop,\n",
        "            \"retention\": retention,\n",
        "            \"avg_detection_auc\": avg_det_auc,\n",
        "            \"avg_detection_f1\": avg_det_f1,\n",
        "            \"transition_results\": transition_results\n",
        "        })\n",
        "\n",
        "    # ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
        "    print(f\"\\n{'='*70}\\n   SELF-SUPERVISED LEARNING ì‹¤í—˜ ê²°ê³¼\\n{'='*70}\")\n",
        "    print(f\"{'Config':<20} {'Orig Acc':<10} {'Trans Acc':<11} {'Drop':<10} {'Retention':<12} {'Det AUC':<10} {'Det F1':<10}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    for r in results_table:\n",
        "        print(f\"{r['config']:<20} {r['orig_acc']:.4f}     {r['avg_trans_acc']:.4f}      \"\n",
        "              f\"{r['avg_drop']:.4f}   {r['retention']:.2f}%      {r['avg_detection_auc']:.4f}    {r['avg_detection_f1']:.4f}\")\n",
        "\n",
        "    # ìƒì„¸ ë¹„êµ ë¶„ì„\n",
        "    if len(results_table) > 1:\n",
        "        euclidean, hyperbolic = results_table[0], results_table[1]\n",
        "\n",
        "        print(\"\\n\" + \"-\"*95)\n",
        "        print(\"ğŸ“Š ìƒì„¸ ë¹„êµ ë¶„ì„\")\n",
        "        print(\"-\" * 95)\n",
        "\n",
        "        # ë¶„ë¥˜ ì„±ëŠ¥ ë¹„êµ\n",
        "        drop_improve = ((euclidean['avg_drop'] - hyperbolic['avg_drop']) / euclidean['avg_drop'] * 100) \\\n",
        "                       if euclidean['avg_drop'] > 0 else 0\n",
        "        print(f\"\\n1ï¸âƒ£  ë¶„ë¥˜ ê°•ê±´ì„±:\")\n",
        "        print(f\"   - Drop ê°ì†Œìœ¨: {drop_improve:+.2f}%\")\n",
        "        print(f\"   - Retention ì´ë“: {hyperbolic['retention'] - euclidean['retention']:+.2f}pp\")\n",
        "\n",
        "        # ì „ì´ íƒì§€ ì„±ëŠ¥ ë¹„êµ\n",
        "        det_auc_improve = (hyperbolic['avg_detection_auc'] - euclidean['avg_detection_auc']) * 100\n",
        "        det_f1_improve = (hyperbolic['avg_detection_f1'] - euclidean['avg_detection_f1']) * 100\n",
        "        print(f\"\\n2ï¸âƒ£  ì „ì´ íƒì§€ ì„±ëŠ¥:\")\n",
        "        print(f\"   - AUC ê°œì„ : {det_auc_improve:+.2f}pp\")\n",
        "        print(f\"   - F1 ê°œì„ : {det_f1_improve:+.2f}pp\")\n",
        "\n",
        "        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìƒì„¸ ë¹„êµ\n",
        "        print(f\"\\n3ï¸âƒ£  ì‹œë‚˜ë¦¬ì˜¤ë³„ ì „ì´ íƒì§€ ì„±ëŠ¥:\")\n",
        "        print(f\"   {'Scenario':<12} {'Euclidean AUC':<16} {'Hyperbolic AUC':<16} {'ê°œì„ ':<10}\")\n",
        "        print(\"   \" + \"-\"*60)\n",
        "        for i in range(len(euclidean['transition_results'])):\n",
        "            euc_auc = euclidean['transition_results'][i]['detection_auc']\n",
        "            hyp_auc = hyperbolic['transition_results'][i]['detection_auc']\n",
        "            improve = (hyp_auc - euc_auc) * 100\n",
        "            print(f\"   Scenario {i+1:<4} {euc_auc:.4f}           {hyp_auc:.4f}           {improve:+.2f}pp\")\n",
        "\n",
        "        # í•´ì„\n",
        "        print(\"\\n\" + \"-\"*95)\n",
        "        print(\"ğŸ§  ê²°ê³¼ í•´ì„:\")\n",
        "        print(\"-\" * 95)\n",
        "\n",
        "        if drop_improve > 20 and det_auc_improve > 5:\n",
        "            print(\"âœ… ìŒê³¡ ê³µê°„ì´ Self-Supervised Learningì—ì„œ íƒì›”í•œ ì„±ëŠ¥ ë°œíœ˜:\")\n",
        "            print(\"   1. ì „ì´ êµ¬ê°„ì„ ë” ì •í™•í•˜ê²Œ íƒì§€ (ë†’ì€ AUC)\")\n",
        "            print(\"   2. íƒì§€ëœ ì •ë³´ë¥¼ í™œìš©í•´ ë¶„ë¥˜ ê°•ê±´ì„± í¬ê²Œ í–¥ìƒ\")\n",
        "            print(\"   3. ìŒê³¡ ê¸°í•˜í•™ì´ implicit + explicit robustness ëª¨ë‘ ì œê³µ\")\n",
        "        elif drop_improve > 10 or det_auc_improve > 3:\n",
        "            print(\"âš ï¸  ìŒê³¡ ê³µê°„ì´ ì ë‹¹í•œ ê°œì„  ì œê³µ:\")\n",
        "            print(\"   - ì „ì´ íƒì§€ ë˜ëŠ” ë¶„ë¥˜ ê°•ê±´ì„± ì¤‘ í•˜ë‚˜ì—ì„œ ìš°ìˆ˜\")\n",
        "            print(\"   - SSL íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ì¶”ê°€ ê°œì„  ê°€ëŠ¥\")\n",
        "        else:\n",
        "            print(\"âŒ ì œí•œì  ê°œì„ :\")\n",
        "            print(\"   - Euclidean ê³µê°„ë„ SSLë¡œ ì¶©ë¶„í•œ ê°•ê±´ì„± í™•ë³´\")\n",
        "            print(\"   - ìŒê³¡ ê³µê°„ì˜ ì´ì ì´ SSL ì„¤ì •ì—ì„œ ë‘ë“œëŸ¬ì§€ì§€ ì•ŠìŒ\")\n",
        "\n",
        "        print(\"\\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:\")\n",
        "        if hyperbolic['avg_detection_auc'] > 0.75:\n",
        "            print(f\"   âœ“ ìŒê³¡ ëª¨ë¸ì˜ ì „ì´ íƒì§€ AUC {hyperbolic['avg_detection_auc']:.3f}ë¡œ ì‹ ë¢°í• ë§Œí•œ ìˆ˜ì¤€\")\n",
        "            print(\"   âœ“ Self-Supervised Headê°€ ì „ì´ íŒ¨í„´ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ\")\n",
        "        if hyperbolic['retention'] > 85:\n",
        "            print(f\"   âœ“ Retention {hyperbolic['retention']:.1f}%ë¡œ ì‹¤ìš©ì  ìˆ˜ì¤€ì˜ ê°•ê±´ì„± ë‹¬ì„±\")\n",
        "\n",
        "        print(\"\\nğŸ“ˆ ì¶”ê°€ ì‹¤í—˜ ì œì•ˆ:\")\n",
        "        print(\"   1. SSL ê°€ì¤‘ì¹˜(ssl_weight, consistency_weight) ìµœì í™”\")\n",
        "        print(\"   2. ë” ë‹¤ì–‘í•œ ì „ì´ íŒ¨í„´(ì ì§„ì  ì „ì´, ë‹¤ì¤‘ ì „ì´ ë“±) í…ŒìŠ¤íŠ¸\")\n",
        "        print(\"   3. Attention ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€ë¡œ ì „ì´ êµ¬ê°„ ì§‘ì¤‘ í•™ìŠµ\")\n",
        "        print(\"   4. ì¤€ì§€ë„ í•™ìŠµ(Semi-supervised) ì„¤ì • ì‹¤í—˜\")\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    with open(os.path.join(cfg.save_dir, \"ssl_results.json\"), \"w\") as f:\n",
        "        json.dump(results_table, f, indent=2, cls=NumpyEncoder)\n",
        "    print(f\"\\nâœ… Results saved to '{cfg.save_dir}/ssl_results.json'\")\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•œ ì¶”ê°€ ì •ë³´ ì €ì¥\n",
        "    visualization_data = {\n",
        "        'configs': [r['config'] for r in results_table],\n",
        "        'orig_acc': [r['orig_acc'] for r in results_table],\n",
        "        'trans_acc': [r['avg_trans_acc'] for r in results_table],\n",
        "        'detection_auc': [r['avg_detection_auc'] for r in results_table],\n",
        "        'detection_f1': [r['avg_detection_f1'] for r in results_table],\n",
        "        'retention': [r['retention'] for r in results_table]\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(cfg.save_dir, \"ssl_visualization_data.json\"), \"w\") as f:\n",
        "        json.dump(visualization_data, f, indent=2, cls=NumpyEncoder)"
      ],
      "metadata": {
        "id": "zlBUe-diAYLb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    config = Config()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"   ğŸ§ª UCI-HAR Self-Supervised Learning with Transition Detection\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"   í•µì‹¬ ì•„ì´ë””ì–´:\")\n",
        "    print(\"   1. ì „ì´ êµ¬ê°„ì„ maskë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ\")\n",
        "    print(\"   2. Multipath CNNì´ ìê¸°ì£¼ë„í•™ìŠµìœ¼ë¡œ ì „ì´ êµ¬ê°„ íƒì§€\")\n",
        "    print(\"   3. Main Task: í–‰ë™ ë¶„ë¥˜ / Pretext Task: ì „ì´ íƒì§€\")\n",
        "    print(\"   4. Temporal Consistency Lossë¡œ ì•”ì‹œì  ê°•ê±´ì„± í•™ìŠµ\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Device: {config.device}\")\n",
        "    print(f\"Epochs: {config.epochs}, LR: {config.lr}\")\n",
        "    print(f\"SSL Weight: {config.ssl_weight}, Consistency Weight: {config.consistency_weight}\")\n",
        "    print(f\"Transition Augment Prob: {config.train_augment_prob}\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    run_ssl_experiment(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnElPggfAgtm",
        "outputId": "5a3734a7-3147-41aa-a99b-6d3d70bc78d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "   ğŸ§ª UCI-HAR Self-Supervised Learning with Transition Detection\n",
            "======================================================================\n",
            "   í•µì‹¬ ì•„ì´ë””ì–´:\n",
            "   1. ì „ì´ êµ¬ê°„ì„ maskë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ\n",
            "   2. Multipath CNNì´ ìê¸°ì£¼ë„í•™ìŠµìœ¼ë¡œ ì „ì´ êµ¬ê°„ íƒì§€\n",
            "   3. Main Task: í–‰ë™ ë¶„ë¥˜ / Pretext Task: ì „ì´ íƒì§€\n",
            "   4. Temporal Consistency Lossë¡œ ì•”ì‹œì  ê°•ê±´ì„± í•™ìŠµ\n",
            "======================================================================\n",
            "Device: cuda\n",
            "Epochs: 30, LR: 0.0003\n",
            "SSL Weight: 0.3, Consistency Weight: 0.2\n",
            "Transition Augment Prob: 0.4\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "    ğŸ”¬ TRANSITIONAL TEST SETS ìƒì„± (Ground Truth í¬í•¨)\n",
            "======================================================================\n",
            "   - STANDINGâ†”SITTING (p=0.60, mix=0.50): 613ê°œ ìƒ˜í”Œ ë³€í˜•\n",
            "   - STANDINGâ†”SITTING (p=0.70, mix=0.55): 715ê°œ ìƒ˜í”Œ ë³€í˜•\n",
            "   - WALKINGâ†”WALKING_UPSTAIRS (p=0.65, mix=0.52): 628ê°œ ìƒ˜í”Œ ë³€í˜•\n",
            "   - SITTINGâ†”LAYING (p=0.75, mix=0.58): 770ê°œ ìƒ˜í”Œ ë³€í˜•\n",
            "\n",
            "======================================================================\n",
            "   ì‹¤í—˜: SSL_Euclidean\n",
            "======================================================================\n",
            "Training SSL_Euclidean for 30 epochs...\n",
            "[01/30] Train L:0.9212 (Cls:0.6860 SSL:0.5784 Cons:0.3082) A:0.8723 | Test A:0.8860 F1:0.8861 TransConf:0.3167\n",
            "[05/30] Train L:0.4172 (Cls:0.3394 SSL:0.1730 Cons:0.1296) A:0.9539 | Test A:0.9209 F1:0.9218 TransConf:0.1326\n",
            "[10/30] Train L:0.3694 (Cls:0.3273 SSL:0.0742 Cons:0.0995) A:0.9574 | Test A:0.9260 F1:0.9266 TransConf:0.0486\n",
            "[15/30] Train L:0.3478 (Cls:0.3166 SSL:0.0454 Cons:0.0878) A:0.9607 | Test A:0.9294 F1:0.9305 TransConf:0.0297\n",
            "[20/30] Train L:0.3385 (Cls:0.3143 SSL:0.0293 Cons:0.0768) A:0.9626 | Test A:0.9203 F1:0.9213 TransConf:0.0278\n",
            "[25/30] Train L:0.3321 (Cls:0.3123 SSL:0.0215 Cons:0.0667) A:0.9631 | Test A:0.9237 F1:0.9245 TransConf:0.0233\n",
            "[30/30] Train L:0.3324 (Cls:0.3122 SSL:0.0236 Cons:0.0657) A:0.9630 | Test A:0.9192 F1:0.9203 TransConf:0.0226\n",
            "âœ… Best Original Test Acc: 0.9328\n",
            "\n",
            "   ğŸ” ì „ì´ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ (Self-Supervised Detection)...\n",
            "     - Scenario 1: ClassAcc=0.9237 (Drop=0.0092) | DetAUC=0.9437 DetF1=0.7311\n",
            "     - Scenario 2: ClassAcc=0.9172 (Drop=0.0156) | DetAUC=0.9456 DetF1=0.7479\n",
            "     - Scenario 3: ClassAcc=0.9223 (Drop=0.0105) | DetAUC=0.9166 DetF1=0.7566\n",
            "     - Scenario 4: ClassAcc=0.9294 (Drop=0.0034) | DetAUC=0.9926 DetF1=0.9266\n",
            "\n",
            "======================================================================\n",
            "   ì‹¤í—˜: SSL_Hyperbolic\n",
            "======================================================================\n",
            "Training SSL_Hyperbolic for 30 epochs...\n",
            "[01/30] Train L:1.6396 (Cls:1.4110 SSL:0.6204 Cons:0.2121) A:0.8239 | Test A:0.8907 F1:0.8912 TransConf:0.3604\n",
            "[05/30] Train L:0.9255 (Cls:0.8604 SSL:0.1737 Cons:0.0650) A:0.9538 | Test A:0.9172 F1:0.9183 TransConf:0.1118\n",
            "[10/30] Train L:0.5828 (Cls:0.5507 SSL:0.0755 Cons:0.0469) A:0.9601 | Test A:0.9182 F1:0.9193 TransConf:0.0571\n",
            "[15/30] Train L:0.4424 (Cls:0.4224 SSL:0.0412 Cons:0.0382) A:0.9603 | Test A:0.9209 F1:0.9215 TransConf:0.0484\n",
            "[20/30] Train L:0.3802 (Cls:0.3642 SSL:0.0310 Cons:0.0338) A:0.9638 | Test A:0.9260 F1:0.9271 TransConf:0.0289\n",
            "[25/30] Train L:0.3440 (Cls:0.3306 SSL:0.0252 Cons:0.0290) A:0.9669 | Test A:0.9304 F1:0.9313 TransConf:0.0118\n",
            "[30/30] Train L:0.3320 (Cls:0.3205 SSL:0.0199 Cons:0.0276) A:0.9672 | Test A:0.9226 F1:0.9229 TransConf:0.0116\n",
            "âœ… Best Original Test Acc: 0.9342\n",
            "\n",
            "   ğŸ” ì „ì´ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ (Self-Supervised Detection)...\n",
            "     - Scenario 1: ClassAcc=0.9267 (Drop=0.0075) | DetAUC=0.9047 DetF1=0.7139\n",
            "     - Scenario 2: ClassAcc=0.9206 (Drop=0.0136) | DetAUC=0.8950 DetF1=0.7413\n",
            "     - Scenario 3: ClassAcc=0.9189 (Drop=0.0153) | DetAUC=0.9802 DetF1=0.8031\n",
            "     - Scenario 4: ClassAcc=0.9332 (Drop=0.0010) | DetAUC=0.9957 DetF1=0.9531\n",
            "\n",
            "======================================================================\n",
            "   SELF-SUPERVISED LEARNING ì‹¤í—˜ ê²°ê³¼\n",
            "======================================================================\n",
            "Config               Orig Acc   Trans Acc   Drop       Retention    Det AUC    Det F1    \n",
            "-----------------------------------------------------------------------------------------------\n",
            "SSL_Euclidean        0.9328     0.9231      0.0097   98.96%      0.9496    0.7906\n",
            "SSL_Hyperbolic       0.9342     0.9248      0.0093   99.00%      0.9439    0.8029\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "ğŸ“Š ìƒì„¸ ë¹„êµ ë¶„ì„\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "1ï¸âƒ£  ë¶„ë¥˜ ê°•ê±´ì„±:\n",
            "   - Drop ê°ì†Œìœ¨: +3.51%\n",
            "   - Retention ì´ë“: +0.04pp\n",
            "\n",
            "2ï¸âƒ£  ì „ì´ íƒì§€ ì„±ëŠ¥:\n",
            "   - AUC ê°œì„ : -0.58pp\n",
            "   - F1 ê°œì„ : +1.23pp\n",
            "\n",
            "3ï¸âƒ£  ì‹œë‚˜ë¦¬ì˜¤ë³„ ì „ì´ íƒì§€ ì„±ëŠ¥:\n",
            "   Scenario     Euclidean AUC    Hyperbolic AUC   ê°œì„         \n",
            "   ------------------------------------------------------------\n",
            "   Scenario 1    0.9437           0.9047           -3.90pp\n",
            "   Scenario 2    0.9456           0.8950           -5.07pp\n",
            "   Scenario 3    0.9166           0.9802           +6.36pp\n",
            "   Scenario 4    0.9926           0.9957           +0.30pp\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "ğŸ§  ê²°ê³¼ í•´ì„:\n",
            "-----------------------------------------------------------------------------------------------\n",
            "âŒ ì œí•œì  ê°œì„ :\n",
            "   - Euclidean ê³µê°„ë„ SSLë¡œ ì¶©ë¶„í•œ ê°•ê±´ì„± í™•ë³´\n",
            "   - ìŒê³¡ ê³µê°„ì˜ ì´ì ì´ SSL ì„¤ì •ì—ì„œ ë‘ë“œëŸ¬ì§€ì§€ ì•ŠìŒ\n",
            "\n",
            "ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:\n",
            "   âœ“ ìŒê³¡ ëª¨ë¸ì˜ ì „ì´ íƒì§€ AUC 0.944ë¡œ ì‹ ë¢°í• ë§Œí•œ ìˆ˜ì¤€\n",
            "   âœ“ Self-Supervised Headê°€ ì „ì´ íŒ¨í„´ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ\n",
            "   âœ“ Retention 99.0%ë¡œ ì‹¤ìš©ì  ìˆ˜ì¤€ì˜ ê°•ê±´ì„± ë‹¬ì„±\n",
            "\n",
            "ğŸ“ˆ ì¶”ê°€ ì‹¤í—˜ ì œì•ˆ:\n",
            "   1. SSL ê°€ì¤‘ì¹˜(ssl_weight, consistency_weight) ìµœì í™”\n",
            "   2. ë” ë‹¤ì–‘í•œ ì „ì´ íŒ¨í„´(ì ì§„ì  ì „ì´, ë‹¤ì¤‘ ì „ì´ ë“±) í…ŒìŠ¤íŠ¸\n",
            "   3. Attention ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€ë¡œ ì „ì´ êµ¬ê°„ ì§‘ì¤‘ í•™ìŠµ\n",
            "   4. ì¤€ì§€ë„ í•™ìŠµ(Semi-supervised) ì„¤ì • ì‹¤í—˜\n",
            "\n",
            "âœ… Results saved to '/content/drive/MyDrive/Colab Notebooks/UCI-HAR/ssl_transition/ssl_results.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLfqNlqnC_pQ"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}