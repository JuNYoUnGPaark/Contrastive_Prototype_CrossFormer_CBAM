================================================================================
   🧪 UCI-HAR Comprehensive Comparison (✨ OPTIMIZED)
   SUPERVISED vs TRUE SELF-SUPERVISED LEARNING
   Architecture: ResNet + Transformer Encoder
================================================================================

   📋 실험 설계:
   1. 동일한 백본 (ResNet + Transformer)
   2. 2레벨 전이 데이터셋 (Moderate/Strong)
   3. 6가지 설정 비교:
      ├─ Supervised × (Linear, Hyperbolic)
      ├─ SSL Linear Eval × (Linear, Hyperbolic)
      └─ SSL Fine-tune × (Linear, Hyperbolic)
================================================================================

   ⚙️  Supervised 설정:
   - Epochs: 50
   - Batch size: 128
   - Learning rate: 0.0003
   - Warmup: 5 epochs
   - EMA decay: Disabled
   - Consistency weight: 0.0
   - Training: End-to-end with labels + consistency loss

   ⚙️  SSL 설정:
   - Stage 1 (Pretrain): 100 epochs, batch=512, lr=0.001
     → Contrastive learning only (NO LABELS)
     → Label-independent augmentation
     → Warmup: 10 epochs
     → EMA decay: Disabled
   - Stage 2 (Eval/FT): 50 epochs, batch=128, lr=0.0003
     → Linear Eval: Freeze backbone
     → Fine-tune: Train all (backbone LR × 0.1)
     → Consistency weight: 0.0

   🔧 Augmentations (SSL - Optimized):
   - Jitter (scale=0.05)
   - Scaling (range=(0.8, 1.2))
   - Channel Drop (prob=0.2)
   - Time Warp (prob=0.1) ✅ 0.3→0.10
   - Cutout (prob=0.2, ratio=0.1) ✅ 0.2→0.10
   - ALL label-independent!

   🏗️  Architecture:
   - Backbone: ResNet(layers=[2,2,2]) + Transformer(heads=4, layers=2)
   - d_model: 128, dropout: 0.1
   - Classifier: Linear vs Hyperbolic (c_init=1.0, learnable ✅)
   - Projection dim (SSL): 128

   🔬 SSL Contrastive Learning:
   - Loss: NT-Xent (InfoNCE)
   - Temperature: 0.07
   - Negative samples: 2*batch_size - 2

   ✨ 최적화 개선사항:
   - 정규화 버그 수정 (전이 테스트셋)
   - Cosine Annealing + Warmup
   - EMA (Exponential Moving Average)
   - 백본/헤드 분리 학습률 (Fine-tune)
   - 전이-유사 일관성 손실 (Tail-Head Stitch)
   - 증강 강도 최적화 (경계 정보 보존)
   - 학습 가능한 Hyperbolic c
   - 2레벨 전이 시나리오 (Moderate/Strong)
================================================================================


📦 Loading UCI-HAR Dataset...
[OK] train: X(7352, 9, 128), y(7352,)
[OK] test: X(2947, 9, 128), y(2947,)
   - Train samples: 7352
   - Test samples: 2947

================================================================================
    🔬 TRANSITIONAL TEST SETS 생성 (2레벨 강도)
================================================================================
   - [Moderate] STANDING↔SITTING (p=0.50, mix=0.40): 511개 샘플 변형
   - [Moderate] WALKING↔WALKING_UPSTAIRS (p=0.55, mix=0.42): 531개 샘플 변형
   - [Strong] STANDING↔SITTING (p=0.70, mix=0.55): 715개 샘플 변형
   - [Strong] WALKING↔WALKING_UPSTAIRS (p=0.65, mix=0.52): 628개 샘플 변형
   - [Strong] SITTING↔LAYING (p=0.75, mix=0.58): 770개 샘플 변형

================================================================================
   실험: Supervised_Linear
================================================================================

📚 Supervised Learning (With Labels)
--------------------------------------------------------------------------------
Training for 50 epochs...
[Supervised 01/50] Train L:1.2297 CE:1.2297 Cons:0.0000 A:0.5888 | Test A:0.8079 F1:0.8009
[Supervised 10/50] Train L:0.3274 CE:0.3274 Cons:0.0000 A:0.9553 | Test A:0.9287 F1:0.9301
[Supervised 20/50] Train L:0.2990 CE:0.2990 Cons:0.0000 A:0.9690 | Test A:0.9189 F1:0.9196
[Supervised 30/50] Train L:0.2760 CE:0.2760 Cons:0.0000 A:0.9833 | Test A:0.9450 F1:0.9453
[Supervised 40/50] Train L:0.2706 CE:0.2706 Cons:0.0000 A:0.9857 | Test A:0.9440 F1:0.9440
[Supervised 50/50] Train L:0.2610 CE:0.2610 Cons:0.0000 A:0.9913 | Test A:0.9413 F1:0.9411
✅ Best Test Acc: 0.9450

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.5881 F1=0.5101 (Drop=0.3570)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.6101 F1=0.5399 (Drop=0.3349)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.5643 F1=0.4788 (Drop=0.3807)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.6088 F1=0.5392 (Drop=0.3363)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.5843 F1=0.4995 (Drop=0.3607)

================================================================================
   실험: Supervised_Hyperbolic
================================================================================

📚 Supervised Learning (With Labels)
--------------------------------------------------------------------------------
Training for 50 epochs...
[Supervised 01/50] Train L:1.7032 CE:1.7032 Cons:0.0000 A:0.4368 | Test A:0.6169 F1:0.5292
[Supervised 10/50] Train L:0.6728 CE:0.6728 Cons:0.0000 A:0.9563 | Test A:0.9243 F1:0.9255
[Supervised 20/50] Train L:0.4052 CE:0.4052 Cons:0.0000 A:0.9640 | Test A:0.9237 F1:0.9250
[Supervised 30/50] Train L:0.3376 CE:0.3376 Cons:0.0000 A:0.9737 | Test A:0.9345 F1:0.9360
[Supervised 40/50] Train L:0.3073 CE:0.3073 Cons:0.0000 A:0.9826 | Test A:0.9315 F1:0.9331
[Supervised 50/50] Train L:0.2990 CE:0.2990 Cons:0.0000 A:0.9856 | Test A:0.9308 F1:0.9322
✅ Best Test Acc: 0.9372

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.5283 F1=0.4662 (Drop=0.4089)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.5266 F1=0.4568 (Drop=0.4106)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.5056 F1=0.4356 (Drop=0.4316)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.5212 F1=0.4468 (Drop=0.4160)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.5426 F1=0.4834 (Drop=0.3946)

================================================================================
   실험: SSL_LinearEval_Linear
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 5.6494
[Pretrain 010/100] SSL Loss: 2.4570
[Pretrain 020/100] SSL Loss: 1.2836
[Pretrain 030/100] SSL Loss: 1.1030
[Pretrain 040/100] SSL Loss: 1.0725
[Pretrain 050/100] SSL Loss: 0.8030
[Pretrain 060/100] SSL Loss: 0.7131
[Pretrain 070/100] SSL Loss: 0.6814
[Pretrain 080/100] SSL Loss: 0.7931
[Pretrain 090/100] SSL Loss: 0.5313
[Pretrain 100/100] SSL Loss: 0.6155
✅ Pretraining Complete!

📚 Stage 2: LINEAR_EVAL (With Labels)
--------------------------------------------------------------------------------
linear_eval for 50 epochs...
[linear_eval 01/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
[linear_eval 10/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
[linear_eval 20/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
[linear_eval 30/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
[linear_eval 40/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
[linear_eval 50/50] Train L:1.9654 A:0.1283 | Test A:0.1042 F1:0.0872
✅ Best Test Acc: 0.1042

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.1585 F1=0.0848 (Drop=-0.0543)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.1537 F1=0.0818 (Drop=-0.0495)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.1558 F1=0.0816 (Drop=-0.0516)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.1537 F1=0.0818 (Drop=-0.0495)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.1717 F1=0.0895 (Drop=-0.0675)

================================================================================
   실험: SSL_LinearEval_Hyperbolic
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 5.6494
[Pretrain 010/100] SSL Loss: 2.4570
[Pretrain 020/100] SSL Loss: 1.2836
[Pretrain 030/100] SSL Loss: 1.1030
[Pretrain 040/100] SSL Loss: 1.0725
[Pretrain 050/100] SSL Loss: 0.8030
[Pretrain 060/100] SSL Loss: 0.7131
[Pretrain 070/100] SSL Loss: 0.6814
[Pretrain 080/100] SSL Loss: 0.7931
[Pretrain 090/100] SSL Loss: 0.5313
[Pretrain 100/100] SSL Loss: 0.6155
✅ Pretraining Complete!

📚 Stage 2: LINEAR_EVAL (With Labels)
--------------------------------------------------------------------------------
linear_eval for 50 epochs...
[linear_eval 01/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
[linear_eval 10/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
[linear_eval 20/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
[linear_eval 30/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
[linear_eval 40/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
[linear_eval 50/50] Train L:1.7825 A:0.1840 | Test A:0.1958 F1:0.1200
✅ Best Test Acc: 0.1958

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.2158 F1=0.1197 (Drop=-0.0200)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.2073 F1=0.1186 (Drop=-0.0115)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.2257 F1=0.1231 (Drop=-0.0299)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.2073 F1=0.1188 (Drop=-0.0115)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.1771 F1=0.0928 (Drop=0.0187)

================================================================================
   실험: SSL_FineTune_Linear
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 5.6494
[Pretrain 010/100] SSL Loss: 2.4570
[Pretrain 020/100] SSL Loss: 1.2836
[Pretrain 030/100] SSL Loss: 1.1030
[Pretrain 040/100] SSL Loss: 1.0725
[Pretrain 050/100] SSL Loss: 0.8030
[Pretrain 060/100] SSL Loss: 0.7131
[Pretrain 070/100] SSL Loss: 0.6814
[Pretrain 080/100] SSL Loss: 0.7931
[Pretrain 090/100] SSL Loss: 0.5313
[Pretrain 100/100] SSL Loss: 0.6155
✅ Pretraining Complete!

📚 Stage 2: FINETUNE (With Labels)
--------------------------------------------------------------------------------
finetune for 50 epochs...
[finetune 01/50] Train L:1.8951 CE:1.8951 Cons:0.0000 A:0.1547 | Test A:0.1938 F1:0.1657
[finetune 10/50] Train L:0.3126 CE:0.3126 Cons:0.0000 A:0.9657 | Test A:0.9620 F1:0.9628
[finetune 20/50] Train L:0.2725 CE:0.2725 Cons:0.0000 A:0.9868 | Test A:0.9746 F1:0.9749
[finetune 30/50] Train L:0.2616 CE:0.2616 Cons:0.0000 A:0.9920 | Test A:0.9762 F1:0.9764
[finetune 40/50] Train L:0.2564 CE:0.2564 Cons:0.0000 A:0.9940 | Test A:0.9762 F1:0.9764
[finetune 50/50] Train L:0.2537 CE:0.2537 Cons:0.0000 A:0.9954 | Test A:0.9776 F1:0.9778
✅ Best Test Acc: 0.9790

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.6067 F1=0.5582 (Drop=0.3722)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.5962 F1=0.5500 (Drop=0.3828)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.5799 F1=0.5192 (Drop=0.3990)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.5687 F1=0.5191 (Drop=0.4102)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.6006 F1=0.5428 (Drop=0.3784)

================================================================================
   실험: SSL_FineTune_Hyperbolic
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 5.6494
[Pretrain 010/100] SSL Loss: 2.4570
[Pretrain 020/100] SSL Loss: 1.2836
[Pretrain 030/100] SSL Loss: 1.1030
[Pretrain 040/100] SSL Loss: 1.0725
[Pretrain 050/100] SSL Loss: 0.8030
[Pretrain 060/100] SSL Loss: 0.7131
[Pretrain 070/100] SSL Loss: 0.6814
[Pretrain 080/100] SSL Loss: 0.7931
[Pretrain 090/100] SSL Loss: 0.5313
[Pretrain 100/100] SSL Loss: 0.6155
✅ Pretraining Complete!

📚 Stage 2: FINETUNE (With Labels)
--------------------------------------------------------------------------------
finetune for 50 epochs...
[finetune 01/50] Train L:1.7696 CE:1.7696 Cons:0.0000 A:0.2134 | Test A:0.2939 F1:0.2111
[finetune 10/50] Train L:0.6495 CE:0.6495 Cons:0.0000 A:0.9599 | Test A:0.9315 F1:0.9317
[finetune 20/50] Train L:0.3744 CE:0.3744 Cons:0.0000 A:0.9829 | Test A:0.9606 F1:0.9606
[finetune 30/50] Train L:0.3138 CE:0.3138 Cons:0.0000 A:0.9886 | Test A:0.9671 F1:0.9669
[finetune 40/50] Train L:0.2908 CE:0.2908 Cons:0.0000 A:0.9928 | Test A:0.9661 F1:0.9658
[finetune 50/50] Train L:0.2844 CE:0.2844 Cons:0.0000 A:0.9956 | Test A:0.9650 F1:0.9648
✅ Best Test Acc: 0.9684

   🔍 전이 테스트셋 평가...
     - [Moderate] Scenario 1 (STANDING↔SITTING): Acc=0.5477 F1=0.4624 (Drop=0.4208)
     - [Moderate] Scenario 2 (WALKING↔WALKING_UPSTAIRS): Acc=0.5490 F1=0.4696 (Drop=0.4194)
     - [Strong] Scenario 3 (STANDING↔SITTING): Acc=0.5273 F1=0.4317 (Drop=0.4411)
     - [Strong] Scenario 4 (WALKING↔WALKING_UPSTAIRS): Acc=0.5300 F1=0.4537 (Drop=0.4384)
     - [Strong] Scenario 5 (SITTING↔LAYING): Acc=0.5304 F1=0.4375 (Drop=0.4381)

================================================================================
   📊 SUPERVISED vs TRUE SSL 실험 결과 (최적화 버전)
================================================================================
Config                              Method       Mode         Classifier   Orig Acc   Trans Acc   Drop       Retention 
-------------------------------------------------------------------------------------------------------------------
Supervised_Linear                   supervised   supervised   Linear       0.9450     0.5911      0.3539  62.55%
Supervised_Hyperbolic               supervised   supervised   Hyperbolic   0.9372     0.5249      0.4124  56.00%
SSL_LinearEval_Linear               ssl          linear_eval  Linear       0.1042     0.1587      -0.0545  152.31%
SSL_LinearEval_Hyperbolic           ssl          linear_eval  Hyperbolic   0.1958     0.2067      -0.0109  105.55%
SSL_FineTune_Linear                 ssl          finetune     Linear       0.9790     0.5904      0.3885  60.31%
SSL_FineTune_Hyperbolic             ssl          finetune     Hyperbolic   0.9684     0.5369      0.4316  55.44%

================================================================================
📊 레벨별 Retention 분석
================================================================================
Config                              Overall      Moderate     Strong      
--------------------------------------------------------------------------------
Supervised_Linear                    62.55%       63.39%        61.99%
Supervised_Hyperbolic                56.00%       56.28%        55.82%
SSL_LinearEval_Linear               152.31%      149.84%       153.96%
SSL_LinearEval_Hyperbolic           105.55%      108.06%       103.87%
SSL_FineTune_Linear                  60.31%       61.44%        59.56%
SSL_FineTune_Hyperbolic              55.44%       56.62%        54.65%

================================================================================
📊 상세 비교 분석
================================================================================

🏆 최종 성능 랭킹 (Overall Retention 기준)
--------------------------------------------------------------------------------
   1. SSL_LinearEval_Linear               (ssl-linear_eval     ) Retention: 152.31% (Mod: 149.84% | Str: 153.96%)
   2. SSL_LinearEval_Hyperbolic           (ssl-linear_eval     ) Retention: 105.55% (Mod: 108.06% | Str: 103.87%)
   3. Supervised_Linear                   (supervised          ) Retention: 62.55% (Mod: 63.39% | Str: 61.99%)
   4. SSL_FineTune_Linear                 (ssl-finetune        ) Retention: 60.31% (Mod: 61.44% | Str: 59.56%)
   5. Supervised_Hyperbolic               (supervised          ) Retention: 56.00% (Mod: 56.28% | Str: 55.82%)
   6. SSL_FineTune_Hyperbolic             (ssl-finetune        ) Retention: 55.44% (Mod: 56.62% | Str: 54.65%)

================================================================================
🎯 결론
================================================================================
   - 최고 성능: SSL_LinearEval_Linear (Retention: 152.31%)
   - Supervised baseline: 62.55% (Mod: 63.39% | Str: 61.99%)
   - SSL best: 152.31% (Mod: 149.84% | Str: 153.96%)
   - Performance gap: 89.76pp

   ✨ 최적화 개선사항:
   - 정규화 버그 수정 ✅
   - Cosine + Warmup 스케줄러 ✅
   - EMA (Exponential Moving Average) ✅
   - 백본/헤드 분리 학습률 (Fine-tune) ✅
   - 전이-유사 일관성 손실 (Tail-Head Stitch) ✅
   - 증강 강도 최적화 (warp: 0.10, cutout: 0.10) ✅
   - 학습 가능한 Hyperbolic c ✅
   - 2레벨 전이 시나리오 (Moderate/Strong) ✅