{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7340188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# 0. 재현성 / 유틸\n",
    "# =================================================================================\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    재현성 확보: Python, NumPy, PyTorch 모두 시드 고정\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader의 worker마다 난수 고정\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae708afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1. 데이터셋 (PAMAP2) - 36 채널\n",
    "# =================================================================================\n",
    "class PAMAP2Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    PAMAP2 데이터셋 로더 (36 채널 사용)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, window_size=500, stride=250):\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # 36 전체 센서 채널 사용 ---\n",
    "        feature_columns = [\n",
    "            'handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
    "            'handAcc6_1', 'handAcc6_2', 'handAcc6_3',\n",
    "            'handGyro1', 'handGyro2', 'handGyro3',\n",
    "            'handMagne1', 'handMagne2', 'handMagne3',\n",
    "            'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
    "            'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3',\n",
    "            'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
    "            'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
    "            'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3',\n",
    "            'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3',\n",
    "            'ankleGyro1', 'ankleGyro2', 'ankleGyro3',\n",
    "            'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
    "        ]\n",
    "        label_column = 'activityID'\n",
    "        \n",
    "        print(f\"Loading PAMAP2 data from: {data_path}\")\n",
    "        \n",
    "        # CSV 파일을 쉼표 구분자로 읽기\n",
    "        full_df = pd.read_csv(data_path, sep=',')\n",
    "        \n",
    "        # 필요한 피처와 레이블 컬럼만 선택\n",
    "        df = full_df[[label_column] + feature_columns]\n",
    "        \n",
    "        # 누락된 값(NaN)을 선형 보간\n",
    "        df.interpolate(inplace=True)\n",
    "        \n",
    "        # transient activity (레이블 0) 제외\n",
    "        df = df[df['activityID'] != 0].copy()\n",
    "        \n",
    "        # 12개의 주요 활동만 사용\n",
    "        valid_labels = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        df = df[df['activityID'].isin(valid_labels)].copy()\n",
    "        \n",
    "        # 레이블을 0~11 범위로 재매핑\n",
    "        label_mapping = {old_label: new_label for new_label, old_label in enumerate(valid_labels)}\n",
    "        df.loc[:, 'label'] = df['activityID'].map(label_mapping)\n",
    "        \n",
    "        X_df = df[feature_columns]\n",
    "        y_series = df['label']\n",
    "        \n",
    "        self.X, self.y = self._create_windows(X_df, y_series)\n",
    "\n",
    "        print(f\"Loaded PAMAP2 data: X shape={self.X.shape}, y shape={self.y.shape}\")\n",
    "\n",
    "    # 이하 _create_windows, __len__, __getitem__ 메소드는 이전과 동일합니다.\n",
    "    def _create_windows(self, X_df, y_series):\n",
    "        windows = []\n",
    "        labels = []\n",
    "        \n",
    "        start = 0\n",
    "        while start + self.window_size <= len(X_df):\n",
    "            end = start + self.window_size\n",
    "            \n",
    "            window_X = X_df.iloc[start:end].values\n",
    "            window_y = y_series.iloc[end-1] \n",
    "            \n",
    "            windows.append(window_X.T)\n",
    "            labels.append(window_y)\n",
    "            \n",
    "            start += self.stride\n",
    "            \n",
    "        return np.array(windows, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c9182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2. CBAM (1D 버전)\n",
    "# =================================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = self.avg_pool(x).squeeze(-1)  # (B, C)\n",
    "        max_out = self.max_pool(x).squeeze(-1)  # (B, C)\n",
    "\n",
    "        avg_out = self.fc(avg_out)\n",
    "        max_out = self.fc(max_out)\n",
    "\n",
    "        out = (avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        scale = self.sigmoid(out)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.conv(out)                        # (B, 1, T)\n",
    "        out = self.sigmoid(out)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f56fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =================================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    각 클래스의 prototype과 feature를 InfoNCE 방식으로 밀어붙이는 loss\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, prototypes, labels):\n",
    "        \"\"\"\n",
    "        Contrastive Loss between features and prototypes\n",
    "\n",
    "        Args:\n",
    "            features: (B, D) - 샘플 특징\n",
    "            prototypes: (N_class, D) - 클래스별 프로토타입\n",
    "            labels: (B,) - 레이블\n",
    "\n",
    "        Returns:\n",
    "            loss: contrastive loss\n",
    "        \"\"\"\n",
    "        # L2 normalize\n",
    "        features = F.normalize(features, dim=1)\n",
    "        prototypes = F.normalize(prototypes, dim=1)\n",
    "\n",
    "        # cosine similarity\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature  # (B, num_classes)\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7715cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 4. CrossFormer Block (Cross-Attn between tokens and learnable prototypes)\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 n_prototypes=6,\n",
    "                 n_heads=4,\n",
    "                 mlp_ratio=2.0, \n",
    "                 dropout=0.1,\n",
    "                 initial_prototypes=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\">>> [Main Model] Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "                                 nn.Linear(hidden_dim, dim), nn.Dropout(dropout))\n",
    "        self.proto_proj = nn.Sequential(nn.Linear(dim, dim), nn.GELU(), nn.Linear(dim, dim))\n",
    "\n",
    "    def forward(self, x, return_proto_features=False, skip_cross_attention=False):\n",
    "        B, T, C = x.shape\n",
    "        attn_weights = None\n",
    "\n",
    "        if not skip_cross_attention:\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).expand(B, -1, -1)\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out\n",
    "\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out\n",
    "        x = x + self.mlp(self.norm3(x))\n",
    "\n",
    "        if return_proto_features:\n",
    "            proto_features = x.mean(dim=1)\n",
    "            proto_features = self.proto_proj(proto_features)\n",
    "            return x, proto_features, attn_weights\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d911c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 5. 최종 HAR 모델: embedding + (CBAM) + CrossFormer + classifier\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=9, \n",
    "                 seq_len=500,\n",
    "                 embed_dim=64, \n",
    "                 reduced_dim=32,\n",
    "                 n_classes=6, \n",
    "                 n_prototypes=6, \n",
    "                 n_heads=8,\n",
    "                 kernel_size=7,\n",
    "                 dropout=0.1,\n",
    "                 temperature=0.07, \n",
    "                 initial_prototypes=None,\n",
    "                 use_cbam=True,\n",
    "                 use_crossformer=True,\n",
    "                 use_contrast=True,\n",
    "                 use_dim_reduction=False):\n",
    "        super().__init__()\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, embed_dim, kernel_size=kernel_size, padding=(kernel_size - 1) // 2),\n",
    "            nn.BatchNorm1d(embed_dim), nn.GELU(), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(embed_dim, reduction=8, kernel_size=kernel_size)\n",
    "\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim, n_prototypes=n_prototypes, n_heads=n_heads,\n",
    "                mlp_ratio=2.0, dropout=dropout, initial_prototypes=initial_prototypes\n",
    "            )\n",
    "        else:\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim, nhead=n_heads, dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout, batch_first=True\n",
    "            )\n",
    "\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "        \n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "    def forward(self, x, labels=None, return_contrast_loss=False):\n",
    "        x = self.embedding(x)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "        \n",
    "        proto_features = None\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, _ = self.crossformer(x, return_proto_features=True)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "            \n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "            \n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_contrast_loss and self.use_contrast and proto_features is not None and labels is not None:\n",
    "            contrast_loss = self.contrast_loss(proto_features, self.crossformer.prototypes, labels)\n",
    "            return logits, contrast_loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 6. 프로토타입 초기화: train data 평균 feature로 클래스별 prototype 만들기\n",
    "# =================================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, config):\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=config['in_channels'],\n",
    "        embed_dim=config['embed_dim'],\n",
    "        reduced_dim=config['reduced_dim'], \n",
    "        n_heads=config['n_heads'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout'],\n",
    "        n_classes=config['n_classes'],\n",
    "        n_prototypes=config['n_prototypes'],\n",
    "        use_cbam=True,\n",
    "        use_crossformer=True, \n",
    "        use_contrast=False,\n",
    "        use_dim_reduction=config['use_dim_reduction']\n",
    "    ).to(device)\n",
    "\n",
    "    temp_model.eval()\n",
    "\n",
    "    temp_loader = DataLoader(train_full_dataset, batch_size=config['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    all_features, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device)\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "            x = temp_model.crossformer(x, skip_cross_attention=True)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1)\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    working_dim = config['reduced_dim'] if config['use_dim_reduction'] else config['embed_dim']\n",
    "    mean_prototypes = torch.zeros(config['n_classes'], working_dim)\n",
    "\n",
    "    for i in range(len(mean_prototypes)):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            mean_prototypes[i] = torch.randn(working_dim)\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "    \n",
    "    return mean_prototypes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada2ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 7. 학습/평가 루프\n",
    "# =================================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_contrast=True, contrast_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    total_contrast_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss + contrast_weight * contrast_loss\n",
    "            total_contrast_loss += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    torch.cuda.synchronize() # 한 에폭 끝에서 동기화\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    avg_contrast_loss = total_contrast_loss / len(dataloader) if total_contrast_loss > 0 else 0\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e48bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 8. 시각화 + 리포트 (cm, t-SNE 등)\n",
    "# =================================================================================\n",
    "\n",
    "# 라벨 이름 (index 0~5가 이 순서라고 가정)\n",
    "ACTIVITY_LABELS = [\n",
    "    'Standing still',       # 1\n",
    "    'Sitting and relaxing', # 2\n",
    "    'Lying down',           # 3\n",
    "    'Walking',              # 4\n",
    "    'Climbing stairs',      # 5\n",
    "    'Waist bends forward',  # 6\n",
    "    'Frontal elevation of arms', # 7\n",
    "    'Knees bending (crouching)', # 8\n",
    "    'Cycling',              # 9\n",
    "    'Jogging',              # 10\n",
    "    'Running',              # 11\n",
    "    'Jump front and back'   # 12\n",
    "]\n",
    "\n",
    "\n",
    "def plot_classification_results(y_true, y_pred, save_path=None):\n",
    "    \"\"\"\n",
    "    Confusion Matrix 시각화 (+ 선택적으로 파일 저장)\n",
    "    \"\"\"\n",
    "    # 1. Classification Report 출력\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_true, y_pred, target_names=ACTIVITY_LABELS, digits=4))\n",
    "\n",
    "    # 2. 정규화된 Confusion Matrix 계산 및 시각화\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Normalized Confusion Matrix\")\n",
    "    print(\"=\"*80)\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=ACTIVITY_LABELS, yticklabels=ACTIVITY_LABELS)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('')\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] Confusion matrix → {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_tsne(model, dataloader, device, save_path=None):\n",
    "    \"\"\"\n",
    "    모델의 마지막 특징(분류 직전 표현)을 t-SNE로 2D 투영해서 그린다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating t-SNE visualization (MODEL FEATURE)...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(dataloader, desc=\"Extracting features for t-SNE\"):\n",
    "            xb = xb.to(device)\n",
    "\n",
    "            # 모델 내부에서 classifier 직전 feature까지 따라가기\n",
    "            # (아래 로직은 네 notebook의 visualize_tsne() 구조 복원)\n",
    "            x = model.embedding(xb)\n",
    "            if model.use_cbam:\n",
    "                x = model.cbam(x)\n",
    "            x = x.transpose(1, 2)\n",
    "            if model.use_dim_reduction:\n",
    "                x = model.dim_reduce(x)\n",
    "            # backbone\n",
    "            if model.use_crossformer:\n",
    "                x = model.crossformer(\n",
    "                    x,\n",
    "                    return_proto_features=False,\n",
    "                    skip_cross_attention=False\n",
    "                )\n",
    "            else:\n",
    "                x = model.self_attn_layer(x)\n",
    "\n",
    "            if model.use_dim_reduction:\n",
    "                x = model.dim_restore(x)\n",
    "            # GAP을 흉내내기 위한 mean pooling over seq\n",
    "            pooled_features = x.mean(dim=1)  # (B, D_working)\n",
    "            all_features.append(pooled_features.cpu().numpy())\n",
    "            all_labels.append(yb.cpu().numpy())\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        perplexity=20,\n",
    "        max_iter=2000,\n",
    "        init='pca',\n",
    "        learning_rate='auto'\n",
    "    )\n",
    "    proj = tsne.fit_transform(all_features)  # (N, 2)\n",
    "\n",
    "    df = pd.DataFrame(proj, columns=['Dim1', 'Dim2'])\n",
    "    df['label'] = [ACTIVITY_LABELS[l] for l in all_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.scatterplot(\n",
    "        data=df,\n",
    "        x='Dim1',\n",
    "        y='Dim2',\n",
    "        hue='label',\n",
    "        palette=sns.color_palette(\"hsv\", n_colors=len(ACTIVITY_LABELS)),\n",
    "        legend=\"full\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.title('t-SNE of embeddings extracted by the model', fontsize=10)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.legend(title='Activity', loc='upper right', fontsize=6, title_fontsize=7, labelspacing=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] t-SNE (feature space) → {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_tsne_raw(dataloader, device, save_path=None, max_points=2000):\n",
    "    \"\"\"\n",
    "    모델을 거치기 전의 raw window (9채널 x 128길이)를\n",
    "    그냥 flatten해서 t-SNE로 투영.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating t-SNE visualization (RAW INPUT)...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    all_raw = []\n",
    "    all_labels = []\n",
    "\n",
    "    for xb, yb in tqdm(dataloader, desc=\"Collecting raw windows for t-SNE\"):\n",
    "        all_raw.append(xb.cpu().numpy())     # (B, C, T)\n",
    "        all_labels.append(yb.cpu().numpy())  # (B,)\n",
    "\n",
    "    all_raw = np.concatenate(all_raw, axis=0)       # (N, C, T)\n",
    "    all_labels = np.concatenate(all_labels, axis=0) # (N,)\n",
    "\n",
    "    N = all_raw.shape[0]\n",
    "    idx = np.arange(N)\n",
    "    if N > max_points:\n",
    "        idx = np.random.choice(N, size=max_points, replace=False)\n",
    "\n",
    "    X_sel = all_raw[idx]      # (M, C, T)\n",
    "    y_sel = all_labels[idx]   # (M,)\n",
    "\n",
    "    X_flat = X_sel.reshape(X_sel.shape[0], -1)  # (M, C*T)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        perplexity=20,\n",
    "        max_iter=2000,\n",
    "        init='pca',\n",
    "        learning_rate='auto'\n",
    "    )\n",
    "    proj = tsne.fit_transform(X_flat)\n",
    "\n",
    "    df = pd.DataFrame(proj, columns=['Dim1', 'Dim2'])\n",
    "    df['label'] = [ACTIVITY_LABELS[l] for l in y_sel]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.scatterplot(\n",
    "        data=df,\n",
    "        x='Dim1',\n",
    "        y='Dim2',\n",
    "        hue='label',\n",
    "        palette=sns.color_palette(\"hsv\", n_colors=len(ACTIVITY_LABELS)),\n",
    "        legend=\"full\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.title('t-SNE of raw data before model processing', fontsize=10)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.legend(title='Activity', loc='upper right', fontsize=6, title_fontsize=7, labelspacing=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] t-SNE (raw input) → {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f770ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 9. 모델 프로파일링: Param(M), FLOPs(M), Inference Time(ms)\n",
    "# =================================================================================\n",
    "def profile_model(model, sample_input, device, warmup=10, iters=50):\n",
    "    \"\"\"\n",
    "    모델 구조/비용 측정:\n",
    "    - 파라미터 수 (M)\n",
    "    - FLOPs per sample (M)\n",
    "    - 추론 시간 평균(ms)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # params\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    params_m = total_params / 1e6\n",
    "\n",
    "    # FLOPs\n",
    "    with torch.no_grad():\n",
    "        flops = FlopCountAnalysis(model, (sample_input.to(device),))\n",
    "        flops_m = flops.total() / 1e6  # million FLOPs\n",
    "\n",
    "    # inference time\n",
    "    with torch.no_grad():\n",
    "        # 워밍업: GPU/CPU 캐시 안정화\n",
    "        for _ in range(warmup):\n",
    "            _ = model(sample_input.to(device))\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "    avg_sec = (end - start) / iters\n",
    "    inference_ms = avg_sec * 1000.0\n",
    "\n",
    "    return {\n",
    "        \"params_m\": params_m,\n",
    "        \"flops_m\": flops_m,\n",
    "        \"inference_ms\": inference_ms,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_model_profile(stats_dict):\n",
    "    print(\"==== Model Profile ====\")\n",
    "    print(f\"Parameters      : {stats_dict['params_m']:.4f} M\")\n",
    "    print(f\"FLOPs / sample : {stats_dict['flops_m']:.3f} M\")\n",
    "    print(f\"Infer Time     : {stats_dict['inference_ms']:.2f} ms/sample\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading PAMAP2 Dataset from: C://Users/park9/CBAM_HAR/PAMAP2/pamap.csv\n",
      "Loading PAMAP2 data from: C://Users/park9/CBAM_HAR/PAMAP2/pamap.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\park9\\AppData\\Local\\Temp\\ipykernel_2384\\4098539008.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.interpolate(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PAMAP2 data: X shape=(7770, 36, 500), y shape=(7770,)\n",
      "Train: 4662, Validation: 1554, Test: 1554\n",
      "Calculating initial prototypes from mean features...\n",
      ">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 37/37 [00:01<00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([12, 64])\n",
      "\n",
      "================================================================================\n",
      "Training with config: {'DATA_FILE': 'C://Users/park9/CBAM_HAR/PAMAP2/pamap.csv', 'BATCH_SIZE': 128, 'EPOCHS': 100, 'SEED': 42, 'LEARNING_RATE': 0.0005, 'WEIGHT_DECAY': 0.0001, 'embed_dim': 64, 'reduced_dim': 32, 'n_heads': 8, 'kernel_size': 7, 'dropout': 0.1, 'in_channels': 36, 'n_classes': 12, 'n_prototypes': 12, 'use_cbam': True, 'use_crossformer': True, 'use_contrast': True, 'use_dim_reduction': False, 'temperature': 0.05, 'contrast_weight': 0.25}\n",
      "================================================================================\n",
      ">>> [Main Model] Prototypes initialized with calculated mean features.\n",
      "Parameters: 81,626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [010/100] TrainLoss=0.1459 TrainAcc=0.9683 ValAcc=0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [020/100] TrainLoss=0.0684 TrainAcc=0.9848 ValAcc=0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [030/100] TrainLoss=0.0381 TrainAcc=0.9910 ValAcc=0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [040/100] TrainLoss=0.0202 TrainAcc=0.9955 ValAcc=0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  32%|███▏      | 12/37 [00:01<00:02, 10.85it/s]"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# 10. 메인 실행\n",
    "# =====================================================================\n",
    "def main():\n",
    "    # -----------------------------\n",
    "    # 실험 설정 모음\n",
    "    # -----------------------------\n",
    "    config = {\n",
    "        # 데이터/학습\n",
    "        'DATA_FILE': 'C://Users/park9/CBAM_HAR/PAMAP2/pamap.csv',\n",
    "        'BATCH_SIZE': 128,\n",
    "        'EPOCHS': 100,\n",
    "        'SEED': 42,\n",
    "        'LEARNING_RATE': 5e-4,\n",
    "        'WEIGHT_DECAY': 1e-4,\n",
    "\n",
    "        # 모델 구조 (너 노트 기준)\n",
    "        'embed_dim': 64,\n",
    "        'reduced_dim': 32,\n",
    "        'n_heads': 8,\n",
    "        'kernel_size': 7,\n",
    "        'dropout': 0.1,\n",
    "\n",
    "        # !!! 데이터셋에 맞게 수정 !!!\n",
    "        'in_channels': 36,       # 채널 수\n",
    "        'n_classes': 12,        # 클래스 수 (Null 제외)\n",
    "        'n_prototypes': 12,     # n_classes와 동일하게 설정\n",
    "\n",
    "        # 구성 스위치\n",
    "        'use_cbam': True,\n",
    "        'use_crossformer': True,\n",
    "        'use_contrast': True,\n",
    "        'use_dim_reduction': False,\n",
    "\n",
    "        # Loss 관련\n",
    "        'temperature': 0.05,\n",
    "        'contrast_weight': 0.25,\n",
    "    }\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    seed_everything(config['SEED'])\n",
    "\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading PAMAP2 Dataset from: {config['DATA_FILE']}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 데이터셋 준비 / split\n",
    "    # -----------------------------\n",
    "    # 1. 정규화 없는 Dataset 클래스로 전체 윈도우 데이터 로드\n",
    "    full_dataset = PAMAP2Dataset(config['DATA_FILE'], window_size=500, stride=250)\n",
    "    X_all, y_all = full_dataset.X, full_dataset.y\n",
    "    \n",
    "    # 2. Train / Val / Test 데이터 분할\n",
    "    X_flat = X_all.reshape(X_all.shape[0], -1) # 분할을 위해 잠시 2D로 변경\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_flat, y_all, test_size=0.4, random_state=config['SEED'], stratify=y_all)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=config['SEED'], stratify=y_temp)\n",
    "\n",
    "    # 3. 표준화 (Train 세트 기준으로 fit)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 4. 원래 모양 (N, C, T)으로 복원\n",
    "    C, T = X_all.shape[1], X_all.shape[2]\n",
    "    X_train = X_train_scaled.reshape(-1, C, T)\n",
    "    X_val = X_val_scaled.reshape(-1, C, T)\n",
    "    X_test = X_test_scaled.reshape(-1, C, T)\n",
    "\n",
    "    # 5. PyTorch TensorDataset으로 변환\n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "    val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "    \n",
    "    train_full_dataset_for_proto = train_dataset\n",
    "    \n",
    "    print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    g = torch.Generator().manual_seed(config['SEED'])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 프로토타입 초기화\n",
    "    # -----------------------------\n",
    "    initial_prototypes = get_mean_prototypes(train_full_dataset_for_proto, DEVICE, config)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training with config: {config}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 모델 생성\n",
    "    # -----------------------------\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=config['in_channels'],\n",
    "        seq_len=500,\n",
    "        n_classes=config['n_classes'],\n",
    "        n_prototypes=config['n_prototypes'],\n",
    "        embed_dim=config['embed_dim'],\n",
    "        reduced_dim=config['reduced_dim'],\n",
    "        n_heads=config['n_heads'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout'],\n",
    "        temperature=config['temperature'],\n",
    "        initial_prototypes=initial_prototypes,\n",
    "        use_cbam=config['use_cbam'],\n",
    "        use_crossformer=config['use_crossformer'],\n",
    "        use_contrast=config['use_contrast'],\n",
    "        use_dim_reduction=config['use_dim_reduction']\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # optimizer / scheduler / criterion\n",
    "    # -----------------------------\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['LEARNING_RATE'],\n",
    "        weight_decay=config['WEIGHT_DECAY']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config['EPOCHS']\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 학습 루프\n",
    "    # -----------------------------\n",
    "    history = []\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        train_results = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            DEVICE,\n",
    "            use_contrast=config['use_contrast'],\n",
    "            contrast_weight=config['contrast_weight']\n",
    "        )\n",
    "        val_results = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss, train_ce, train_contrast, train_acc, train_f1 = train_results\n",
    "        val_loss, val_acc, val_f1, _, _ = val_results\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_f1': train_f1,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "        })\n",
    "\n",
    "        # best ckpt 추적\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1:03d}/{config['EPOCHS']:03d}] \"\n",
    "                f\"TrainLoss={train_loss:.4f} \"\n",
    "                f\"TrainAcc={train_acc:.4f} \"\n",
    "                f\"ValAcc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 최종 테스트 (best 상태로)\n",
    "    # -----------------------------\n",
    "    assert best_state is not None, \"best_state is None (no epochs?)\"\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "        model, test_loader, criterion, DEVICE\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ Training Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(f\"  Final Test (Best-VAL ckpt): Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 시각화 + 저장\n",
    "    # -----------------------------\n",
    "    plot_classification_results(\n",
    "        test_labels,\n",
    "        test_preds,\n",
    "        save_path=\"confusion_matrix.png\"\n",
    "    )\n",
    "\n",
    "    visualize_tsne(\n",
    "        model,\n",
    "        test_loader,\n",
    "        DEVICE,\n",
    "        save_path=\"tsne_feature.png\"\n",
    "    )\n",
    "\n",
    "    visualize_tsne_raw(\n",
    "        test_loader,\n",
    "        DEVICE,\n",
    "        save_path=\"tsne_raw.png\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 모델 프로파일링\n",
    "    # -----------------------------\n",
    "    dummy_input = torch.randn(1, config['in_channels'], 128)  # (B=1, C=12, T=128)\n",
    "    stats = profile_model(model, dummy_input, DEVICE)\n",
    "    print_model_profile(stats)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL PROCESSES COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
