{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a4f79d",
   "metadata": {},
   "source": [
    "`Prototype 초기화 방식 변경, temparture 변경, contrastive_weight 변경, Batch_size 변경, use_dim_reduction 변경`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca1099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading UCI HAR Dataset from: C://Users/park9/CBAM_HAR/data\n",
      "Loaded train data: X shape=(7352, 9, 128), y shape=(7352,)\n",
      "Loaded test data: X shape=(2947, 9, 128), y shape=(2947,)\n",
      "Train: 5881, Validation: 1471, Test: 2947\n",
      "Calculating initial prototypes from mean features...\n",
      ">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 58/58 [00:00<00:00, 123.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([6, 64])\n",
      "\n",
      "================================================================================\n",
      "Training: + CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\n",
      "Config: {'use_cbam': True, 'use_crossformer': True, 'use_contrast': True, 'use_dim_reduction': True}\n",
      "================================================================================\n",
      ">>> [Main Model] Prototypes initialized with calculated mean features.\n",
      "Parameters: 114,596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] train: loss=1.2208, ce=0.9527, ct=1.0723, acc=0.6332, f1=0.6109 | val: loss=0.4325, acc=0.8776, f1=0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/100] train: loss=0.4503, ce=0.2774, ct=0.6918, acc=0.8922, f1=0.8920 | val: loss=0.2615, acc=0.8878, f1=0.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/100] train: loss=0.2510, ce=0.1462, ct=0.4194, acc=0.9395, f1=0.9393 | val: loss=0.1056, acc=0.9456, f1=0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/100] train: loss=0.1992, ce=0.1300, ct=0.2766, acc=0.9478, f1=0.9477 | val: loss=0.1268, acc=0.9551, f1=0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/100] train: loss=0.1745, ce=0.1224, ct=0.2086, acc=0.9490, f1=0.9489 | val: loss=0.1115, acc=0.9483, f1=0.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/100] train: loss=0.1683, ce=0.1231, ct=0.1808, acc=0.9469, f1=0.9468 | val: loss=0.1186, acc=0.9599, f1=0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007/100] train: loss=0.1598, ce=0.1192, ct=0.1627, acc=0.9475, f1=0.9474 | val: loss=0.0996, acc=0.9504, f1=0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008/100] train: loss=0.1557, ce=0.1181, ct=0.1504, acc=0.9498, f1=0.9498 | val: loss=0.1041, acc=0.9619, f1=0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009/100] train: loss=0.1545, ce=0.1185, ct=0.1442, acc=0.9488, f1=0.9487 | val: loss=0.1077, acc=0.9606, f1=0.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/100] train: loss=0.1542, ce=0.1192, ct=0.1399, acc=0.9502, f1=0.9501 | val: loss=0.0954, acc=0.9538, f1=0.9535\n",
      "  Epoch [10/100] Loss: 0.1542 (CE: 0.1192, CT: 0.1399) | Val Acc: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011/100] train: loss=0.1456, ce=0.1129, ct=0.1305, acc=0.9515, f1=0.9515 | val: loss=0.0966, acc=0.9551, f1=0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012/100] train: loss=0.1545, ce=0.1203, ct=0.1367, acc=0.9471, f1=0.9470 | val: loss=0.1079, acc=0.9613, f1=0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013/100] train: loss=0.1420, ce=0.1109, ct=0.1244, acc=0.9529, f1=0.9529 | val: loss=0.0932, acc=0.9551, f1=0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014/100] train: loss=0.1355, ce=0.1059, ct=0.1185, acc=0.9563, f1=0.9563 | val: loss=0.1023, acc=0.9585, f1=0.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015/100] train: loss=0.1328, ce=0.1037, ct=0.1163, acc=0.9565, f1=0.9565 | val: loss=0.1109, acc=0.9483, f1=0.9472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016/100] train: loss=0.1340, ce=0.1048, ct=0.1166, acc=0.9556, f1=0.9556 | val: loss=0.0993, acc=0.9565, f1=0.9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017/100] train: loss=0.1324, ce=0.1044, ct=0.1120, acc=0.9556, f1=0.9556 | val: loss=0.0860, acc=0.9592, f1=0.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018/100] train: loss=0.1239, ce=0.0973, ct=0.1066, acc=0.9587, f1=0.9587 | val: loss=0.0994, acc=0.9585, f1=0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019/100] train: loss=0.1278, ce=0.1007, ct=0.1081, acc=0.9560, f1=0.9559 | val: loss=0.0811, acc=0.9619, f1=0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/100] train: loss=0.1242, ce=0.0977, ct=0.1060, acc=0.9565, f1=0.9565 | val: loss=0.0988, acc=0.9572, f1=0.9569\n",
      "  Epoch [20/100] Loss: 0.1242 (CE: 0.0977, CT: 0.1060) | Val Acc: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021/100] train: loss=0.1189, ce=0.0938, ct=0.1003, acc=0.9611, f1=0.9611 | val: loss=0.0833, acc=0.9606, f1=0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022/100] train: loss=0.1172, ce=0.0924, ct=0.0991, acc=0.9599, f1=0.9599 | val: loss=0.0906, acc=0.9613, f1=0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023/100] train: loss=0.1232, ce=0.0974, ct=0.1031, acc=0.9595, f1=0.9595 | val: loss=0.0818, acc=0.9687, f1=0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024/100] train: loss=0.1175, ce=0.0929, ct=0.0985, acc=0.9629, f1=0.9629 | val: loss=0.0809, acc=0.9680, f1=0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025/100] train: loss=0.1099, ce=0.0868, ct=0.0926, acc=0.9636, f1=0.9636 | val: loss=0.1356, acc=0.9334, f1=0.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026/100] train: loss=0.1156, ce=0.0916, ct=0.0958, acc=0.9628, f1=0.9628 | val: loss=0.0772, acc=0.9660, f1=0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027/100] train: loss=0.1179, ce=0.0936, ct=0.0974, acc=0.9646, f1=0.9646 | val: loss=0.0884, acc=0.9640, f1=0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028/100] train: loss=0.1049, ce=0.0827, ct=0.0888, acc=0.9668, f1=0.9668 | val: loss=0.0811, acc=0.9606, f1=0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029/100] train: loss=0.1053, ce=0.0832, ct=0.0886, acc=0.9660, f1=0.9660 | val: loss=0.0711, acc=0.9735, f1=0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/100] train: loss=0.1081, ce=0.0855, ct=0.0903, acc=0.9634, f1=0.9634 | val: loss=0.0767, acc=0.9735, f1=0.9735\n",
      "  Epoch [30/100] Loss: 0.1081 (CE: 0.0855, CT: 0.0903) | Val Acc: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[031/100] train: loss=0.0963, ce=0.0762, ct=0.0803, acc=0.9714, f1=0.9714 | val: loss=0.0700, acc=0.9769, f1=0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[032/100] train: loss=0.1045, ce=0.0831, ct=0.0858, acc=0.9684, f1=0.9684 | val: loss=0.0849, acc=0.9667, f1=0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[033/100] train: loss=0.0979, ce=0.0777, ct=0.0807, acc=0.9677, f1=0.9677 | val: loss=0.0639, acc=0.9728, f1=0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[034/100] train: loss=0.0916, ce=0.0727, ct=0.0758, acc=0.9708, f1=0.9707 | val: loss=0.1039, acc=0.9572, f1=0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[035/100] train: loss=0.0922, ce=0.0730, ct=0.0769, acc=0.9713, f1=0.9713 | val: loss=0.0688, acc=0.9742, f1=0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[036/100] train: loss=0.0897, ce=0.0713, ct=0.0736, acc=0.9728, f1=0.9728 | val: loss=0.0931, acc=0.9674, f1=0.9674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037/100] train: loss=0.0976, ce=0.0769, ct=0.0830, acc=0.9694, f1=0.9694 | val: loss=0.0926, acc=0.9633, f1=0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[038/100] train: loss=0.0881, ce=0.0702, ct=0.0716, acc=0.9747, f1=0.9747 | val: loss=0.0834, acc=0.9592, f1=0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[039/100] train: loss=0.0821, ce=0.0647, ct=0.0695, acc=0.9743, f1=0.9743 | val: loss=0.1320, acc=0.9497, f1=0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/100] train: loss=0.0800, ce=0.0633, ct=0.0669, acc=0.9740, f1=0.9740 | val: loss=0.1045, acc=0.9504, f1=0.9492\n",
      "  Epoch [40/100] Loss: 0.0800 (CE: 0.0633, CT: 0.0669) | Val Acc: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[041/100] train: loss=0.0682, ce=0.0535, ct=0.0588, acc=0.9796, f1=0.9796 | val: loss=0.0553, acc=0.9782, f1=0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[042/100] train: loss=0.0695, ce=0.0546, ct=0.0594, acc=0.9782, f1=0.9782 | val: loss=0.0811, acc=0.9667, f1=0.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[043/100] train: loss=0.0653, ce=0.0515, ct=0.0551, acc=0.9791, f1=0.9791 | val: loss=0.0548, acc=0.9816, f1=0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[044/100] train: loss=0.0635, ce=0.0500, ct=0.0539, acc=0.9810, f1=0.9809 | val: loss=0.0712, acc=0.9769, f1=0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[045/100] train: loss=0.0760, ce=0.0602, ct=0.0632, acc=0.9757, f1=0.9757 | val: loss=0.0787, acc=0.9735, f1=0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[046/100] train: loss=0.0606, ce=0.0477, ct=0.0518, acc=0.9806, f1=0.9806 | val: loss=0.0594, acc=0.9796, f1=0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[047/100] train: loss=0.0577, ce=0.0457, ct=0.0480, acc=0.9828, f1=0.9828 | val: loss=0.0653, acc=0.9816, f1=0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[048/100] train: loss=0.0581, ce=0.0459, ct=0.0490, acc=0.9830, f1=0.9830 | val: loss=0.0451, acc=0.9830, f1=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[049/100] train: loss=0.0461, ce=0.0362, ct=0.0395, acc=0.9869, f1=0.9869 | val: loss=0.0470, acc=0.9823, f1=0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/100] train: loss=0.0514, ce=0.0405, ct=0.0433, acc=0.9849, f1=0.9849 | val: loss=0.0597, acc=0.9796, f1=0.9796\n",
      "  Epoch [50/100] Loss: 0.0514 (CE: 0.0405, CT: 0.0433) | Val Acc: 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[051/100] train: loss=0.0528, ce=0.0419, ct=0.0435, acc=0.9852, f1=0.9852 | val: loss=0.0591, acc=0.9796, f1=0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[052/100] train: loss=0.0426, ce=0.0337, ct=0.0357, acc=0.9871, f1=0.9871 | val: loss=0.0725, acc=0.9721, f1=0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[053/100] train: loss=0.0377, ce=0.0296, ct=0.0324, acc=0.9895, f1=0.9895 | val: loss=0.0497, acc=0.9837, f1=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[054/100] train: loss=0.0405, ce=0.0319, ct=0.0344, acc=0.9872, f1=0.9873 | val: loss=0.0553, acc=0.9830, f1=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[055/100] train: loss=0.0388, ce=0.0305, ct=0.0330, acc=0.9869, f1=0.9869 | val: loss=0.0487, acc=0.9844, f1=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[056/100] train: loss=0.0328, ce=0.0258, ct=0.0279, acc=0.9898, f1=0.9898 | val: loss=0.0454, acc=0.9830, f1=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[057/100] train: loss=0.0278, ce=0.0218, ct=0.0242, acc=0.9918, f1=0.9918 | val: loss=0.0593, acc=0.9776, f1=0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[058/100] train: loss=0.0337, ce=0.0265, ct=0.0288, acc=0.9886, f1=0.9886 | val: loss=0.0519, acc=0.9850, f1=0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[059/100] train: loss=0.0309, ce=0.0242, ct=0.0266, acc=0.9906, f1=0.9906 | val: loss=0.0607, acc=0.9816, f1=0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[060/100] train: loss=0.0316, ce=0.0245, ct=0.0282, acc=0.9903, f1=0.9903 | val: loss=0.0427, acc=0.9857, f1=0.9857\n",
      "  Epoch [60/100] Loss: 0.0316 (CE: 0.0245, CT: 0.0282) | Val Acc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[061/100] train: loss=0.0317, ce=0.0251, ct=0.0266, acc=0.9903, f1=0.9903 | val: loss=0.0424, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[062/100] train: loss=0.0241, ce=0.0190, ct=0.0204, acc=0.9929, f1=0.9929 | val: loss=0.0525, acc=0.9850, f1=0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[063/100] train: loss=0.0215, ce=0.0168, ct=0.0184, acc=0.9932, f1=0.9932 | val: loss=0.0420, acc=0.9857, f1=0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[064/100] train: loss=0.0291, ce=0.0229, ct=0.0250, acc=0.9910, f1=0.9910 | val: loss=0.0539, acc=0.9844, f1=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[065/100] train: loss=0.0259, ce=0.0204, ct=0.0220, acc=0.9922, f1=0.9922 | val: loss=0.0427, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[066/100] train: loss=0.0231, ce=0.0181, ct=0.0198, acc=0.9929, f1=0.9929 | val: loss=0.0501, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[067/100] train: loss=0.0175, ce=0.0136, ct=0.0156, acc=0.9947, f1=0.9947 | val: loss=0.0490, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[068/100] train: loss=0.0234, ce=0.0183, ct=0.0203, acc=0.9925, f1=0.9925 | val: loss=0.0497, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[069/100] train: loss=0.0204, ce=0.0159, ct=0.0179, acc=0.9942, f1=0.9942 | val: loss=0.0584, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[070/100] train: loss=0.0209, ce=0.0164, ct=0.0179, acc=0.9944, f1=0.9944 | val: loss=0.0490, acc=0.9871, f1=0.9871\n",
      "  Epoch [70/100] Loss: 0.0209 (CE: 0.0164, CT: 0.0179) | Val Acc: 0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[071/100] train: loss=0.0210, ce=0.0164, ct=0.0184, acc=0.9932, f1=0.9932 | val: loss=0.0522, acc=0.9803, f1=0.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[072/100] train: loss=0.0183, ce=0.0143, ct=0.0159, acc=0.9951, f1=0.9951 | val: loss=0.0490, acc=0.9850, f1=0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[073/100] train: loss=0.0233, ce=0.0185, ct=0.0194, acc=0.9939, f1=0.9939 | val: loss=0.0440, acc=0.9878, f1=0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[074/100] train: loss=0.0214, ce=0.0168, ct=0.0184, acc=0.9930, f1=0.9930 | val: loss=0.0469, acc=0.9844, f1=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[075/100] train: loss=0.0179, ce=0.0140, ct=0.0155, acc=0.9956, f1=0.9956 | val: loss=0.0446, acc=0.9878, f1=0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[076/100] train: loss=0.0184, ce=0.0145, ct=0.0159, acc=0.9944, f1=0.9944 | val: loss=0.0450, acc=0.9864, f1=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[077/100] train: loss=0.0202, ce=0.0158, ct=0.0176, acc=0.9940, f1=0.9940 | val: loss=0.0419, acc=0.9864, f1=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[078/100] train: loss=0.0155, ce=0.0120, ct=0.0139, acc=0.9951, f1=0.9951 | val: loss=0.0426, acc=0.9850, f1=0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[079/100] train: loss=0.0124, ce=0.0095, ct=0.0114, acc=0.9969, f1=0.9969 | val: loss=0.0445, acc=0.9878, f1=0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[080/100] train: loss=0.0164, ce=0.0127, ct=0.0149, acc=0.9957, f1=0.9957 | val: loss=0.0412, acc=0.9891, f1=0.9891\n",
      "  Epoch [80/100] Loss: 0.0164 (CE: 0.0127, CT: 0.0149) | Val Acc: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[081/100] train: loss=0.0134, ce=0.0104, ct=0.0119, acc=0.9959, f1=0.9959 | val: loss=0.0439, acc=0.9891, f1=0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[082/100] train: loss=0.0130, ce=0.0101, ct=0.0116, acc=0.9969, f1=0.9969 | val: loss=0.0405, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[083/100] train: loss=0.0126, ce=0.0098, ct=0.0113, acc=0.9964, f1=0.9964 | val: loss=0.0428, acc=0.9864, f1=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[084/100] train: loss=0.0149, ce=0.0116, ct=0.0133, acc=0.9963, f1=0.9963 | val: loss=0.0412, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[085/100] train: loss=0.0121, ce=0.0093, ct=0.0110, acc=0.9961, f1=0.9961 | val: loss=0.0420, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[086/100] train: loss=0.0165, ce=0.0128, ct=0.0151, acc=0.9954, f1=0.9954 | val: loss=0.0407, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[087/100] train: loss=0.0142, ce=0.0109, ct=0.0133, acc=0.9959, f1=0.9959 | val: loss=0.0461, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[088/100] train: loss=0.0143, ce=0.0111, ct=0.0130, acc=0.9952, f1=0.9952 | val: loss=0.0435, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[089/100] train: loss=0.0136, ce=0.0105, ct=0.0124, acc=0.9961, f1=0.9961 | val: loss=0.0450, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[090/100] train: loss=0.0125, ce=0.0096, ct=0.0115, acc=0.9963, f1=0.9963 | val: loss=0.0444, acc=0.9898, f1=0.9898\n",
      "  Epoch [90/100] Loss: 0.0125 (CE: 0.0096, CT: 0.0115) | Val Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[091/100] train: loss=0.0128, ce=0.0100, ct=0.0115, acc=0.9966, f1=0.9966 | val: loss=0.0420, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[092/100] train: loss=0.0138, ce=0.0107, ct=0.0125, acc=0.9952, f1=0.9952 | val: loss=0.0416, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[093/100] train: loss=0.0124, ce=0.0096, ct=0.0115, acc=0.9964, f1=0.9964 | val: loss=0.0413, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[094/100] train: loss=0.0165, ce=0.0129, ct=0.0144, acc=0.9956, f1=0.9956 | val: loss=0.0401, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[095/100] train: loss=0.0127, ce=0.0099, ct=0.0114, acc=0.9966, f1=0.9966 | val: loss=0.0443, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[096/100] train: loss=0.0119, ce=0.0091, ct=0.0111, acc=0.9963, f1=0.9963 | val: loss=0.0418, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[097/100] train: loss=0.0134, ce=0.0104, ct=0.0120, acc=0.9957, f1=0.9957 | val: loss=0.0419, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[098/100] train: loss=0.0104, ce=0.0080, ct=0.0093, acc=0.9964, f1=0.9964 | val: loss=0.0405, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[099/100] train: loss=0.0126, ce=0.0097, ct=0.0117, acc=0.9963, f1=0.9963 | val: loss=0.0426, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/100] train: loss=0.0118, ce=0.0091, ct=0.0108, acc=0.9966, f1=0.9966 | val: loss=0.0412, acc=0.9898, f1=0.9898\n",
      "  Epoch [100/100] Loss: 0.0118 (CE: 0.0091, CT: 0.0108) | Val Acc: 0.9898\n",
      "\n",
      "✓ + CBAM + CrossFormer + Contrast (Full + Mean Proto Init) Complete!\n",
      "  Best Val Acc: 0.9912 @ epoch 93\n",
      "  Final Test (Best-VAL ckpt): Acc=0.9410 | F1=0.9405\n",
      "\n",
      "================================================================================\n",
      "PROCESS COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os, copy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    재현성을 위해 Python, NumPy, PyTorch의 Seed를 고정합니다.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    \n",
    "    # cuDNN 설정 (재현성은 보장되나, 속도가 느려질 수 있음)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader의 worker process를 위한 Seed 설정\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. UCI HAR 데이터 로더\n",
    "# =====================================================================\n",
    "class UCIHARDataset(Dataset):\n",
    "    def __init__(self, data_dir, train=True):\n",
    "        \"\"\"\n",
    "        UCI HAR Dataset 로더\n",
    "        data_dir: UCI HAR Dataset 폴더 경로\n",
    "        train: True면 train 데이터, False면 test 데이터\n",
    "        \"\"\"\n",
    "        subset = 'train' if train else 'test'\n",
    "\n",
    "        # Inertial Signals 로드 (9개 센서)\n",
    "        signals = []\n",
    "        signal_types = [\n",
    "            'body_acc_x', 'body_acc_y', 'body_acc_z',\n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'\n",
    "        ]\n",
    "\n",
    "        for signal in signal_types:\n",
    "            filename = os.path.join(data_dir, subset, 'Inertial Signals',\n",
    "                                f'{signal}_{subset}.txt')\n",
    "            # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "            with open(filename, 'r') as f:\n",
    "                # 2. np.loadtxt에 파일 이름 대신 파일 객체(f)를 전달합니다.\n",
    "                data = np.loadtxt(f)\n",
    "                \n",
    "            signals.append(data)\n",
    "\n",
    "        # (N, 9, 128) 형태로 변환\n",
    "        self.X = np.stack(signals, axis=1)\n",
    "\n",
    "        # 레이블 로드 (1~6 -> 0~5로 변환)\n",
    "        label_file = os.path.join(data_dir, subset, f'y_{subset}.txt')\n",
    "        # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "        with open(label_file, 'r') as f:\n",
    "            # 2. np.loadtxt에 파일 객체(f)를 전달합니다.\n",
    "            self.y = np.loadtxt(f, dtype=np.int32) - 1\n",
    "\n",
    "        print(f\"Loaded {subset} data: X shape={self.X.shape}, y shape={self.y.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. 1D-CBAM (Channel + Temporal Attention)\n",
    "# =====================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = self.fc(self.avg_pool(x).squeeze(-1))  # (B, C)\n",
    "        max_out = self.fc(self.max_pool(x).squeeze(-1))  # (B, C)\n",
    "        out = self.sigmoid(avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.sigmoid(self.conv(out))  # (B, 1, T)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =====================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, prototypes, labels):\n",
    "        \"\"\"\n",
    "        Contrastive Loss between features and prototypes\n",
    "\n",
    "        Args:\n",
    "            features: (B, D) - 샘플 특징\n",
    "            prototypes: (N_class, D) - 클래스별 프로토타입\n",
    "            labels: (B,) - 레이블\n",
    "\n",
    "        Returns:\n",
    "            loss: contrastive loss\n",
    "        \"\"\"\n",
    "        # L2 정규화\n",
    "        features = F.normalize(features, dim=1)\n",
    "        prototypes = F.normalize(prototypes, dim=1)\n",
    "\n",
    "        # 유사도 계산 (B, N_class)\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4. CrossFormer with Contrast Prototypes\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self, dim, n_prototypes=6, n_heads=4, mlp_ratio=2.0, dropout=0.1,\n",
    "                 initial_prototypes=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable prototypes (L2 정규화 적용)\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "\n",
    "        # Xavier 초기화 대신, 전달받은 값으로 초기화 (없으면 Xavier 유지)\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\">>> [Main Model] Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        # Cross-Attention: Input(Q) x Prototypes(K, V)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Self-Attention\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # FFN\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # Prototype projection (contrastive learning용)\n",
    "        self.proto_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_proto_features=False, skip_cross_attention=False):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # 1. Cross-Attention (선택적 실행)\n",
    "        if not skip_cross_attention:\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).repeat(B, 1, 1).contiguous()\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out\n",
    "        else: # Cross-Attention을 건너뛸 경우, attn_weights는 None\n",
    "            attn_weights = None\n",
    "\n",
    "        # 2. Self-Attention\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out\n",
    "\n",
    "        # 3. FFN\n",
    "        x = x + self.mlp(self.norm3(x))\n",
    "\n",
    "        # Prototype features for contrastive loss\n",
    "        if return_proto_features:\n",
    "            # Global average pooling\n",
    "            proto_features = x.mean(dim=1)  # (B, C)\n",
    "            proto_features = self.proto_proj(proto_features)  # projection\n",
    "            return x, proto_features, attn_weights\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5. 메인 모델: CrossFormer + 1D-CBAM + Contrast Prototype\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=9,\n",
    "                 seq_len=128,\n",
    "                 embed_dim=64,\n",
    "                 reduced_dim=32,\n",
    "                 n_classes=6,\n",
    "                 n_prototypes=6,\n",
    "                 n_heads=4,\n",
    "                 dropout=0.1,\n",
    "                 temperature=0.07,\n",
    "                 initial_prototypes=None,\n",
    "                 # Ablation 옵션\n",
    "                 use_cbam=True,\n",
    "                 use_crossformer=True,\n",
    "                 use_contrast=True,\n",
    "                 use_dim_reduction=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        # 1. Input Embedding (1D Conv)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, embed_dim, kernel_size=15, padding=7),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(embed_dim, reduction=8, kernel_size=15)\n",
    "\n",
    "        # 3. 차원 축소 (선택적)\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        # 4. CrossFormer Block (선택적)\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim,\n",
    "                n_prototypes=n_prototypes,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=2.0,\n",
    "                dropout=dropout,\n",
    "                initial_prototypes=initial_prototypes\n",
    "            )\n",
    "        else:\n",
    "            # CrossFormer 없이 Self-Attention만 사용\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "\n",
    "        # 5. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        # 6. Global Pooling + Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "\n",
    "        # 7. Contrastive Loss (선택적)\n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "    def forward(self, x, labels=None, return_contrast_loss=False):\n",
    "        # x: (B, C, T) = (B, 9, 128)\n",
    "\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(x)  # (B, embed_dim, T)\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "\n",
    "        # 3. Reshape for Transformer\n",
    "        x = x.transpose(1, 2).contiguous()  # (B, T, embed_dim)\n",
    "\n",
    "        # 4. 차원 축소 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "\n",
    "        # 5. CrossFormer 또는 Self-Attention\n",
    "        proto_features = None\n",
    "        attn_weights = None\n",
    "\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, attn_weights = self.crossformer(x, return_proto_features=True)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "\n",
    "        # 6. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "\n",
    "        # 7. Pooling + Classification\n",
    "        x = x.transpose(1, 2).contiguous()  # (B, embed_dim, T)\n",
    "        x = self.pool(x).squeeze(-1)  # (B, embed_dim)\n",
    "        logits = self.classifier(x)  # (B, n_classes)\n",
    "\n",
    "        # Contrastive Loss 계산\n",
    "        if return_contrast_loss and self.use_contrast and proto_features is not None and labels is not None:\n",
    "            contrast_loss = self.contrast_loss(\n",
    "                proto_features,\n",
    "                self.crossformer.prototypes,\n",
    "                labels\n",
    "            )\n",
    "            return logits, contrast_loss\n",
    "\n",
    "        return logits\n",
    "\n",
    "# =====================================================================\n",
    "# 6. 평균 프로토타입 계산 함수\n",
    "# =====================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, embed_dim=64, \n",
    "                        reduced_dim=32, batch_size=128, use_dim_reduction=False):\n",
    "    \"\"\"\n",
    "    훈련 데이터셋 전체를 사용하여 클래스별 평균 특징 벡터를 계산합니다.\n",
    "    (Cross-Attention 제외하고 특징 추출)\n",
    "    \"\"\"\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    # 1. 임시 특징 추출 모델 정의 (Embedding ~ Pooling까지만)\n",
    "    #    (주의: 실제 모델 구조와 파라미터(dropout 등) 일치시킬 것)\n",
    "    #    (여기서는 use_dim_reduction=False라고 가정)\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        embed_dim=embed_dim, reduced_dim=reduced_dim, dropout=0.1, # Baseline 값 사용\n",
    "        use_cbam=True, use_crossformer=True, use_contrast=False, # Contrast False로!\n",
    "        use_dim_reduction=use_dim_reduction # 평균 계산 시 차원 축소 안 함\n",
    "    ).to(device)\n",
    "    temp_model.eval() # 평가 모드로 설정\n",
    "\n",
    "    # 2. 전체 훈련 데이터 로더 (섞지 않음)\n",
    "    temp_loader = DataLoader(train_full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 3. 특징 추출 루프\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            # --- 특징 추출 (ContrastCrossFormerCBAM_HAR의 forward 참고) ---\n",
    "            # 1. Embedding\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            # 2. CBAM\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "            # 3. Reshape\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            # 4. 차원 축소 \n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "\n",
    "            # 5. Self-Attention (CrossFormer 없이)\n",
    "            # CrossFormer 블록을 호출하되, cross-attention 건너뛰기 옵션 활성화\n",
    "            x = temp_model.crossformer(x, skip_cross_attention=True)\n",
    "\n",
    "            # 6. 차원 복원 (여기서는 안 함)\n",
    "            # 7. Pooling (Classifier 직전)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1) # (B, embed_dim)\n",
    "            # -----------------------------------------------------------\n",
    "\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # 4. 클래스별 평균 계산\n",
    "    n_classes = temp_model.classifier[-1].out_features # 모델 정의에서 클래스 수 가져오기\n",
    "    # ⬇️ 프로토타입 차원을 working_dim에 맞게 동적으로 설정\n",
    "    working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "    mean_prototypes = torch.zeros(n_classes, working_dim)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            print(f\"Warning: No samples found for class {i} during prototype initialization.\")\n",
    "            # (샘플 없는 경우 랜덤 초기화 또는 0 벡터 사용 등 처리 필요)\n",
    "            mean_prototypes[i] = torch.randn(working_dim) # 임시로 랜덤 사용\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "    return mean_prototypes.to(device) # GPU로 다시 보냄\n",
    "\n",
    "# =====================================================================\n",
    "# 7. 학습 및 평가 (Contrastive Loss 포함)\n",
    "# =====================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_contrast=True, contrast_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    total_contrast_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss + contrast_weight * contrast_loss\n",
    "            total_contrast_loss += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    torch.cuda.synchronize() # 한 에폭 끝에서 동기화\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    avg_contrast_loss = total_contrast_loss / len(dataloader) if total_contrast_loss > 0 else 0\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, acc, f1, all_preds, all_labels\n",
    "\n",
    "# =====================================================================\n",
    "# 8. 메인 실행\n",
    "# =====================================================================\n",
    "def main():\n",
    "    # 하이퍼파라미터\n",
    "    DATA_DIR = 'C://Users/park9/CBAM_HAR/data'\n",
    "    BATCH_SIZE = 128  # 최소 256\n",
    "    EPOCHS = 100  # 100으로 고정 \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SEED = 42\n",
    "    embed_dim = 128\n",
    "    reduced_dim = 64\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading UCI HAR Dataset from: {DATA_DIR}\")\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_full_dataset = UCIHARDataset(DATA_DIR, train=True)\n",
    "    test_dataset = UCIHARDataset(DATA_DIR, train=False)\n",
    "\n",
    "    # Train을 Train/Validation으로 분할 (80:20)\n",
    "    train_size = int(0.8 * len(train_full_dataset))\n",
    "    val_size = len(train_full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_full_dataset, [train_size, val_size],\n",
    "                                               generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              worker_init_fn=seed_worker, generator=g, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            worker_init_fn=seed_worker, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             worker_init_fn=seed_worker, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # Ablation Study 대신, \"Full Model\" 직접 생성 및 훈련/테스트\n",
    "    config_name = \"+ CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\"\n",
    "    config_params = dict(use_cbam=True, use_crossformer=True, use_contrast=True, use_dim_reduction=True)\n",
    "\n",
    "    # 평균 프로토타입 계산 (모델 생성 전)\n",
    "    # (주의: embed_dim=64는 모델 생성 시 사용할 값과 일치해야 함)\n",
    "    initial_prototypes = get_mean_prototypes(train_full_dataset, DEVICE, embed_dim=embed_dim, reduced_dim=reduced_dim,\n",
    "                                             batch_size=BATCH_SIZE, use_dim_reduction=config_params['use_dim_reduction'])\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training: {config_name}\")\n",
    "    print(f\"Config: {config_params}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 모델 생성 시 initial_prototypes 전달\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=9, seq_len=128, embed_dim=embed_dim, reduced_dim=reduced_dim,\n",
    "        n_classes=6, n_prototypes=6, n_heads=4, dropout=0.1, temperature=0.05, # Baseline 값들\n",
    "        initial_prototypes=initial_prototypes, # ⬅️ 계산된 값 전달\n",
    "        **config_params\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4) # Baseline 옵티마이저\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 학습 루프 (기존 run_ablation_study 내부 로직과 유사하게)\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_ce, train_contrast, train_acc, train_f1 = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, DEVICE,\n",
    "            use_contrast=config_params['use_contrast'], contrast_weight=0.25 # Baseline contrast_weight\n",
    "        )\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "        torch.cuda.synchronize()  # GPU 작업 끝날 때까지 대기 → 로그가 제때 찍힘\n",
    "        print(f\"[{epoch+1:03d}/{EPOCHS}] \"\n",
    "              f\"train: loss={train_loss:.4f}, ce={train_ce:.4f}, ct={train_contrast:.4f}, \"\n",
    "              f\"acc={train_acc:.4f}, f1={train_f1:.4f} | \"\n",
    "              f\"val: loss={val_loss:.4f}, acc={val_acc:.4f}, f1={val_f1:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "             print(f\"  Epoch [{epoch+1:2d}/{EPOCHS}] Loss: {train_loss:.4f} (CE: {train_ce:.4f}, CT: {train_contrast:.4f}) | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 최종 테스트\n",
    "    assert best_state is not None\n",
    "    model.load_state_dict(best_state)\n",
    "    test_loss, test_acc, test_f1, _, _ = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "    print(f\"\\n✓ {config_name} Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(f\"  Final Test (Best-VAL ckpt): Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESS COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
