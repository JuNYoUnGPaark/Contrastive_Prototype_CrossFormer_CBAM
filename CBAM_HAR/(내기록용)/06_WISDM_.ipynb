{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7340188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler # SMOTE 대신 이걸로 변경\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# 0. 재현성 / 유틸\n",
    "# =================================================================================\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    재현성 확보: Python, NumPy, PyTorch 모두 시드 고정\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader의 worker마다 난수 고정\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae708afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1. 데이터셋 (UCI-HAR)\n",
    "# =================================================================================\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split # 추가\n",
    "\n",
    "class WISDMDataset(Dataset):\n",
    "    # __init__ 메서드를 파일 경로가 아닌 DataFrame을 받도록 수정\n",
    "    def __init__(self, dataframe, window_size=192, step_size=96):\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.activity_mapping = {\n",
    "            'Walking': 0, 'Jogging': 1, 'Upstairs': 2,\n",
    "            'Downstairs': 3, 'Sitting': 4, 'Standing': 5\n",
    "        }\n",
    "        \n",
    "        # 이제 외부에서 전달받은 DataFrame으로 바로 윈도우를 분할합니다.\n",
    "        self.X, self.y = self._segment_data(dataframe)\n",
    "        \n",
    "        print(f\"Dataset created with X shape={self.X.shape}, y shape={self.y.shape}\")\n",
    "\n",
    "    def _segment_data(self, df):\n",
    "        \"\"\"데이터를 슬라이딩 윈도우 방식으로 분할합니다.\"\"\"\n",
    "        signals, labels = [], []\n",
    "        \n",
    "        # 사용자별, 활동별로 데이터를 그룹화\n",
    "        for (user, activity), group in df.groupby(['user', 'activity']):\n",
    "            for i in range(0, len(group) - self.window_size, self.step_size):\n",
    "                window = group.iloc[i : i + self.window_size]\n",
    "                \n",
    "                signals.append(window[['x', 'y', 'z']].values.T) # (3, window_size) 형태로 바로 변환\n",
    "                labels.append(self.activity_mapping[activity])\n",
    "\n",
    "        return np.array(signals, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]\n",
    "\n",
    "# --- load_full_dataframe 함수 추가 ---\n",
    "def load_full_dataframe(filepath):\n",
    "    \"\"\"오류 처리를 포함하여 전체 raw txt 파일을 로드하는 함수\"\"\"\n",
    "    col_names = ['user', 'activity', 'timestamp', 'x', 'y', 'z']\n",
    "    df = pd.read_csv(filepath, header=None, names=col_names, on_bad_lines='skip')\n",
    "    df['z'] = pd.to_numeric(df['z'].astype(str).str.rstrip(';'), errors='coerce')\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c9182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2. CBAM (1D 버전)\n",
    "# =================================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = self.avg_pool(x).squeeze(-1)  # (B, C)\n",
    "        max_out = self.max_pool(x).squeeze(-1)  # (B, C)\n",
    "\n",
    "        avg_out = self.fc(avg_out)\n",
    "        max_out = self.fc(max_out)\n",
    "\n",
    "        out = (avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        scale = self.sigmoid(out)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.conv(out)                        # (B, 1, T)\n",
    "        out = self.sigmoid(out)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f56fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =================================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    각 클래스의 prototype과 feature를 InfoNCE 방식으로 밀어붙이는 loss\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, prototypes, labels):\n",
    "        \"\"\"\n",
    "        Contrastive Loss between features and prototypes\n",
    "\n",
    "        Args:\n",
    "            features: (B, D) - 샘플 특징\n",
    "            prototypes: (N_class, D) - 클래스별 프로토타입\n",
    "            labels: (B,) - 레이블\n",
    "\n",
    "        Returns:\n",
    "            loss: contrastive loss\n",
    "        \"\"\"\n",
    "        # L2 normalize\n",
    "        features = F.normalize(features, dim=1)\n",
    "        prototypes = F.normalize(prototypes, dim=1)\n",
    "\n",
    "        # cosine similarity\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature  # (B, num_classes)\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7715cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 4. CrossFormer Block (Cross-Attn between tokens and learnable prototypes)\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 n_prototypes=6,\n",
    "                 n_heads=4,\n",
    "                 mlp_ratio=2.0, \n",
    "                 dropout=0.1,\n",
    "                 initial_prototypes=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\">>> [Main Model] Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "                                 nn.Linear(hidden_dim, dim), nn.Dropout(dropout))\n",
    "        self.proto_proj = nn.Sequential(nn.Linear(dim, dim), nn.GELU(), nn.Linear(dim, dim))\n",
    "\n",
    "    def forward(self, x, return_proto_features=False, skip_cross_attention=False):\n",
    "        B, T, C = x.shape\n",
    "        attn_weights = None\n",
    "\n",
    "        if not skip_cross_attention:\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).expand(B, -1, -1)\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out\n",
    "\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out\n",
    "        x = x + self.mlp(self.norm3(x))\n",
    "\n",
    "        if return_proto_features:\n",
    "            proto_features = x.mean(dim=1)\n",
    "            proto_features = self.proto_proj(proto_features)\n",
    "            return x, proto_features, attn_weights\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d911c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 5. 최종 HAR 모델: embedding + (CBAM) + CrossFormer + classifier\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=9, \n",
    "                 seq_len=128,\n",
    "                 embed_dim=64, \n",
    "                 reduced_dim=32,\n",
    "                 n_classes=6, \n",
    "                 n_prototypes=6, \n",
    "                 n_heads=8,\n",
    "                 kernel_size=7,\n",
    "                 dropout=0.1,\n",
    "                 temperature=0.07, \n",
    "                 initial_prototypes=None,\n",
    "                 use_cbam=True,\n",
    "                 use_crossformer=True,\n",
    "                 use_contrast=True,\n",
    "                 use_dim_reduction=False):\n",
    "        super().__init__()\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, embed_dim, kernel_size=kernel_size, padding=(kernel_size - 1) // 2),\n",
    "            nn.BatchNorm1d(embed_dim), nn.GELU(), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(embed_dim, reduction=8, kernel_size=kernel_size)\n",
    "\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim, n_prototypes=n_prototypes, n_heads=n_heads,\n",
    "                mlp_ratio=2.0, dropout=dropout, initial_prototypes=initial_prototypes\n",
    "            )\n",
    "        else:\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim, nhead=n_heads, dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout, batch_first=True\n",
    "            )\n",
    "\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "        \n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "    def forward(self, x, labels=None, return_contrast_loss=False):\n",
    "        x = self.embedding(x)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "        \n",
    "        proto_features = None\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, _ = self.crossformer(x, return_proto_features=True)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "            \n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "            \n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_contrast_loss and self.use_contrast and proto_features is not None and labels is not None:\n",
    "            contrast_loss = self.contrast_loss(proto_features, self.crossformer.prototypes, labels)\n",
    "            return logits, contrast_loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 6. 프로토타입 초기화: train data 평균 feature로 클래스별 prototype 만들기\n",
    "# =================================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, config):\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=config['in_channels'],\n",
    "        seq_len=config['seq_len'],\n",
    "        embed_dim=config['embed_dim'],\n",
    "        reduced_dim=config['reduced_dim'], \n",
    "        n_heads=config['n_heads'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout'],\n",
    "        use_cbam=True,\n",
    "        use_crossformer=True, \n",
    "        use_contrast=False,\n",
    "        use_dim_reduction=config['use_dim_reduction']\n",
    "    ).to(device)\n",
    "\n",
    "    temp_model.eval()\n",
    "\n",
    "    temp_loader = DataLoader(train_full_dataset, batch_size=config['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    all_features, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device)\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "            x = temp_model.crossformer(x, skip_cross_attention=True)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1)\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    working_dim = config['reduced_dim'] if config['use_dim_reduction'] else config['embed_dim']\n",
    "    mean_prototypes = torch.zeros(temp_model.classifier[-1].out_features, working_dim)\n",
    "\n",
    "    for i in range(len(mean_prototypes)):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            mean_prototypes[i] = torch.randn(working_dim)\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "    \n",
    "    return mean_prototypes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada2ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 7. 학습/평가 루프\n",
    "# =================================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_contrast=True, contrast_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    total_contrast_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss + contrast_weight * contrast_loss\n",
    "            total_contrast_loss += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    torch.cuda.synchronize() # 한 에폭 끝에서 동기화\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    avg_contrast_loss = total_contrast_loss / len(dataloader) if total_contrast_loss > 0 else 0\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e48bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 8. 시각화 + 리포트 (cm, t-SNE 등)\n",
    "# =================================================================================\n",
    "\n",
    "# 라벨 이름 (index 0~5가 이 순서라고 가정)\n",
    "ACTIVITY_LABELS = [\n",
    "    'Walking',\n",
    "    'Jogging',\n",
    "    'Upstairs',\n",
    "    'Downstairs',\n",
    "    'Sitting',\n",
    "    'Standing'\n",
    "]\n",
    "\n",
    "\n",
    "def plot_classification_results(y_true, y_pred, save_path=None):\n",
    "    \"\"\"\n",
    "    Confusion Matrix 시각화 (+ 선택적으로 파일 저장)\n",
    "    \"\"\"\n",
    "    # 1. Classification Report 출력\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_true, y_pred, target_names=ACTIVITY_LABELS, digits=4))\n",
    "\n",
    "    # 2. 정규화된 Confusion Matrix 계산 및 시각화\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Normalized Confusion Matrix\")\n",
    "    print(\"=\"*80)\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=ACTIVITY_LABELS, yticklabels=ACTIVITY_LABELS)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Normalized Confusion Matrix', fontsize=16)\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] Confusion matrix → {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_tsne(model, dataloader, device, save_path=None):\n",
    "    \"\"\"\n",
    "    모델의 마지막 특징(분류 직전 표현)을 t-SNE로 2D 투영해서 그린다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating t-SNE visualization (MODEL FEATURE)...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(dataloader, desc=\"Extracting features for t-SNE\"):\n",
    "            xb = xb.to(device)\n",
    "\n",
    "            # 모델 내부에서 classifier 직전 feature까지 따라가기\n",
    "            # (아래 로직은 네 notebook의 visualize_tsne() 구조 복원)\n",
    "            x = model.embedding(xb)\n",
    "            if model.use_cbam:\n",
    "                x = model.cbam(x)\n",
    "            x = x.transpose(1, 2)\n",
    "            if model.use_dim_reduction:\n",
    "                x = model.dim_reduce(x)\n",
    "            # backbone\n",
    "            if model.use_crossformer:\n",
    "                x = model.crossformer(\n",
    "                    x,\n",
    "                    return_proto_features=False,\n",
    "                    skip_cross_attention=False\n",
    "                )\n",
    "            else:\n",
    "                x = model.self_attn_layer(x)\n",
    "\n",
    "            if model.use_dim_reduction:\n",
    "                x = model.dim_restore(x)\n",
    "            # GAP을 흉내내기 위한 mean pooling over seq\n",
    "            pooled_features = x.mean(dim=1)  # (B, D_working)\n",
    "            all_features.append(pooled_features.cpu().numpy())\n",
    "            all_labels.append(yb.cpu().numpy())\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        perplexity=20,\n",
    "        max_iter=2000,\n",
    "        init='pca',\n",
    "        learning_rate='auto'\n",
    "    )\n",
    "    proj = tsne.fit_transform(all_features)  # (N, 2)\n",
    "\n",
    "    df = pd.DataFrame(proj, columns=['Dim1', 'Dim2'])\n",
    "    df['label'] = [ACTIVITY_LABELS[l] for l in all_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.scatterplot(\n",
    "        data=df,\n",
    "        x='Dim1',\n",
    "        y='Dim2',\n",
    "        hue='label',\n",
    "        palette=sns.color_palette(\"hsv\", n_colors=len(ACTIVITY_LABELS)),\n",
    "        legend=\"full\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.title('t-SNE Visualization of Feature Space', fontsize=16)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.legend(title='Activity', loc='upper right', fontsize=6, title_fontsize=7, labelspacing=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] t-SNE (feature space) → {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_tsne_raw(dataloader, device, save_path=None, max_points=2000):\n",
    "    \"\"\"\n",
    "    모델을 거치기 전의 raw window (9채널 x 128길이)를\n",
    "    그냥 flatten해서 t-SNE로 투영.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating t-SNE visualization (RAW INPUT)...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    all_raw = []\n",
    "    all_labels = []\n",
    "\n",
    "    for xb, yb in tqdm(dataloader, desc=\"Collecting raw windows for t-SNE\"):\n",
    "        all_raw.append(xb.cpu().numpy())     # (B, C, T)\n",
    "        all_labels.append(yb.cpu().numpy())  # (B,)\n",
    "\n",
    "    all_raw = np.concatenate(all_raw, axis=0)       # (N, C, T)\n",
    "    all_labels = np.concatenate(all_labels, axis=0) # (N,)\n",
    "\n",
    "    N = all_raw.shape[0]\n",
    "    idx = np.arange(N)\n",
    "    if N > max_points:\n",
    "        idx = np.random.choice(N, size=max_points, replace=False)\n",
    "\n",
    "    X_sel = all_raw[idx]      # (M, C, T)\n",
    "    y_sel = all_labels[idx]   # (M,)\n",
    "\n",
    "    X_flat = X_sel.reshape(X_sel.shape[0], -1)  # (M, C*T)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        perplexity=20,\n",
    "        max_iter=2000,\n",
    "        init='pca',\n",
    "        learning_rate='auto'\n",
    "    )\n",
    "    proj = tsne.fit_transform(X_flat)\n",
    "\n",
    "    df = pd.DataFrame(proj, columns=['Dim1', 'Dim2'])\n",
    "    df['label'] = [ACTIVITY_LABELS[l] for l in y_sel]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.scatterplot(\n",
    "        data=df,\n",
    "        x='Dim1',\n",
    "        y='Dim2',\n",
    "        hue='label',\n",
    "        palette=sns.color_palette(\"hsv\", n_colors=len(ACTIVITY_LABELS)),\n",
    "        legend=\"full\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.title('t-SNE Visualization of RAW Input Space', fontsize=16)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.legend(title='Activity', loc='upper right', fontsize=6, title_fontsize=7, labelspacing=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"[Saved] t-SNE (raw input) → {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f770ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 9. 모델 프로파일링: Param(M), FLOPs(M), Inference Time(ms)\n",
    "# =================================================================================\n",
    "def profile_model(model, sample_input, device, warmup=10, iters=50):\n",
    "    \"\"\"\n",
    "    모델 구조/비용 측정:\n",
    "    - 파라미터 수 (M)\n",
    "    - FLOPs per sample (M)\n",
    "    - 추론 시간 평균(ms)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # params\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    params_m = total_params / 1e6\n",
    "\n",
    "    # FLOPs\n",
    "    with torch.no_grad():\n",
    "        flops = FlopCountAnalysis(model, (sample_input.to(device),))\n",
    "        flops_m = flops.total() / 1e6  # million FLOPs\n",
    "\n",
    "    # inference time\n",
    "    with torch.no_grad():\n",
    "        # 워밍업: GPU/CPU 캐시 안정화\n",
    "        for _ in range(warmup):\n",
    "            _ = model(sample_input.to(device))\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "    avg_sec = (end - start) / iters\n",
    "    inference_ms = avg_sec * 1000.0\n",
    "\n",
    "    return {\n",
    "        \"params_m\": params_m,\n",
    "        \"flops_m\": flops_m,\n",
    "        \"inference_ms\": inference_ms,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_model_profile(stats_dict):\n",
    "    print(\"==== Model Profile ====\")\n",
    "    print(f\"Parameters      : {stats_dict['params_m']:.4f} M\")\n",
    "    print(f\"FLOPs / sample : {stats_dict['flops_m']:.3f} M\")\n",
    "    print(f\"Infer Time     : {stats_dict['inference_ms']:.2f} ms/sample\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d680cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading UCI HAR Dataset from: C://Users/park9/CBAM_HAR/WISDM\n",
      "Total Users: 36\n",
      "Train Users: 24, Val Users: 6, Test Users: 6\n",
      "\n",
      "StandardScaler applied (fitted on train data only).\n",
      "Dataset created with X shape=(6976, 3, 192), y shape=(6976,)\n",
      "Dataset created with X shape=(2297, 3, 192), y shape=(2297,)\n",
      "Dataset created with X shape=(1778, 3, 192), y shape=(1778,)\n",
      "Train: 6976, Validation: 2297, Test: 1778\n",
      "\n",
      "Applying SMOTE to the training data...\n",
      "Original train samples: 6976, Resampled train samples: 16002\n",
      "Train (resampled): 16002, Validation: 2297, Test: 1778\n",
      "Calculating initial prototypes from mean features...\n",
      ">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 126/126 [00:01<00:00, 110.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([6, 64])\n",
      "\n",
      "================================================================================\n",
      "Training with config: {'DATA_DIR': 'C://Users/park9/CBAM_HAR/WISDM', 'BATCH_SIZE': 128, 'EPOCHS': 200, 'SEED': 42, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'in_channels': 3, 'seq_len': 192, 'step_size': 96, 'embed_dim': 64, 'reduced_dim': 32, 'n_heads': 8, 'kernel_size': 13, 'dropout': 0.1, 'use_cbam': True, 'use_crossformer': True, 'use_contrast': True, 'use_dim_reduction': False, 'temperature': 0.05, 'contrast_weight': 0.3}\n",
      "================================================================================\n",
      ">>> [Main Model] Prototypes initialized with calculated mean features.\n",
      "Parameters: 67,232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [010/200] TrainLoss=0.0500 TrainAcc=0.9983 ValAcc=0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [020/200] TrainLoss=0.0991 TrainAcc=0.9808 ValAcc=0.9051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [030/200] TrainLoss=0.1015 TrainAcc=0.9986 ValAcc=0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [040/200] TrainLoss=0.0123 TrainAcc=0.9985 ValAcc=0.8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [050/200] TrainLoss=0.0026 TrainAcc=0.9994 ValAcc=0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [060/200] TrainLoss=0.0785 TrainAcc=0.9895 ValAcc=0.8986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [070/200] TrainLoss=0.0030 TrainAcc=0.9996 ValAcc=0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [080/200] TrainLoss=0.0290 TrainAcc=0.9950 ValAcc=0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 297\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mEPOCHS\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m    209\u001b[39m     train_results = train_epoch(\n\u001b[32m    210\u001b[39m         model,\n\u001b[32m    211\u001b[39m         train_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m         contrast_weight=config[\u001b[33m'\u001b[39m\u001b[33mcontrast_weight\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    217\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     val_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     scheduler.step()\n\u001b[32m    221\u001b[39m     train_loss, train_ce, train_contrast, train_acc, train_f1 = train_results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, dataloader, criterion, device)\u001b[39m\n\u001b[32m     58\u001b[39m logits = model(batch_x)\n\u001b[32m     59\u001b[39m loss = criterion(logits, batch_y)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m preds = logits.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     63\u001b[39m all_preds.extend(preds.cpu().numpy())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# 10. 메인 실행\n",
    "# =====================================================================\n",
    "def main():\n",
    "    # -----------------------------\n",
    "    # 실험 설정 모음\n",
    "    # -----------------------------\n",
    "    config = {\n",
    "        # 데이터/학습\n",
    "        'DATA_DIR': 'C://Users/park9/CBAM_HAR/WISDM',\n",
    "        'BATCH_SIZE': 128,\n",
    "        'EPOCHS': 200,\n",
    "        'SEED': 42,\n",
    "        'LEARNING_RATE': 1e-3,\n",
    "        'WEIGHT_DECAY': 1e-4,\n",
    "\n",
    "        # --- 모델 입력 형태 (WISDM용으로 수정) ---\n",
    "        'in_channels': 3,\n",
    "        'seq_len': 192,\n",
    "        'step_size': 96,\n",
    "\n",
    "        # 모델 구조 (너 노트 기준)\n",
    "        'embed_dim': 64,\n",
    "        'reduced_dim': 32,\n",
    "        'n_heads': 8,\n",
    "        'kernel_size': 13,  # 13\n",
    "        'dropout': 0.1,  # 0.1\n",
    "\n",
    "        # 구성 스위치\n",
    "        'use_cbam': True,\n",
    "        'use_crossformer': True,\n",
    "        'use_contrast': True,\n",
    "        'use_dim_reduction': False,\n",
    "\n",
    "        # Loss 관련\n",
    "        'temperature': 0.05,\n",
    "        'contrast_weight': 0.3,\n",
    "    }\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    seed_everything(config['SEED'])\n",
    "\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading UCI HAR Dataset from: {config['DATA_DIR']}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. 데이터셋 전체 로드\n",
    "    # -----------------------------\n",
    "    full_df = load_full_dataframe(os.path.join(config['DATA_DIR'], 'WISDM_ar_v1.1_raw.txt'))\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2. 사용자 ID를 기준으로 Train, Val, Test 분할\n",
    "    # -----------------------------\n",
    "    all_users = full_df['user'].unique()\n",
    "    \n",
    "    # Train+Val (85%) / Test (15%) 사용자로 분할\n",
    "    train_val_users, test_users = train_test_split(\n",
    "        all_users, test_size=0.15, random_state=config['SEED']\n",
    "    )\n",
    "    \n",
    "    # Train (70%) / Val (15%) 사용자로 분할\n",
    "    train_users, val_users = train_test_split(\n",
    "        train_val_users, test_size=0.1765, random_state=config['SEED'] # 0.15 / 0.85 ≈ 0.1765\n",
    "    )\n",
    "\n",
    "    print(f\"Total Users: {len(all_users)}\")\n",
    "    print(f\"Train Users: {len(train_users)}, Val Users: {len(val_users)}, Test Users: {len(test_users)}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. 분할된 사용자에 맞춰 DataFrame 생성\n",
    "    # -----------------------------\n",
    "    train_df = full_df[full_df['user'].isin(train_users)]\n",
    "    val_df = full_df[full_df['user'].isin(val_users)]\n",
    "    test_df = full_df[full_df['user'].isin(test_users)]\n",
    "\n",
    "    # 정규화할 피처 선택\n",
    "    feature_columns = ['x', 'y', 'z']\n",
    "    \n",
    "    # 1. Scaler 객체를 생성하고, **오직 train_df만으로** 학습(fit)시킵니다.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df[feature_columns])\n",
    "    \n",
    "    # 2. 학습된 scaler를 사용해 train, val, test 데이터프레임을 모두 변환(transform)합니다.\n",
    "    train_df.loc[:, feature_columns] = scaler.transform(train_df[feature_columns])\n",
    "    val_df.loc[:, feature_columns] = scaler.transform(val_df[feature_columns])\n",
    "    test_df.loc[:, feature_columns] = scaler.transform(test_df[feature_columns])\n",
    "\n",
    "    print(\"\\nStandardScaler applied (fitted on train data only).\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 4. 각 DataFrame으로 Dataset 객체 생성\n",
    "    # -----------------------------\n",
    "    train_dataset = WISDMDataset(train_df, window_size=config['seq_len'], step_size=config['step_size'])\n",
    "    val_dataset = WISDMDataset(val_df, window_size=config['seq_len'], step_size=config['step_size'])\n",
    "    test_dataset = WISDMDataset(test_df, window_size=config['seq_len'], step_size=config['step_size'])\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "    print(\"\\nApplying SMOTE to the training data...\")\n",
    "    # 1. 원본 train_dataset에서 X, y 추출\n",
    "    X_train_full = train_dataset.X\n",
    "    y_train_full = train_dataset.y\n",
    "    N, C, T = X_train_full.shape\n",
    "    \n",
    "    # 2. SMOTE를 위해 2D로 펼치기 (N, C, T) -> (N, C*T)\n",
    "    X_train_flat = X_train_full.reshape(N, C * T)\n",
    "    \n",
    "    # 3. SMOTE 적용 \n",
    "    ros = RandomOverSampler(random_state=config['SEED'])\n",
    "    X_resampled_flat, y_resampled = ros.fit_resample(X_train_flat, y_train_full)\n",
    "    \n",
    "    # 4. 3D 딥러닝 형태로 복원 (N_new, C*T) -> (N_new, C, T)\n",
    "    N_new = X_resampled_flat.shape[0]\n",
    "    X_resampled = X_resampled_flat.reshape(N_new, C, T)\n",
    "    \n",
    "    print(f\"Original train samples: {N}, Resampled train samples: {N_new}\")\n",
    "    \n",
    "    # 5. resampled 데이터로 새 TensorDataset 생성\n",
    "    X_resampled_tensor = torch.FloatTensor(X_resampled)\n",
    "    y_resampled_tensor = torch.LongTensor(y_resampled)\n",
    "    \n",
    "    # 6. 'train_dataset' 변수를 SMOTE가 적용된 새 데이터셋으로 덮어쓰기\n",
    "    train_dataset = TensorDataset(X_resampled_tensor, y_resampled_tensor)\n",
    "    print(f\"Train (resampled): {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "    g = torch.Generator().manual_seed(config['SEED'])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 프로토타입 초기화\n",
    "    # -----------------------------\n",
    "    initial_prototypes = get_mean_prototypes(train_dataset, DEVICE, config)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training with config: {config}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 모델 생성\n",
    "    # -----------------------------\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=config['in_channels'],\n",
    "        seq_len=config['seq_len'],\n",
    "        n_classes=6,\n",
    "        n_prototypes=6,\n",
    "        embed_dim=config['embed_dim'],\n",
    "        reduced_dim=config['reduced_dim'],\n",
    "        n_heads=config['n_heads'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout'],\n",
    "        temperature=config['temperature'],\n",
    "        initial_prototypes=initial_prototypes,\n",
    "        use_cbam=config['use_cbam'],\n",
    "        use_crossformer=config['use_crossformer'],\n",
    "        use_contrast=config['use_contrast'],\n",
    "        use_dim_reduction=config['use_dim_reduction']\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # optimizer / scheduler / criterion\n",
    "    # -----------------------------\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['LEARNING_RATE'],\n",
    "        weight_decay=config['WEIGHT_DECAY']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config['EPOCHS']\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 학습 루프\n",
    "    # -----------------------------\n",
    "    history = []\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        train_results = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            DEVICE,\n",
    "            use_contrast=config['use_contrast'],\n",
    "            contrast_weight=config['contrast_weight']\n",
    "        )\n",
    "        val_results = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss, train_ce, train_contrast, train_acc, train_f1 = train_results\n",
    "        val_loss, val_acc, val_f1, _, _ = val_results\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_f1': train_f1,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "        })\n",
    "\n",
    "        # best ckpt 추적\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1:03d}/{config['EPOCHS']:03d}] \"\n",
    "                f\"TrainLoss={train_loss:.4f} \"\n",
    "                f\"TrainAcc={train_acc:.4f} \"\n",
    "                f\"ValAcc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 최종 테스트 (best 상태로)\n",
    "    # -----------------------------\n",
    "    assert best_state is not None, \"best_state is None (no epochs?)\"\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "        model, test_loader, criterion, DEVICE\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ Training Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(f\"  Final Test (Best-VAL ckpt): Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 시각화 + 저장\n",
    "    # -----------------------------\n",
    "    plot_classification_results(\n",
    "        test_labels,\n",
    "        test_preds,\n",
    "        save_path=\"confusion_matrix.png\"\n",
    "    )\n",
    "\n",
    "    visualize_tsne(\n",
    "        model,\n",
    "        test_loader,\n",
    "        DEVICE,\n",
    "        save_path=\"tsne_feature.png\"\n",
    "    )\n",
    "\n",
    "    visualize_tsne_raw(\n",
    "        test_loader,\n",
    "        DEVICE,\n",
    "        save_path=\"tsne_raw.png\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 모델 프로파일링\n",
    "    # -----------------------------\n",
    "    dummy_input = torch.randn(1, 3, 128)  # (B=1, C=3, T=128)\n",
    "    stats = profile_model(model, dummy_input, DEVICE)\n",
    "    print_model_profile(stats)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL PROCESSES COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
