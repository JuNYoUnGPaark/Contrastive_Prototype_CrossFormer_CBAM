{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a4f79d",
   "metadata": {},
   "source": [
    "`Prototype 초기화 방식 변경, temparture 변경, contrastive_weight 변경, Batch_size 변경, use_dim_reduction 변경`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca1099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading UCI HAR Dataset from: C://Users/park9/CBAM_HAR/data\n",
      "Loaded train data: X shape=(7352, 9, 128), y shape=(7352,)\n",
      "Loaded test data: X shape=(2947, 9, 128), y shape=(2947,)\n",
      "Train: 5881, Validation: 1471, Test: 2947\n",
      "Calculating initial prototypes from mean features...\n",
      ">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 58/58 [00:00<00:00, 132.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([6, 64])\n",
      "\n",
      "================================================================================\n",
      "Training: + CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\n",
      "Config: {'use_cbam': True, 'use_crossformer': True, 'use_contrast': True, 'use_dim_reduction': False}\n",
      "================================================================================\n",
      ">>> [Main Model] Prototypes initialized with calculated mean features.\n",
      "Parameters: 72,224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] train: loss=1.3823, ce=1.1505, ct=0.9272, acc=0.5596, f1=0.5182 | val: loss=0.6202, acc=0.7342, f1=0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/100] train: loss=0.5163, ce=0.3851, ct=0.5250, acc=0.8721, f1=0.8709 | val: loss=0.2534, acc=0.9075, f1=0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/100] train: loss=0.2260, ce=0.1597, ct=0.2653, acc=0.9383, f1=0.9382 | val: loss=0.1131, acc=0.9490, f1=0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/100] train: loss=0.1788, ce=0.1320, ct=0.1873, acc=0.9473, f1=0.9471 | val: loss=0.1112, acc=0.9524, f1=0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/100] train: loss=0.1648, ce=0.1249, ct=0.1595, acc=0.9464, f1=0.9464 | val: loss=0.1013, acc=0.9531, f1=0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/100] train: loss=0.1671, ce=0.1274, ct=0.1589, acc=0.9447, f1=0.9446 | val: loss=0.1021, acc=0.9585, f1=0.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007/100] train: loss=0.1589, ce=0.1230, ct=0.1436, acc=0.9488, f1=0.9487 | val: loss=0.0988, acc=0.9531, f1=0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008/100] train: loss=0.1490, ce=0.1159, ct=0.1324, acc=0.9510, f1=0.9510 | val: loss=0.1018, acc=0.9613, f1=0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009/100] train: loss=0.1438, ce=0.1121, ct=0.1269, acc=0.9553, f1=0.9553 | val: loss=0.0954, acc=0.9613, f1=0.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/100] train: loss=0.1389, ce=0.1083, ct=0.1221, acc=0.9543, f1=0.9542 | val: loss=0.0914, acc=0.9619, f1=0.9620\n",
      "  Epoch [10/100] Loss: 0.1389 (CE: 0.1083, CT: 0.1221) | Val Acc: 0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011/100] train: loss=0.1402, ce=0.1097, ct=0.1217, acc=0.9524, f1=0.9524 | val: loss=0.0974, acc=0.9626, f1=0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012/100] train: loss=0.1463, ce=0.1146, ct=0.1269, acc=0.9497, f1=0.9496 | val: loss=0.0910, acc=0.9545, f1=0.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013/100] train: loss=0.1326, ce=0.1041, ct=0.1138, acc=0.9566, f1=0.9566 | val: loss=0.0838, acc=0.9626, f1=0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014/100] train: loss=0.1247, ce=0.0980, ct=0.1071, acc=0.9582, f1=0.9582 | val: loss=0.0848, acc=0.9660, f1=0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015/100] train: loss=0.1220, ce=0.0958, ct=0.1050, acc=0.9583, f1=0.9583 | val: loss=0.0830, acc=0.9633, f1=0.9632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016/100] train: loss=0.1194, ce=0.0938, ct=0.1024, acc=0.9599, f1=0.9599 | val: loss=0.0812, acc=0.9680, f1=0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017/100] train: loss=0.1213, ce=0.0953, ct=0.1041, acc=0.9599, f1=0.9599 | val: loss=0.0762, acc=0.9694, f1=0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018/100] train: loss=0.1113, ce=0.0875, ct=0.0955, acc=0.9641, f1=0.9641 | val: loss=0.1055, acc=0.9551, f1=0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019/100] train: loss=0.1147, ce=0.0899, ct=0.0989, acc=0.9597, f1=0.9597 | val: loss=0.0743, acc=0.9721, f1=0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/100] train: loss=0.1110, ce=0.0870, ct=0.0961, acc=0.9623, f1=0.9622 | val: loss=0.0938, acc=0.9646, f1=0.9646\n",
      "  Epoch [20/100] Loss: 0.1110 (CE: 0.0870, CT: 0.0961) | Val Acc: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021/100] train: loss=0.1069, ce=0.0842, ct=0.0909, acc=0.9648, f1=0.9648 | val: loss=0.0783, acc=0.9694, f1=0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022/100] train: loss=0.1005, ce=0.0793, ct=0.0849, acc=0.9655, f1=0.9655 | val: loss=0.0761, acc=0.9721, f1=0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023/100] train: loss=0.0957, ce=0.0752, ct=0.0818, acc=0.9694, f1=0.9694 | val: loss=0.0668, acc=0.9748, f1=0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024/100] train: loss=0.0888, ce=0.0701, ct=0.0746, acc=0.9714, f1=0.9714 | val: loss=0.0726, acc=0.9742, f1=0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025/100] train: loss=0.0906, ce=0.0718, ct=0.0754, acc=0.9714, f1=0.9714 | val: loss=0.0914, acc=0.9619, f1=0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026/100] train: loss=0.0820, ce=0.0646, ct=0.0698, acc=0.9748, f1=0.9748 | val: loss=0.0755, acc=0.9735, f1=0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027/100] train: loss=0.0750, ce=0.0590, ct=0.0641, acc=0.9760, f1=0.9760 | val: loss=0.0754, acc=0.9762, f1=0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028/100] train: loss=0.0755, ce=0.0594, ct=0.0642, acc=0.9760, f1=0.9760 | val: loss=0.0946, acc=0.9721, f1=0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029/100] train: loss=0.0761, ce=0.0602, ct=0.0633, acc=0.9757, f1=0.9757 | val: loss=0.0827, acc=0.9735, f1=0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/100] train: loss=0.0681, ce=0.0537, ct=0.0576, acc=0.9772, f1=0.9772 | val: loss=0.0676, acc=0.9789, f1=0.9789\n",
      "  Epoch [30/100] Loss: 0.0681 (CE: 0.0537, CT: 0.0576) | Val Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[031/100] train: loss=0.0678, ce=0.0537, ct=0.0563, acc=0.9799, f1=0.9799 | val: loss=0.0679, acc=0.9762, f1=0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[032/100] train: loss=0.0640, ce=0.0503, ct=0.0545, acc=0.9798, f1=0.9798 | val: loss=0.0667, acc=0.9796, f1=0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[033/100] train: loss=0.0620, ce=0.0489, ct=0.0525, acc=0.9798, f1=0.9798 | val: loss=0.0624, acc=0.9782, f1=0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[034/100] train: loss=0.0578, ce=0.0454, ct=0.0497, acc=0.9818, f1=0.9818 | val: loss=0.0689, acc=0.9748, f1=0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[035/100] train: loss=0.0598, ce=0.0469, ct=0.0515, acc=0.9806, f1=0.9806 | val: loss=0.0667, acc=0.9755, f1=0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[036/100] train: loss=0.0537, ce=0.0424, ct=0.0455, acc=0.9833, f1=0.9833 | val: loss=0.0730, acc=0.9776, f1=0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037/100] train: loss=0.0535, ce=0.0424, ct=0.0446, acc=0.9842, f1=0.9842 | val: loss=0.0645, acc=0.9816, f1=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[038/100] train: loss=0.0473, ce=0.0372, ct=0.0404, acc=0.9844, f1=0.9844 | val: loss=0.0526, acc=0.9789, f1=0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[039/100] train: loss=0.0489, ce=0.0385, ct=0.0416, acc=0.9838, f1=0.9838 | val: loss=0.0764, acc=0.9701, f1=0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/100] train: loss=0.0455, ce=0.0360, ct=0.0380, acc=0.9867, f1=0.9867 | val: loss=0.0595, acc=0.9769, f1=0.9768\n",
      "  Epoch [40/100] Loss: 0.0455 (CE: 0.0360, CT: 0.0380) | Val Acc: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[041/100] train: loss=0.0445, ce=0.0351, ct=0.0377, acc=0.9867, f1=0.9867 | val: loss=0.0464, acc=0.9816, f1=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[042/100] train: loss=0.0389, ce=0.0307, ct=0.0329, acc=0.9878, f1=0.9878 | val: loss=0.0800, acc=0.9742, f1=0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[043/100] train: loss=0.0446, ce=0.0351, ct=0.0382, acc=0.9862, f1=0.9862 | val: loss=0.0513, acc=0.9837, f1=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[044/100] train: loss=0.0341, ce=0.0268, ct=0.0293, acc=0.9896, f1=0.9896 | val: loss=0.0491, acc=0.9837, f1=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[045/100] train: loss=0.0309, ce=0.0242, ct=0.0267, acc=0.9908, f1=0.9908 | val: loss=0.0677, acc=0.9796, f1=0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[046/100] train: loss=0.0306, ce=0.0242, ct=0.0257, acc=0.9912, f1=0.9912 | val: loss=0.0515, acc=0.9837, f1=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[047/100] train: loss=0.0296, ce=0.0233, ct=0.0254, acc=0.9906, f1=0.9906 | val: loss=0.0573, acc=0.9823, f1=0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[048/100] train: loss=0.0343, ce=0.0271, ct=0.0291, acc=0.9888, f1=0.9888 | val: loss=0.0876, acc=0.9728, f1=0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[049/100] train: loss=0.0304, ce=0.0238, ct=0.0264, acc=0.9898, f1=0.9898 | val: loss=0.0576, acc=0.9850, f1=0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/100] train: loss=0.0272, ce=0.0214, ct=0.0233, acc=0.9922, f1=0.9922 | val: loss=0.0553, acc=0.9864, f1=0.9864\n",
      "  Epoch [50/100] Loss: 0.0272 (CE: 0.0214, CT: 0.0233) | Val Acc: 0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[051/100] train: loss=0.0301, ce=0.0234, ct=0.0265, acc=0.9908, f1=0.9908 | val: loss=0.0471, acc=0.9864, f1=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[052/100] train: loss=0.0236, ce=0.0186, ct=0.0202, acc=0.9932, f1=0.9932 | val: loss=0.0411, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[053/100] train: loss=0.0265, ce=0.0210, ct=0.0220, acc=0.9927, f1=0.9927 | val: loss=0.0403, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[054/100] train: loss=0.0229, ce=0.0181, ct=0.0194, acc=0.9929, f1=0.9929 | val: loss=0.0450, acc=0.9864, f1=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[055/100] train: loss=0.0206, ce=0.0161, ct=0.0177, acc=0.9934, f1=0.9934 | val: loss=0.0595, acc=0.9850, f1=0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[056/100] train: loss=0.0277, ce=0.0218, ct=0.0237, acc=0.9910, f1=0.9910 | val: loss=0.0350, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[057/100] train: loss=0.0183, ce=0.0145, ct=0.0156, acc=0.9942, f1=0.9942 | val: loss=0.0460, acc=0.9878, f1=0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[058/100] train: loss=0.0226, ce=0.0177, ct=0.0195, acc=0.9937, f1=0.9937 | val: loss=0.0623, acc=0.9844, f1=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[059/100] train: loss=0.0215, ce=0.0170, ct=0.0179, acc=0.9940, f1=0.9940 | val: loss=0.0359, acc=0.9891, f1=0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[060/100] train: loss=0.0267, ce=0.0212, ct=0.0220, acc=0.9925, f1=0.9925 | val: loss=0.0478, acc=0.9891, f1=0.9891\n",
      "  Epoch [60/100] Loss: 0.0267 (CE: 0.0212, CT: 0.0220) | Val Acc: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[061/100] train: loss=0.0194, ce=0.0152, ct=0.0167, acc=0.9947, f1=0.9947 | val: loss=0.0335, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[062/100] train: loss=0.0157, ce=0.0122, ct=0.0139, acc=0.9957, f1=0.9957 | val: loss=0.0460, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[063/100] train: loss=0.0185, ce=0.0146, ct=0.0158, acc=0.9949, f1=0.9949 | val: loss=0.0359, acc=0.9878, f1=0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[064/100] train: loss=0.0187, ce=0.0147, ct=0.0160, acc=0.9942, f1=0.9942 | val: loss=0.0379, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[065/100] train: loss=0.0175, ce=0.0137, ct=0.0151, acc=0.9944, f1=0.9944 | val: loss=0.0627, acc=0.9837, f1=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[066/100] train: loss=0.0193, ce=0.0152, ct=0.0166, acc=0.9947, f1=0.9947 | val: loss=0.0442, acc=0.9871, f1=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[067/100] train: loss=0.0139, ce=0.0109, ct=0.0121, acc=0.9963, f1=0.9963 | val: loss=0.0521, acc=0.9878, f1=0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[068/100] train: loss=0.0189, ce=0.0149, ct=0.0161, acc=0.9947, f1=0.9947 | val: loss=0.0363, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[069/100] train: loss=0.0168, ce=0.0131, ct=0.0150, acc=0.9947, f1=0.9947 | val: loss=0.0536, acc=0.9857, f1=0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[070/100] train: loss=0.0118, ce=0.0091, ct=0.0107, acc=0.9966, f1=0.9966 | val: loss=0.0402, acc=0.9925, f1=0.9925\n",
      "  Epoch [70/100] Loss: 0.0118 (CE: 0.0091, CT: 0.0107) | Val Acc: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[071/100] train: loss=0.0136, ce=0.0106, ct=0.0121, acc=0.9961, f1=0.9961 | val: loss=0.0413, acc=0.9918, f1=0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[072/100] train: loss=0.0129, ce=0.0102, ct=0.0107, acc=0.9957, f1=0.9957 | val: loss=0.0467, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[073/100] train: loss=0.0161, ce=0.0126, ct=0.0138, acc=0.9951, f1=0.9951 | val: loss=0.0383, acc=0.9918, f1=0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[074/100] train: loss=0.0127, ce=0.0097, ct=0.0117, acc=0.9963, f1=0.9963 | val: loss=0.0348, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[075/100] train: loss=0.0115, ce=0.0089, ct=0.0105, acc=0.9968, f1=0.9968 | val: loss=0.0371, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[076/100] train: loss=0.0145, ce=0.0114, ct=0.0125, acc=0.9966, f1=0.9966 | val: loss=0.0409, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[077/100] train: loss=0.0128, ce=0.0100, ct=0.0110, acc=0.9963, f1=0.9963 | val: loss=0.0439, acc=0.9884, f1=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[078/100] train: loss=0.0111, ce=0.0086, ct=0.0099, acc=0.9968, f1=0.9968 | val: loss=0.0360, acc=0.9925, f1=0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[079/100] train: loss=0.0114, ce=0.0089, ct=0.0099, acc=0.9966, f1=0.9966 | val: loss=0.0377, acc=0.9918, f1=0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[080/100] train: loss=0.0113, ce=0.0089, ct=0.0096, acc=0.9966, f1=0.9966 | val: loss=0.0443, acc=0.9898, f1=0.9898\n",
      "  Epoch [80/100] Loss: 0.0113 (CE: 0.0089, CT: 0.0096) | Val Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[081/100] train: loss=0.0094, ce=0.0074, ct=0.0081, acc=0.9971, f1=0.9971 | val: loss=0.0422, acc=0.9898, f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[082/100] train: loss=0.0113, ce=0.0089, ct=0.0095, acc=0.9969, f1=0.9969 | val: loss=0.0422, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[083/100] train: loss=0.0088, ce=0.0069, ct=0.0079, acc=0.9980, f1=0.9980 | val: loss=0.0449, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[084/100] train: loss=0.0110, ce=0.0086, ct=0.0094, acc=0.9968, f1=0.9968 | val: loss=0.0386, acc=0.9932, f1=0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[085/100] train: loss=0.0100, ce=0.0077, ct=0.0090, acc=0.9974, f1=0.9974 | val: loss=0.0433, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[086/100] train: loss=0.0100, ce=0.0078, ct=0.0089, acc=0.9971, f1=0.9971 | val: loss=0.0379, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[087/100] train: loss=0.0117, ce=0.0092, ct=0.0099, acc=0.9959, f1=0.9959 | val: loss=0.0382, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[088/100] train: loss=0.0093, ce=0.0072, ct=0.0082, acc=0.9974, f1=0.9974 | val: loss=0.0347, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[089/100] train: loss=0.0114, ce=0.0090, ct=0.0098, acc=0.9968, f1=0.9968 | val: loss=0.0413, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[090/100] train: loss=0.0088, ce=0.0068, ct=0.0080, acc=0.9983, f1=0.9983 | val: loss=0.0374, acc=0.9912, f1=0.9912\n",
      "  Epoch [90/100] Loss: 0.0088 (CE: 0.0068, CT: 0.0080) | Val Acc: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[091/100] train: loss=0.0078, ce=0.0061, ct=0.0069, acc=0.9980, f1=0.9980 | val: loss=0.0380, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[092/100] train: loss=0.0078, ce=0.0061, ct=0.0068, acc=0.9974, f1=0.9974 | val: loss=0.0411, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[093/100] train: loss=0.0064, ce=0.0049, ct=0.0057, acc=0.9990, f1=0.9990 | val: loss=0.0400, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[094/100] train: loss=0.0097, ce=0.0076, ct=0.0084, acc=0.9968, f1=0.9968 | val: loss=0.0387, acc=0.9912, f1=0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[095/100] train: loss=0.0108, ce=0.0083, ct=0.0102, acc=0.9969, f1=0.9969 | val: loss=0.0411, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[096/100] train: loss=0.0088, ce=0.0068, ct=0.0080, acc=0.9980, f1=0.9980 | val: loss=0.0408, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[097/100] train: loss=0.0099, ce=0.0078, ct=0.0082, acc=0.9973, f1=0.9973 | val: loss=0.0396, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[098/100] train: loss=0.0070, ce=0.0055, ct=0.0062, acc=0.9985, f1=0.9985 | val: loss=0.0389, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[099/100] train: loss=0.0086, ce=0.0067, ct=0.0078, acc=0.9976, f1=0.9976 | val: loss=0.0372, acc=0.9905, f1=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/100] train: loss=0.0081, ce=0.0064, ct=0.0070, acc=0.9973, f1=0.9973 | val: loss=0.0398, acc=0.9898, f1=0.9898\n",
      "  Epoch [100/100] Loss: 0.0081 (CE: 0.0064, CT: 0.0070) | Val Acc: 0.9898\n",
      "\n",
      "✓ + CBAM + CrossFormer + Contrast (Full + Mean Proto Init) Complete!\n",
      "  Best Val Acc: 0.9932 @ epoch 84\n",
      "  Final Test (Best-VAL ckpt): Acc=0.9484 | F1=0.9483\n",
      "\n",
      "================================================================================\n",
      "PROCESS COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os, copy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    재현성을 위해 Python, NumPy, PyTorch의 Seed를 고정합니다.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    \n",
    "    # cuDNN 설정 (재현성은 보장되나, 속도가 느려질 수 있음)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader의 worker process를 위한 Seed 설정\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. UCI HAR 데이터 로더\n",
    "# =====================================================================\n",
    "class UCIHARDataset(Dataset):\n",
    "    def __init__(self, data_dir, train=True):\n",
    "        \"\"\"\n",
    "        UCI HAR Dataset 로더\n",
    "        data_dir: UCI HAR Dataset 폴더 경로\n",
    "        train: True면 train 데이터, False면 test 데이터\n",
    "        \"\"\"\n",
    "        subset = 'train' if train else 'test'\n",
    "\n",
    "        # Inertial Signals 로드 (9개 센서)\n",
    "        signals = []\n",
    "        signal_types = [\n",
    "            'body_acc_x', 'body_acc_y', 'body_acc_z',\n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'\n",
    "        ]\n",
    "\n",
    "        for signal in signal_types:\n",
    "            filename = os.path.join(data_dir, subset, 'Inertial Signals',\n",
    "                                f'{signal}_{subset}.txt')\n",
    "            # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "            with open(filename, 'r') as f:\n",
    "                # 2. np.loadtxt에 파일 이름 대신 파일 객체(f)를 전달합니다.\n",
    "                data = np.loadtxt(f)\n",
    "                \n",
    "            signals.append(data)\n",
    "\n",
    "        # (N, 9, 128) 형태로 변환\n",
    "        self.X = np.stack(signals, axis=1)\n",
    "\n",
    "        # 레이블 로드 (1~6 -> 0~5로 변환)\n",
    "        label_file = os.path.join(data_dir, subset, f'y_{subset}.txt')\n",
    "        # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "        with open(label_file, 'r') as f:\n",
    "            # 2. np.loadtxt에 파일 객체(f)를 전달합니다.\n",
    "            self.y = np.loadtxt(f, dtype=np.int32) - 1\n",
    "\n",
    "        print(f\"Loaded {subset} data: X shape={self.X.shape}, y shape={self.y.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. 1D-CBAM (Channel + Temporal Attention)\n",
    "# =====================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = self.fc(self.avg_pool(x).squeeze(-1))  # (B, C)\n",
    "        max_out = self.fc(self.max_pool(x).squeeze(-1))  # (B, C)\n",
    "        out = self.sigmoid(avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.sigmoid(self.conv(out))  # (B, 1, T)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =====================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, prototypes, labels):\n",
    "        \"\"\"\n",
    "        Contrastive Loss between features and prototypes\n",
    "\n",
    "        Args:\n",
    "            features: (B, D) - 샘플 특징\n",
    "            prototypes: (N_class, D) - 클래스별 프로토타입\n",
    "            labels: (B,) - 레이블\n",
    "\n",
    "        Returns:\n",
    "            loss: contrastive loss\n",
    "        \"\"\"\n",
    "        # L2 정규화\n",
    "        features = F.normalize(features, dim=1)\n",
    "        prototypes = F.normalize(prototypes, dim=1)\n",
    "\n",
    "        # 유사도 계산 (B, N_class)\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4. CrossFormer with Contrast Prototypes\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self, dim, n_prototypes=6, n_heads=4, mlp_ratio=2.0, dropout=0.1,\n",
    "                 initial_prototypes=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable prototypes (L2 정규화 적용)\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "\n",
    "        # Xavier 초기화 대신, 전달받은 값으로 초기화 (없으면 Xavier 유지)\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\">>> [Main Model] Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        # Cross-Attention: Input(Q) x Prototypes(K, V)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Self-Attention\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # FFN\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # Prototype projection (contrastive learning용)\n",
    "        self.proto_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_proto_features=False, skip_cross_attention=False):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # 1. Cross-Attention (선택적 실행)\n",
    "        if not skip_cross_attention:\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).repeat(B, 1, 1).contiguous()\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out\n",
    "        else: # Cross-Attention을 건너뛸 경우, attn_weights는 None\n",
    "            attn_weights = None\n",
    "\n",
    "        # 2. Self-Attention\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out\n",
    "\n",
    "        # 3. FFN\n",
    "        x = x + self.mlp(self.norm3(x))\n",
    "\n",
    "        # Prototype features for contrastive loss\n",
    "        if return_proto_features:\n",
    "            # Global average pooling\n",
    "            proto_features = x.mean(dim=1)  # (B, C)\n",
    "            proto_features = self.proto_proj(proto_features)  # projection\n",
    "            return x, proto_features, attn_weights\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5. 메인 모델: CrossFormer + 1D-CBAM + Contrast Prototype\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=9,\n",
    "                 seq_len=128,\n",
    "                 embed_dim=64,\n",
    "                 reduced_dim=32,\n",
    "                 n_classes=6,\n",
    "                 n_prototypes=6,\n",
    "                 n_heads=4,\n",
    "                 dropout=0.1,\n",
    "                 temperature=0.07,\n",
    "                 initial_prototypes=None,\n",
    "                 # Ablation 옵션\n",
    "                 use_cbam=True,\n",
    "                 use_crossformer=True,\n",
    "                 use_contrast=True,\n",
    "                 use_dim_reduction=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        # 1. Input Embedding (1D Conv)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, embed_dim, kernel_size=13, padding=6),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(embed_dim, reduction=8, kernel_size=13)\n",
    "\n",
    "        # 3. 차원 축소 (선택적)\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        # 4. CrossFormer Block (선택적)\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim,\n",
    "                n_prototypes=n_prototypes,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=2.0,\n",
    "                dropout=dropout,\n",
    "                initial_prototypes=initial_prototypes\n",
    "            )\n",
    "        else:\n",
    "            # CrossFormer 없이 Self-Attention만 사용\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "\n",
    "        # 5. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        # 6. Global Pooling + Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "\n",
    "        # 7. Contrastive Loss (선택적)\n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "    def forward(self, x, labels=None, return_contrast_loss=False):\n",
    "        # x: (B, C, T) = (B, 9, 128)\n",
    "\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(x)  # (B, embed_dim, T)\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "\n",
    "        # 3. Reshape for Transformer\n",
    "        x = x.transpose(1, 2).contiguous()  # (B, T, embed_dim)\n",
    "\n",
    "        # 4. 차원 축소 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "\n",
    "        # 5. CrossFormer 또는 Self-Attention\n",
    "        proto_features = None\n",
    "        attn_weights = None\n",
    "\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, attn_weights = self.crossformer(x, return_proto_features=True)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "\n",
    "        # 6. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "\n",
    "        # 7. Pooling + Classification\n",
    "        x = x.transpose(1, 2).contiguous()  # (B, embed_dim, T)\n",
    "        x = self.pool(x).squeeze(-1)  # (B, embed_dim)\n",
    "        logits = self.classifier(x)  # (B, n_classes)\n",
    "\n",
    "        # Contrastive Loss 계산\n",
    "        if return_contrast_loss and self.use_contrast and proto_features is not None and labels is not None:\n",
    "            contrast_loss = self.contrast_loss(\n",
    "                proto_features,\n",
    "                self.crossformer.prototypes,\n",
    "                labels\n",
    "            )\n",
    "            return logits, contrast_loss\n",
    "\n",
    "        return logits\n",
    "\n",
    "# =====================================================================\n",
    "# 6. 평균 프로토타입 계산 함수\n",
    "# =====================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, embed_dim=64, \n",
    "                        reduced_dim=32, batch_size=128, use_dim_reduction=False):\n",
    "    \"\"\"\n",
    "    훈련 데이터셋 전체를 사용하여 클래스별 평균 특징 벡터를 계산합니다.\n",
    "    (Cross-Attention 제외하고 특징 추출)\n",
    "    \"\"\"\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    # 1. 임시 특징 추출 모델 정의 (Embedding ~ Pooling까지만)\n",
    "    #    (주의: 실제 모델 구조와 파라미터(dropout 등) 일치시킬 것)\n",
    "    #    (여기서는 use_dim_reduction=False라고 가정)\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        embed_dim=embed_dim, reduced_dim=reduced_dim, dropout=0.1, # Baseline 값 사용\n",
    "        use_cbam=True, use_crossformer=True, use_contrast=False, # Contrast False로!\n",
    "        use_dim_reduction=use_dim_reduction # 평균 계산 시 차원 축소 안 함\n",
    "    ).to(device)\n",
    "    temp_model.eval() # 평가 모드로 설정\n",
    "\n",
    "    # 2. 전체 훈련 데이터 로더 (섞지 않음)\n",
    "    temp_loader = DataLoader(train_full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 3. 특징 추출 루프\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            # --- 특징 추출 (ContrastCrossFormerCBAM_HAR의 forward 참고) ---\n",
    "            # 1. Embedding\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            # 2. CBAM\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "            # 3. Reshape\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            # 4. 차원 축소 \n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "\n",
    "            # 5. Self-Attention (CrossFormer 없이)\n",
    "            # CrossFormer 블록을 호출하되, cross-attention 건너뛰기 옵션 활성화\n",
    "            x = temp_model.crossformer(x, skip_cross_attention=True)\n",
    "\n",
    "            # 6. 차원 복원 (여기서는 안 함)\n",
    "            # 7. Pooling (Classifier 직전)\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1) # (B, embed_dim)\n",
    "            # -----------------------------------------------------------\n",
    "\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # 4. 클래스별 평균 계산\n",
    "    n_classes = temp_model.classifier[-1].out_features # 모델 정의에서 클래스 수 가져오기\n",
    "    # ⬇️ 프로토타입 차원을 working_dim에 맞게 동적으로 설정\n",
    "    working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "    mean_prototypes = torch.zeros(n_classes, working_dim)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            print(f\"Warning: No samples found for class {i} during prototype initialization.\")\n",
    "            # (샘플 없는 경우 랜덤 초기화 또는 0 벡터 사용 등 처리 필요)\n",
    "            mean_prototypes[i] = torch.randn(working_dim) # 임시로 랜덤 사용\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "    return mean_prototypes.to(device) # GPU로 다시 보냄\n",
    "\n",
    "# =====================================================================\n",
    "# 7. 학습 및 평가 (Contrastive Loss 포함)\n",
    "# =====================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_contrast=True, contrast_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    total_contrast_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss + contrast_weight * contrast_loss\n",
    "            total_contrast_loss += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    torch.cuda.synchronize() # 한 에폭 끝에서 동기화\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    avg_contrast_loss = total_contrast_loss / len(dataloader) if total_contrast_loss > 0 else 0\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, acc, f1, all_preds, all_labels\n",
    "\n",
    "# =====================================================================\n",
    "# 8. 메인 실행\n",
    "# =====================================================================\n",
    "def main():\n",
    "    # 하이퍼파라미터\n",
    "    DATA_DIR = 'C://Users/park9/CBAM_HAR/data'\n",
    "    BATCH_SIZE = 128  # 최소 256\n",
    "    EPOCHS = 100  # 100으로 고정 \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SEED = 42\n",
    "    embed_dim = 64\n",
    "    reduced_dim = 32\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading UCI HAR Dataset from: {DATA_DIR}\")\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_full_dataset = UCIHARDataset(DATA_DIR, train=True)\n",
    "    test_dataset = UCIHARDataset(DATA_DIR, train=False)\n",
    "\n",
    "    # Train을 Train/Validation으로 분할 (80:20)\n",
    "    train_size = int(0.8 * len(train_full_dataset))\n",
    "    val_size = len(train_full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_full_dataset, [train_size, val_size],\n",
    "                                               generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              worker_init_fn=seed_worker, generator=g, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            worker_init_fn=seed_worker, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             worker_init_fn=seed_worker, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # Ablation Study 대신, \"Full Model\" 직접 생성 및 훈련/테스트\n",
    "    config_name = \"+ CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\"\n",
    "    config_params = dict(use_cbam=True, use_crossformer=True, use_contrast=True, use_dim_reduction=False)\n",
    "\n",
    "    # 평균 프로토타입 계산 (모델 생성 전)\n",
    "    # (주의: embed_dim=64는 모델 생성 시 사용할 값과 일치해야 함)\n",
    "    initial_prototypes = get_mean_prototypes(train_full_dataset, DEVICE, embed_dim=embed_dim, reduced_dim=reduced_dim,\n",
    "                                             batch_size=BATCH_SIZE, use_dim_reduction=config_params['use_dim_reduction'])\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training: {config_name}\")\n",
    "    print(f\"Config: {config_params}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 모델 생성 시 initial_prototypes 전달\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=9, seq_len=128, embed_dim=embed_dim, reduced_dim=reduced_dim,\n",
    "        n_classes=6, n_prototypes=6, n_heads=8, dropout=0.1, temperature=0.05, # Baseline 값들\n",
    "        initial_prototypes=initial_prototypes, # ⬅️ 계산된 값 전달\n",
    "        **config_params\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4) # Baseline 옵티마이저\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 학습 루프 (기존 run_ablation_study 내부 로직과 유사하게)\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_ce, train_contrast, train_acc, train_f1 = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, DEVICE,\n",
    "            use_contrast=config_params['use_contrast'], contrast_weight=0.25 # Baseline contrast_weight\n",
    "        )\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "        torch.cuda.synchronize()  # GPU 작업 끝날 때까지 대기 → 로그가 제때 찍힘\n",
    "        print(f\"[{epoch+1:03d}/{EPOCHS}] \"\n",
    "              f\"train: loss={train_loss:.4f}, ce={train_ce:.4f}, ct={train_contrast:.4f}, \"\n",
    "              f\"acc={train_acc:.4f}, f1={train_f1:.4f} | \"\n",
    "              f\"val: loss={val_loss:.4f}, acc={val_acc:.4f}, f1={val_f1:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "             print(f\"  Epoch [{epoch+1:2d}/{EPOCHS}] Loss: {train_loss:.4f} (CE: {train_ce:.4f}, CT: {train_contrast:.4f}) | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 최종 테스트\n",
    "    assert best_state is not None\n",
    "    model.load_state_dict(best_state)\n",
    "    test_loss, test_acc, test_f1, _, _ = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "    print(f\"\\n✓ {config_name} Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(f\"  Final Test (Best-VAL ckpt): Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESS COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
