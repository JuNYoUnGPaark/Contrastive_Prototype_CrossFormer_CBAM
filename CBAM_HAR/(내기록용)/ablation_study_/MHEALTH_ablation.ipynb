{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7340188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-1. Library Import \n",
    "# =================================================================================\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import io\n",
    "import contextlib\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b0fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-2. CONFIG (experiment setup for MHEALTH)\n",
    "# =================================================================================\n",
    "CONFIG = {\n",
    "    # ---------------------------\n",
    "    # Reproducibility / ID\n",
    "    # ---------------------------\n",
    "    \"seed\": 42,\n",
    "    \"dataset_name\": \"MHEALTH\",\n",
    "\n",
    "    # ---------------------------\n",
    "    # Data / Windowing\n",
    "    # ---------------------------\n",
    "    # MHEALTH raw 로그(.log)들이 들어있는 상위 폴더\n",
    "    \"data_dir\": r\"C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\",\n",
    "\n",
    "    # MHEALTH 슬라이딩 윈도우 설정\n",
    "    # (250 samples per window, 125 stride)  <- 이건 문헌에서 자주 쓰는 셋팅이라 baseline처럼 둘 거야\n",
    "    \"window_size\": 128,\n",
    "    \"step_size\": 64,\n",
    "\n",
    "    # train/val/test split 방식:\n",
    "    # - subject-wise 분할 (각 subject 기준으로 60/20/20 나눌 예정)\n",
    "    # (class 비율은 안 맞춰주고, subject generalization 관점 유지)\n",
    "    \"subject_split_train_ratio\": 0.6,\n",
    "    \"subject_split_val_ratio\": 0.2,\n",
    "    # 나머지 0.2는 test\n",
    "\n",
    "    \"batch_size\": 128,\n",
    "\n",
    "    # ---------------------------\n",
    "    # Training\n",
    "    # ---------------------------\n",
    "    \"epochs\": 100,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "\n",
    "    \"contrast_weight\": 0.25,     # total_loss = CE + contrast_weight * contrast_loss\n",
    "    \"temperature\": 0.05,         # contrastive prototype loss temperature\n",
    "\n",
    "    \"scheduler_type\": \"cosine\",  # 고정 (CosineAnnealingLR)\n",
    "    \"scheduler_T_max\": 100,      # should match epochs\n",
    "\n",
    "    # ---------------------------\n",
    "    # Model architecture\n",
    "    # ---------------------------\n",
    "    # MHEALTH 채널: 23채널 (가슴/발목/팔 가속도+자이로+자력 + ECG 등)\n",
    "    \"in_channels\": 23,\n",
    "\n",
    "    # 시퀀스 길이: window_size 그대로 들어가므로 128\n",
    "    \"seq_len\": 128,\n",
    "\n",
    "    # MHEALTH 라벨: 1~12 동작, 0은 \"null/기타\"라서 학습에서 제외.\n",
    "    # => 그래서 실제 학습 클래스는 12개.\n",
    "    \"n_classes\": 12,\n",
    "    \"n_prototypes\": 12,  # prototype per class (1:1)\n",
    "\n",
    "    \"embed_dim\": 64,     # Conv1d embed dim (우리는 이걸 고정해서 계속 씀)\n",
    "    \"reduced_dim\": 32,   # only used if use_dim_reduction=True\n",
    "    \"use_dim_reduction\": False,\n",
    "\n",
    "    \"n_heads\": 8,\n",
    "    \"dropout\": 0.1,\n",
    "\n",
    "    # Conv1d kernel + CBAM temporal kernel\n",
    "    \"kernel_size\": 7,\n",
    "\n",
    "    # ---------------------------\n",
    "    # Feature toggles / Ablations\n",
    "    # ---------------------------\n",
    "    \"use_cbam\": True,\n",
    "    \"use_crossformer\": True,\n",
    "    \"use_contrast\": True,    # prototype contrast term on during training\n",
    "\n",
    "    # ---------------------------\n",
    "    # Logging / Debug convenience\n",
    "    # ---------------------------\n",
    "    \"print_every\": 50,\n",
    "    \"do_tsne\": True,\n",
    "    \"profile_model\": True,\n",
    "}\n",
    "\n",
    "\n",
    "def pretty_print_config(cfg: dict):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXPERIMENT CONFIG\")\n",
    "    print(\"-\" * 80)\n",
    "    max_k = max(len(k) for k in cfg.keys())\n",
    "    for k in sorted(cfg.keys()):\n",
    "        print(f\"{k.ljust(max_k)} : {cfg[k]}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0823bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-3. Reproducibility helpers\n",
    "# =================================================================================\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Fix random seeds for reproducibility across random, numpy, torch (cpu & cuda).\n",
    "    Also configures CuDNN for deterministic behavior.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # cudnn deterministic mode: reproducible but may be slower\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    To make DataLoader workers deterministic.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae708afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-4. Dataset: MHEALTH (23-channel version)\n",
    "# =================================================================================\n",
    "def _load_single_mhealth_log(path: str, feature_cols: list[str]):\n",
    "    \"\"\"\n",
    "    하나의 mHealth_subjectXX.log 파일을 로드해서 DataFrame으로 반환.\n",
    "    파일은 탭(\\t)으로 구분된 24개의 컬럼:\n",
    "        23개 센서 채널 + 마지막 1개 activity label\n",
    "    여기서는 subject ID는 따로 붙이지 않고,\n",
    "    단순히 시계열만 이어붙일 목적이라 subject 열은 만들지 않는다.\n",
    "    (=> 기존 코드와 동일하게 subject 구분 없이 concat)\n",
    "    \"\"\"\n",
    "    # names=[23개 피처 + 'label'] 로 읽는다\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=feature_cols + [\"label\"],\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_mhealth_dataframe(data_dir: str):\n",
    "    \"\"\"\n",
    "    data_dir 안의 mHealth_subject*.log 전부 읽어서 하나의 DataFrame으로 concat.\n",
    "    (기존 코드와 동일하게 subject별 경계 정보는 사용하지 않고, 그냥 이어붙임)\n",
    "    \"\"\"\n",
    "    feature_cols = [\n",
    "        \"acc_chest_x\", \"acc_chest_y\", \"acc_chest_z\",\n",
    "        \"ecg_1\", \"ecg_2\",\n",
    "        \"acc_ankle_x\", \"acc_ankle_y\", \"acc_ankle_z\",\n",
    "        \"gyro_ankle_x\", \"gyro_ankle_y\", \"gyro_ankle_z\",\n",
    "        \"mag_ankle_x\", \"mag_ankle_y\", \"mag_ankle_z\",\n",
    "        \"acc_arm_x\", \"acc_arm_y\", \"acc_arm_z\",\n",
    "        \"gyro_arm_x\", \"gyro_arm_y\", \"gyro_arm_z\",\n",
    "        \"mag_arm_x\", \"mag_arm_y\", \"mag_arm_z\",\n",
    "    ]  # 총 23 channels\n",
    "\n",
    "    log_files = glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\"))\n",
    "    print(f\"Found {len(log_files)} log files in {data_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for fp in log_files:\n",
    "        df_i = _load_single_mhealth_log(fp, feature_cols)\n",
    "        dfs.append(df_i)\n",
    "\n",
    "    if not dfs:\n",
    "        raise RuntimeError(f\"No mHealth_subject*.log files found under {data_dir}\")\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Null 클래스(label==0)는 제외 (기존 코드 동일)\n",
    "    full_df = full_df[full_df[\"label\"] != 0].copy()\n",
    "\n",
    "    # 원래 라벨 1~12 → 0~11 로 shift\n",
    "    full_df.loc[:, \"label\"] = full_df[\"label\"] - 1\n",
    "\n",
    "    return full_df, feature_cols\n",
    "\n",
    "\n",
    "def create_mhealth_windows(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    window_size: int,\n",
    "    step_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    전체 시계열을 (window_size, step_size)로 슬라이딩하면서 윈도우 생성.\n",
    "    - 윈도우 라벨 = 그 윈도우 마지막 프레임의 라벨 (end-1)\n",
    "    - 윈도우 내에 여러 클래스가 섞여 있어도 상관없음\n",
    "    - 이미 label==0 (Null)은 load 단계에서 제거했으므로 여기선 신경 안 씀\n",
    "\n",
    "    반환:\n",
    "        X_np : (N, C, T) float32  ← (채널, 시간)\n",
    "        y_np : (N,) int64         ← 0~11 로 이미 shift된 라벨\n",
    "    \"\"\"\n",
    "    data_arr = df[feature_cols].to_numpy(dtype=np.float32)  # (L, 23)\n",
    "    labels_arr = df[\"label\"].to_numpy(dtype=np.int64)       # (L,)\n",
    "\n",
    "    L = data_arr.shape[0]\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    start = 0\n",
    "    while start + window_size <= L:\n",
    "        end = start + window_size\n",
    "\n",
    "        window_x = data_arr[start:end]        # (T, C)\n",
    "        window_label = labels_arr[end - 1]    # 마지막 타임스텝 라벨\n",
    "\n",
    "        # (T, C) -> (C, T) 로 바꿔서 모델 입력 형태랑 맞춤\n",
    "        window_x_ct = np.transpose(window_x, (1, 0))  # (23, window_size)\n",
    "\n",
    "        X_list.append(window_x_ct)\n",
    "        y_list.append(int(window_label))\n",
    "\n",
    "        start += step_size\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"No windows created. Check window_size / step_size / dataset length.\")\n",
    "\n",
    "    X_np = np.stack(X_list, axis=0).astype(np.float32)  # (N, 23, window_size)\n",
    "    y_np = np.array(y_list, dtype=np.int64)             # (N,)\n",
    "\n",
    "    return X_np, y_np\n",
    "\n",
    "\n",
    "class MHEALTHDataset(Dataset):\n",
    "    \"\"\"\n",
    "    MHEALTH Dataset wrapper\n",
    "    - 로직은 기존 버전 그대로:\n",
    "      1) 모든 subject의 로그를 읽어 하나의 긴 시계열로 합침\n",
    "      2) label==0(Null) 은 제거\n",
    "      3) 라벨을 0부터 시작하도록 shift\n",
    "      4) 전체 시계열을 슬라이딩 윈도우\n",
    "         - 윈도우 라벨 = 마지막 프레임 라벨\n",
    "      5) 반환 shape: (C, T)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir: str, window_size: int = 128, step_size: int = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) 로그 로드 & 전처리\n",
    "        full_df, feature_cols = load_mhealth_dataframe(data_dir)\n",
    "\n",
    "        # 2) 슬라이딩 윈도우 생성\n",
    "        X, y = create_mhealth_windows(\n",
    "            df=full_df,\n",
    "            feature_cols=feature_cols,\n",
    "            window_size=window_size,\n",
    "            step_size=step_size,\n",
    "        )\n",
    "\n",
    "        # 보관\n",
    "        self.X = X  # (N, C, T), float32\n",
    "        self.y = y  # (N,), int64\n",
    "\n",
    "        # 라벨 이름 (0~11 인덱스 기준)\n",
    "        # 원래 mHealth 라벨 정의에서 1~12 이고, 우리가 -1 해서 0~11 됨.\n",
    "        self.label_names = [\n",
    "            \"Standing still\",            # 1 -> 0\n",
    "            \"Sitting and relaxing\",      # 2 -> 1\n",
    "            \"Lying down\",                # 3 -> 2\n",
    "            \"Walking\",                   # 4 -> 3\n",
    "            \"Climbing stairs\",           # 5 -> 4\n",
    "            \"Waist bends forward\",       # 6 -> 5\n",
    "            \"Frontal elevation of arms\", # 7 -> 6\n",
    "            \"Knees bending\",             # 8 -> 7\n",
    "            \"Cycling\",                   # 9 -> 8\n",
    "            \"Jogging\",                   # 10 -> 9\n",
    "            \"Running\",                   # 11 -> 10\n",
    "            \"Jump front & back\",         # 12 -> 11\n",
    "        ]\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Loaded MHEALTH dataset\")\n",
    "        print(f\"  X shape : {self.X.shape}  (N, C, T)\")\n",
    "        print(f\"  y shape : {self.y.shape}  (N,)\")\n",
    "        print(f\"  Classes : {len(self.label_names)}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            x_i: torch.FloatTensor, shape (C,T)\n",
    "            y_i: torch.LongTensor scalar\n",
    "        \"\"\"\n",
    "        x_i = torch.from_numpy(self.X[idx]).float()\n",
    "        y_i = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x_i, y_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c9182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2. CBAM (1D 버전)\n",
    "# =================================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = self.avg_pool(x).squeeze(-1)  # (B, C)\n",
    "        max_out = self.max_pool(x).squeeze(-1)  # (B, C)\n",
    "\n",
    "        avg_out = self.fc(avg_out)\n",
    "        max_out = self.fc(max_out)\n",
    "\n",
    "        out = (avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        scale = self.sigmoid(out)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.conv(out)                        # (B, 1, T)\n",
    "        out = self.sigmoid(out)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f56fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =================================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    각 클래스의 prototype과 feature를 InfoNCE 스타일로 밀어붙이는 loss\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature: float = 0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,    # (B, D)\n",
    "        prototypes: torch.Tensor,  # (N_class, D)\n",
    "        labels: torch.Tensor       # (B,)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            scalar contrastive loss (tensor)\n",
    "        \"\"\"\n",
    "        # L2 normalize\n",
    "        features = F.normalize(features, dim=1, eps=1e-6)\n",
    "        prototypes = F.normalize(prototypes, dim=1, eps=1e-6)\n",
    "\n",
    "        # cosine similarity -> logits\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature  # (B, num_classes)\n",
    "\n",
    "        return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7715cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 4. CrossFormer Block (Cross-Attn between tokens and learnable prototypes)\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Token sequence ↔ class prototypes 간 cross-attention + self-attention 블록.\n",
    "\n",
    "    흐름:\n",
    "      1) (선택) Cross-Attention\n",
    "         - query: 시퀀스 토큰 x (B, T, C)\n",
    "         - key/value: learnable prototypes (P, C)\n",
    "         - 각 토큰이 어떤 prototype(=행동 클래스)랑 강하게 연결되는지 학습\n",
    "      2) Self-Attention\n",
    "         - 토큰들끼리 상호참조\n",
    "      3) MLP\n",
    "      4) (옵션) contrast를 위한 샘플 표현(proto_features) 뽑기\n",
    "\n",
    "    Args:\n",
    "        dim                : token embedding dim (C)\n",
    "        n_prototypes       : prototype 개수 (보통 클래스 수와 동일)\n",
    "        n_heads            : multi-head attention head 수\n",
    "        mlp_ratio          : FFN hidden dim 배수 (hidden_dim = dim * mlp_ratio)\n",
    "        dropout            : dropout rate\n",
    "        initial_prototypes : (n_prototypes, dim) 텐서. 제공되면 그 값으로 prototype init,\n",
    "                             없으면 Xavier Uniform으로 초기화\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 n_prototypes: int = 6,\n",
    "                 n_heads: int = 4,\n",
    "                 mlp_ratio: float = 2.0,\n",
    "                 dropout: float = 0.1,\n",
    "                 initial_prototypes: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Learnable prototypes (P, C)\n",
    "        # -------------------------------------------------\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, (\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} \"\n",
    "                f\"vs self.prototypes {self.prototypes.shape}\"\n",
    "            )\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\"Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\"Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Cross-Attention: tokens Q  vs  prototypes K,V\n",
    "        # -------------------------------------------------\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=dim,\n",
    "            num_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Self-Attention on tokens\n",
    "        # -------------------------------------------------\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            embed_dim=dim,\n",
    "            num_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # FFN (MLP with residual)\n",
    "        # -------------------------------------------------\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # contrast용 sample-level feature projection\n",
    "        self.proto_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        return_proto_features: bool = False,\n",
    "        skip_cross_attention: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : (B, T, C=dim)\n",
    "            return_proto_features : True면 contrastive loss용 feature도 같이 리턴\n",
    "            skip_cross_attention  : True면 cross-attn을 건너뛰고 self-attn만 수행\n",
    "                                    (프로토타입 초기화할 때 평균 특징 뽑는 용도)\n",
    "\n",
    "        Returns:\n",
    "            if return_proto_features:\n",
    "                (x_out, proto_features, attn_weights)\n",
    "                - x_out           : (B, T, C)\n",
    "                - proto_features  : (B, C) pooled token feature after block\n",
    "                - attn_weights    : (B, T, P) cross-attn weights (or None)\n",
    "            else:\n",
    "                x_out\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        attn_weights = None\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1) Cross-Attention (optional)\n",
    "        # -------------------------------------------------\n",
    "        if not skip_cross_attention:\n",
    "            # normalize prototypes for stable attention keys/values\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1, eps=1e-6)  # (P, C)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).expand(B, -1, -1)      # (B, P, C)\n",
    "\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(\n",
    "                query=x_norm,\n",
    "                key=prototypes,\n",
    "                value=prototypes,\n",
    "            )\n",
    "            x = x + cross_out  # residual\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2) Self-Attention on tokens\n",
    "        # -------------------------------------------------\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(\n",
    "            query=x_norm,\n",
    "            key=x_norm,\n",
    "            value=x_norm,\n",
    "        )\n",
    "        x = x + self_out  # residual\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3) FFN\n",
    "        # -------------------------------------------------\n",
    "        x = x + self.mlp(self.norm3(x))  # residual\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4) Optional prototype features for contrastive loss\n",
    "        # -------------------------------------------------\n",
    "        if return_proto_features:\n",
    "            # 토큰 평균 (B, T, C) -> (B, C)\n",
    "            proto_features = x.mean(dim=1)\n",
    "            proto_features = self.proto_proj(proto_features)  # (B, C)\n",
    "            return x, proto_features, attn_weights\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d911c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 5. Final HAR model: Conv1d embedding + (CBAM) + CrossFormer + classifier\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    \"\"\"\n",
    "    HAR classifier with:\n",
    "      1) Conv1d embedding (+ BN + GELU + Dropout)\n",
    "      2) (optional) CBAM channel+temporal attention on the embedded sequence\n",
    "      3) Sequence modeling block:\n",
    "         - CrossFormerBlock (tokens ↔ learnable prototypes cross-attn + self-attn)\n",
    "           OR\n",
    "         - vanilla TransformerEncoderLayer self-attn as fallback\n",
    "      4) Global temporal pooling (AdaptiveAvgPool1d)\n",
    "      5) MLP classifier head\n",
    "      6) (optional) contrastive prototype loss\n",
    "\n",
    "    Args:\n",
    "        in_channels        : # raw sensor channels (C_in)\n",
    "        seq_len            : sequence length (T) (주로 로깅/프로파일용)\n",
    "        embed_dim          : conv embedding dim (also classifier input dim)\n",
    "        reduced_dim        : working dim if use_dim_reduction=True\n",
    "        n_classes          : # activity classes\n",
    "        n_prototypes       : # learnable prototypes in CrossFormer\n",
    "        n_heads            : # attention heads\n",
    "        kernel_size        : Conv1d kernel size (and CBAM temporal conv kernel)\n",
    "        dropout            : dropout prob\n",
    "        temperature        : contrastive temperature\n",
    "        initial_prototypes : precomputed (n_prototypes, dim) tensor for proto init,\n",
    "                             or None (then Xavier init)\n",
    "        use_cbam           : apply CBAM after embedding\n",
    "        use_crossformer    : use CrossFormerBlock (True) vs. vanilla self-attn (False)\n",
    "        use_contrast       : if True, forward() can also return contrastive loss\n",
    "        use_dim_reduction  : if True, project embed_dim -> reduced_dim before attention\n",
    "                             and restore after\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 9,\n",
    "                 seq_len: int = 128,\n",
    "                 embed_dim: int = 64,\n",
    "                 reduced_dim: int = 32,\n",
    "                 n_classes: int = 6,\n",
    "                 n_prototypes: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 kernel_size: int = 7,\n",
    "                 dropout: float = 0.1,\n",
    "                 temperature: float = 0.07,\n",
    "                 initial_prototypes: torch.Tensor = None,\n",
    "                 use_cbam: bool = True,\n",
    "                 use_crossformer: bool = True,\n",
    "                 use_contrast: bool = True,\n",
    "                 use_dim_reduction: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Save config (편하게 접근하려고 들고만 있음. 로직 영향 없음)\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.reduced_dim = reduced_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 1) Embedding: Conv1d -> BN -> GELU -> Dropout\n",
    "        #    Input : (B, C_in, T)\n",
    "        #    Output: (B, embed_dim, T)\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels,\n",
    "                embed_dim,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=(kernel_size - 1) // 2,  # \"same\" padding for odd kernel\n",
    "            ),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 2) Optional CBAM (ChannelAttention1D + TemporalAttention1D)\n",
    "        #    (B, embed_dim, T) -> (B, embed_dim, T)\n",
    "        # ---------------------------------------------------------------------\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(\n",
    "                channels=embed_dim,\n",
    "                reduction=8,\n",
    "                kernel_size=kernel_size,\n",
    "            )\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 3) (Optional) Dim Reduction before attention\n",
    "        #    working_dim: attention block이 실제로 보는 채널 수\n",
    "        #    - if use_dim_reduction=False -> working_dim == embed_dim\n",
    "        # ---------------------------------------------------------------------\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 4) Sequence modeling backbone\n",
    "        #    A) CrossFormerBlock (prototype cross-attn + self-attn)\n",
    "        #    B) Fallback: vanilla TransformerEncoderLayer self-attn\n",
    "        #    Input : (B, T, working_dim)\n",
    "        #    Output: (B, T, working_dim)\n",
    "        # ---------------------------------------------------------------------\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim,\n",
    "                n_prototypes=n_prototypes,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=2.0,\n",
    "                dropout=dropout,\n",
    "                initial_prototypes=initial_prototypes,\n",
    "            )\n",
    "        else:\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 5) (Optional) Dim restore after attention\n",
    "        #    If we shrank to reduced_dim, bring it back up to embed_dim\n",
    "        # ---------------------------------------------------------------------\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 6) Temporal pooling + classifier head\n",
    "        #    After attention:\n",
    "        #      shape (B, T, embed_dim)\n",
    "        #    -> transpose to (B, embed_dim, T)\n",
    "        #    -> AdaptiveAvgPool1d(1) -> (B, embed_dim)\n",
    "        #    -> classifier -> (B, n_classes)\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes),\n",
    "        )\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 7) Contrastive prototype loss module (optional)\n",
    "        # ---------------------------------------------------------------------\n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(\n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        labels: torch.Tensor = None,\n",
    "        return_contrast_loss: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : (B, C_in, T)\n",
    "            labels : (B,) long tensor, class indices [0..n_classes-1]\n",
    "            return_contrast_loss : True면 contrastive loss를 같이 반환\n",
    "\n",
    "        Returns:\n",
    "            logits                     : (B, n_classes)\n",
    "            (optionally) contrast_loss : scalar tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1) Conv embedding (+ CBAM)\n",
    "        #    x -> (B, embed_dim, T)\n",
    "        # -------------------------------------------------\n",
    "        x = self.embedding(x)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2) Prep for attention\n",
    "        #    (B, embed_dim, T) -> (B, T, embed_dim)\n",
    "        #    and (optional) dim reduction\n",
    "        # -------------------------------------------------\n",
    "        x = x.transpose(1, 2).contiguous()  # (B, T, embed_dim)\n",
    "\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)          # (B, T, reduced_dim)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3) Attention backbone\n",
    "        #    CrossFormerBlock or vanilla self-attn\n",
    "        #    Also optionally get proto_features for contrast\n",
    "        # -------------------------------------------------\n",
    "        proto_features = None\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, _ = self.crossformer(\n",
    "                    x,\n",
    "                    return_proto_features=True,\n",
    "                    skip_cross_attention=False,\n",
    "                )\n",
    "            else:\n",
    "                x = self.crossformer(\n",
    "                    x,\n",
    "                    return_proto_features=False,\n",
    "                    skip_cross_attention=False,\n",
    "                )\n",
    "        else:\n",
    "            x = self.self_attn(x)  # (B, T, working_dim)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4) Restore dim if reduced\n",
    "        #    (B, T, reduced_dim) -> (B, T, embed_dim)\n",
    "        # -------------------------------------------------\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 5) Temporal pooling to get clip-level feature\n",
    "        #    (B, T, embed_dim) -> (B, embed_dim, T)\n",
    "        #    -> pool -> (B, embed_dim)\n",
    "        # -------------------------------------------------\n",
    "        x = x.transpose(1, 2).contiguous()      # (B, embed_dim, T)\n",
    "        feat_vec = self.pool(x).squeeze(-1)     # (B, embed_dim)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 6) Classifier head\n",
    "        # -------------------------------------------------\n",
    "        logits = self.classifier(feat_vec)      # (B, n_classes)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 7) Optional contrastive prototype loss\n",
    "        # -------------------------------------------------\n",
    "        if (\n",
    "            return_contrast_loss\n",
    "            and self.use_contrast\n",
    "            and proto_features is not None\n",
    "            and labels is not None\n",
    "        ):\n",
    "            contrast_loss = self.contrast_loss(\n",
    "                proto_features,                # (B, dim)\n",
    "                self.crossformer.prototypes,   # (n_prototypes, dim)\n",
    "                labels,                        # (B,)\n",
    "            )\n",
    "            return logits, contrast_loss\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 6. Prototype Initialization\n",
    "#    -> 평균 feature 로 클래스별 초기 prototype 생성\n",
    "# =================================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, config):\n",
    "    \"\"\"\n",
    "    train_full_dataset (train subset 전체)에 대해 임시 모델(temp_model)을 돌려서\n",
    "    각 클래스의 평균 feature vector를 구한 다음,\n",
    "    그걸 CrossFormerBlock의 초기 prototype으로 쓰기 위한 텐서를 만든다.\n",
    "\n",
    "    temp_model은 contrast_loss를 사용하지 않고,\n",
    "    crossformer를 skip_cross_attention=True로 호출해서\n",
    "    (프로토타입-토큰 상호작용 없이) 순수 토큰 표현만 뽑는다.\n",
    "    \"\"\"\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) 임시 모델: contrast 없이 feature만 뽑는 용도\n",
    "    #    (initial_prototypes=None 으로 시작)\n",
    "    # -------------------------------------------------\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels        = config['in_channels'],\n",
    "        seq_len            = config['seq_len'],\n",
    "        embed_dim          = config['embed_dim'],\n",
    "        reduced_dim        = config['reduced_dim'],\n",
    "        n_classes          = config['n_classes'],\n",
    "        n_prototypes       = config['n_prototypes'],\n",
    "        n_heads            = config['n_heads'],\n",
    "        kernel_size        = config['kernel_size'],\n",
    "        dropout            = config['dropout'],\n",
    "        temperature        = config['temperature'],\n",
    "        initial_prototypes = None,  # 초기 프로토타입 없이 시작\n",
    "        use_cbam           = True,\n",
    "        use_crossformer    = True,\n",
    "        use_contrast       = False,  # 여기서는 contrast loss 안 쓸 거라 False\n",
    "        use_dim_reduction  = config['use_dim_reduction'],\n",
    "    ).to(device)\n",
    "\n",
    "    temp_model.eval()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) temp_loader: shuffle=False로 전체 train feature 훑기\n",
    "    # -------------------------------------------------\n",
    "    temp_loader = DataLoader(\n",
    "        train_full_dataset,\n",
    "        batch_size = config['batch_size'],\n",
    "        shuffle    = False,\n",
    "        num_workers= 0,\n",
    "        pin_memory = True,\n",
    "    )\n",
    "\n",
    "    all_features = []\n",
    "    all_labels   = []\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) 각 배치에 대해 pooled feature 추출\n",
    "    #    (classifier 직전과 유사하지만 skip_cross_attention=True로\n",
    "    #     프로토타입 영향은 뺀 representation)\n",
    "    # -------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device, non_blocking=True)\n",
    "\n",
    "            # ---- embed + (optional) CBAM\n",
    "            x = temp_model.embedding(batch_x)          # (B, embed_dim, T)\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)                 # (B, embed_dim, T)\n",
    "\n",
    "            # ---- prep for attention\n",
    "            x = x.transpose(1, 2).contiguous()         # (B, T, embed_dim)\n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)           # (B, T, reduced_dim)\n",
    "\n",
    "            # ---- run crossformer WITHOUT letting prototypes pull tokens\n",
    "            #      (skip_cross_attention=True)\n",
    "            x = temp_model.crossformer(\n",
    "                x,\n",
    "                return_proto_features=False,\n",
    "                skip_cross_attention=True,\n",
    "            )                                          # (B, T, working_dim)\n",
    "\n",
    "            # ---- back to (B, working_dim, T) for pooling\n",
    "            x = x.transpose(1, 2).contiguous()         # (B, working_dim, T)\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1)  # (B, working_dim)\n",
    "\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4) 전체 concat\n",
    "    # -------------------------------------------------\n",
    "    all_features = torch.cat(all_features, dim=0)   # (N, working_dim)\n",
    "    all_labels   = torch.cat(all_labels,   dim=0)   # (N,)\n",
    "\n",
    "    # working_dim은 dim_reduction 여부에 따라 달라진다.\n",
    "    working_dim = config['reduced_dim'] if config['use_dim_reduction'] else config['embed_dim']\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 5) 클래스별 평균 feature -> prototype\n",
    "    #    shape: (n_classes, working_dim)\n",
    "    # -------------------------------------------------\n",
    "    mean_prototypes = torch.zeros(\n",
    "        config['n_classes'],\n",
    "        working_dim,\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    for cls_idx in range(config['n_classes']):\n",
    "        class_mask = (all_labels == cls_idx)\n",
    "        class_features = all_features[class_mask]    # (Nc, working_dim)\n",
    "\n",
    "        if class_features.shape[0] > 0:\n",
    "            mean_vec = class_features.mean(dim=0)\n",
    "        else:\n",
    "            # 만약 어떤 클래스가 train_full_dataset에 전혀 없다면\n",
    "            # 그냥 랜덤으로 하나 넣어줌 (안전장치)\n",
    "            mean_vec = torch.randn(working_dim)\n",
    "\n",
    "        mean_prototypes[cls_idx] = mean_vec\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "\n",
    "    # (n_classes, working_dim) -> device로\n",
    "    return mean_prototypes.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada2ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 7. train, evaluation\n",
    "# =================================================================================\n",
    "def train_epoch(model,\n",
    "                dataloader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                device,\n",
    "                use_contrast=True,\n",
    "                contrast_weight=0.5):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    ce_loss_sum = 0.0\n",
    "    contrast_loss_sum = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x = batch_x.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            total_loss = ce_loss + contrast_weight * contrast_loss\n",
    "            contrast_loss_sum += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            total_loss = ce_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_sum += total_loss.item()\n",
    "        ce_loss_sum += ce_loss.item()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(batch_y.detach().cpu().numpy())\n",
    "\n",
    "    # CUDA 동기화 (소요시간 측정/안정화용)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    avg_total_loss = total_loss_sum / len(dataloader)\n",
    "    avg_ce_loss = ce_loss_sum / len(dataloader)\n",
    "    avg_contrast_loss = contrast_loss_sum / len(dataloader) if contrast_loss_sum > 0 else 0.0\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_total_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model,\n",
    "             dataloader,\n",
    "             criterion,\n",
    "             device,\n",
    "             use_contrast=True,\n",
    "             contrast_weight=0.5):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    ce_loss_sum = 0.0\n",
    "    contrast_loss_sum = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device, non_blocking=True)\n",
    "            batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            # validation/test에서는 contrastive term을 포함할지 말지 선택 가능.\n",
    "            # 일관성 유지 차원에서 train_epoch와 같은 코드 경로를 둔다.\n",
    "            if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "                logits, contrast_loss = model(\n",
    "                    batch_x,\n",
    "                    batch_y,\n",
    "                    return_contrast_loss=True\n",
    "                )\n",
    "                ce_loss = criterion(logits, batch_y)\n",
    "                total_loss = ce_loss + contrast_weight * contrast_loss\n",
    "                contrast_loss_sum += contrast_loss.item()\n",
    "            else:\n",
    "                logits = model(batch_x)\n",
    "                ce_loss = criterion(logits, batch_y)\n",
    "                total_loss = ce_loss\n",
    "\n",
    "            total_loss_sum += total_loss.item()\n",
    "            ce_loss_sum += ce_loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    avg_total_loss = total_loss_sum / len(dataloader)\n",
    "    avg_ce_loss = ce_loss_sum / len(dataloader)\n",
    "    avg_contrast_loss = contrast_loss_sum / len(dataloader) if contrast_loss_sum > 0 else 0.0\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # main()에서 confusion matrix, report, t-SNE용으로 예측/GT도 같이 받으니까 그대로 반환\n",
    "    return avg_total_loss, acc, f1, all_preds, all_labels, avg_ce_loss, avg_contrast_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f770ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 9. 모델 프로파일링: Param(M), FLOPs(M), Inference Time(ms)\n",
    "# =================================================================================\n",
    "def profile_model(model, sample_input, device, warmup=10, iters=50):\n",
    "    \"\"\"\n",
    "    모델 구조/비용 측정:\n",
    "      - 파라미터 수 (M)\n",
    "      - FLOPs per sample (M)  ← fvcore 가능할 때만\n",
    "      - 평균 추론 시간 (ms/sample)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 1) 파라미터 수\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    params_m = total_params / 1e6\n",
    "\n",
    "    # 2) FLOPs (optional)\n",
    "    flops_m = None\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            fake_out = io.StringIO()\n",
    "            fake_err = io.StringIO()\n",
    "            with contextlib.redirect_stdout(fake_out), contextlib.redirect_stderr(fake_err):\n",
    "                flops = FlopCountAnalysis(model, (sample_input.to(device),))\n",
    "                total_flops = flops.total()\n",
    "        flops_m = total_flops / 1e6\n",
    "    except Exception:\n",
    "        flops_m = None\n",
    "\n",
    "    # 3) 추론 시간 측정\n",
    "    with torch.no_grad():\n",
    "        # warmup\n",
    "        for _ in range(warmup):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "    avg_sec = (end - start) / iters\n",
    "    inference_ms = avg_sec * 1000.0\n",
    "\n",
    "    return {\n",
    "        \"params_m\": params_m,\n",
    "        \"flops_m\": flops_m,\n",
    "        \"inference_ms\": inference_ms,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a906d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 11-B. Single variant runner for MHEALTH\n",
    "# =====================================================================\n",
    "\n",
    "def run_experiment(base_config, variant_overrides, device):\n",
    "    \"\"\"\n",
    "    하나의 variant (예: 'Embed+CBAM')를 독립적으로 돌린다.\n",
    "    과정:\n",
    "      - 전체 MHEALTH 로드 & 전처리(윈도우링)  :contentReference[oaicite:1]{index=1}\n",
    "      - (60/20/20) random split 후 train/val/test 만들기  :contentReference[oaicite:2]{index=2}\n",
    "      - train 기준으로 StandardScaler fit 후 모든 split에 적용  :contentReference[oaicite:3]{index=3}\n",
    "      - CrossFormer를 쓸 경우 class mean feature로 prototype 초기화(get_mean_prototypes)  :contentReference[oaicite:4]{index=4}\n",
    "      - 학습(contrast 포함 여부는 use_contrast로 제어)  :contentReference[oaicite:5]{index=5}\n",
    "      - best val acc 기준 ckpt로 test 평가 + confusion matrix + t-SNE + 프로파일링  :contentReference[oaicite:6]{index=6}\n",
    "    \"\"\"\n",
    "\n",
    "    # 0) config 준비: base_config 복사 후 variant 설정 덮어쓰기\n",
    "    cfg = copy.deepcopy(base_config)\n",
    "    for k, v in variant_overrides.items():\n",
    "        if k == \"tag\":\n",
    "            continue\n",
    "        cfg[k] = v\n",
    "\n",
    "    seed_everything(cfg[\"seed\"])\n",
    "    DEVICE = device\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[{variant_overrides['tag']}] Dataset : {cfg['dataset_name']}\")\n",
    "    print(f\"Device  : {DEVICE}\")\n",
    "    print(\"=\" * 80)\n",
    "    pretty_print_config(cfg)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) 전체 MHEALTH 로드 (윈도우 시퀀스 만들기)\n",
    "    #    - label 0 (null) 제거 후 라벨을 0~11로 shift\n",
    "    #    - 각 윈도우 라벨은 마지막 프레임 라벨\n",
    "    # -------------------------------------------------\n",
    "    full_dataset_raw = MHEALTHDataset(\n",
    "        data_dir=cfg[\"data_dir\"],\n",
    "        window_size=cfg[\"window_size\"],\n",
    "        step_size=cfg[\"step_size\"],\n",
    "    )\n",
    "    label_names = full_dataset_raw.label_names\n",
    "\n",
    "    # shape 정보 -> cfg에 반영\n",
    "    cfg[\"in_channels\"]  = full_dataset_raw.X.shape[1]  # 23\n",
    "    cfg[\"seq_len\"]      = full_dataset_raw.X.shape[2]  # 128\n",
    "    cfg[\"n_classes\"]    = len(full_dataset_raw.label_names)  # 12\n",
    "    cfg[\"n_prototypes\"] = cfg[\"n_classes\"]  # class별 prototype 1:1\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) 60/20/20 split (random_split과 동일 아이디어)\n",
    "    # -------------------------------------------------\n",
    "    total_size = len(full_dataset_raw)\n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size   = int(0.2 * total_size)\n",
    "    test_size  = total_size - train_size - val_size\n",
    "\n",
    "    train_subset, val_subset, test_subset = random_split(\n",
    "        full_dataset_raw,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(cfg[\"seed\"])\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) 채널별 표준화(StandardScaler)\n",
    "    #    - train subset으로 fit\n",
    "    #    - 모든 split에 transform 적용\n",
    "    #    - 그리고 TensorDataset으로 바꿔줌\n",
    "    # -------------------------------------------------\n",
    "    def subset_to_numpy(subset):\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        for x_i, y_i in subset:\n",
    "            X_list.append(x_i.numpy())      # (C,T)\n",
    "            y_list.append(int(y_i.item()))\n",
    "        X_np = np.stack(X_list, axis=0)     # (N,C,T)\n",
    "        y_np = np.array(y_list, dtype=np.int64)\n",
    "        return X_np, y_np\n",
    "\n",
    "    X_train_raw, y_train = subset_to_numpy(train_subset)\n",
    "    X_val_raw,   y_val   = subset_to_numpy(val_subset)\n",
    "    X_test_raw,  y_test  = subset_to_numpy(test_subset)\n",
    "\n",
    "    C_in  = cfg[\"in_channels\"]\n",
    "    T_len = cfg[\"seq_len\"]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fit scaler on train (reshape to (N*T, C))\n",
    "    X_train_rs = X_train_raw.transpose(0, 2, 1).reshape(-1, C_in)\n",
    "    scaler.fit(X_train_rs)\n",
    "\n",
    "    def apply_scaler(X_raw):\n",
    "        X_rs   = X_raw.transpose(0, 2, 1).reshape(-1, C_in)  # (N*T, C)\n",
    "        X_norm = scaler.transform(X_rs)\n",
    "        X_out  = X_norm.reshape(-1, T_len, C_in).transpose(0, 2, 1)  # (N,C,T)\n",
    "        return X_out.astype(np.float32)\n",
    "\n",
    "    X_train = apply_scaler(X_train_raw)\n",
    "    X_val   = apply_scaler(X_val_raw)\n",
    "    X_test  = apply_scaler(X_test_raw)\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.from_numpy(X_train).float(),\n",
    "        torch.from_numpy(y_train).long()\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.from_numpy(X_val).float(),\n",
    "        torch.from_numpy(y_val).long()\n",
    "    )\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.from_numpy(X_test).float(),\n",
    "        torch.from_numpy(y_test).long()\n",
    "    )\n",
    "\n",
    "    # get_mean_prototypes는 train 전체 텐서데이터셋을 받도록 main에서 그렇게 썼으므로\n",
    "    train_full_dataset = train_dataset\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Split sizes -> train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4) DataLoader들 (seed 고정 / worker_init_fn 고정)\n",
    "    # -------------------------------------------------\n",
    "    g = torch.Generator().manual_seed(cfg[\"seed\"])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 5) Prototype 초기화 (CrossFormer를 쓰는 variant만)\n",
    "    # -------------------------------------------------\n",
    "    if cfg[\"use_crossformer\"]:\n",
    "        initial_prototypes = get_mean_prototypes(\n",
    "            train_full_dataset,\n",
    "            DEVICE,\n",
    "            cfg\n",
    "        )\n",
    "    else:\n",
    "        initial_prototypes = None\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 6) 모델 생성\n",
    "    # -------------------------------------------------\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels        = cfg[\"in_channels\"],\n",
    "        seq_len            = cfg[\"seq_len\"],\n",
    "        embed_dim          = cfg[\"embed_dim\"],\n",
    "        reduced_dim        = cfg[\"reduced_dim\"],\n",
    "        n_classes          = cfg[\"n_classes\"],\n",
    "        n_prototypes       = cfg[\"n_prototypes\"],\n",
    "        n_heads            = cfg[\"n_heads\"],\n",
    "        kernel_size        = cfg[\"kernel_size\"],\n",
    "        dropout            = cfg[\"dropout\"],\n",
    "        temperature        = cfg[\"temperature\"],\n",
    "        initial_prototypes = initial_prototypes,\n",
    "        use_cbam           = cfg[\"use_cbam\"],\n",
    "        use_crossformer    = cfg[\"use_crossformer\"],\n",
    "        use_contrast       = cfg[\"use_contrast\"],\n",
    "        use_dim_reduction  = cfg[\"use_dim_reduction\"],\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 7) Optimizer / Scheduler / Loss\n",
    "    # -------------------------------------------------\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg[\"learning_rate\"],\n",
    "        weight_decay=cfg[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    if cfg[\"scheduler_type\"] == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=cfg[\"scheduler_T_max\"],\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 8) Train Loop (best val acc checkpoint keep)\n",
    "    # -------------------------------------------------\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch   = -1\n",
    "    best_state   = None\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        # train step\n",
    "        train_total, train_ce, train_ct, train_acc, train_f1 = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            DEVICE,\n",
    "            use_contrast=cfg[\"use_contrast\"],\n",
    "            contrast_weight=cfg[\"contrast_weight\"],\n",
    "        )\n",
    "\n",
    "        # val step\n",
    "        val_total, val_acc, val_f1, _, _, val_ce, val_ct = evaluate(\n",
    "            model,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            DEVICE,\n",
    "            use_contrast=cfg[\"use_contrast\"],\n",
    "            contrast_weight=cfg[\"contrast_weight\"],\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_total\": train_total,\n",
    "            \"train_ce\": train_ce,\n",
    "            \"train_ct\": train_ct,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"train_f1\": train_f1,\n",
    "            \"val_total\": val_total,\n",
    "            \"val_ce\": val_ce,\n",
    "            \"val_ct\": val_ct,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch   = epoch + 1\n",
    "            best_state   = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % cfg[\"print_every\"] == 0:\n",
    "            ep_now   = epoch + 1\n",
    "            ep_total = cfg[\"epochs\"]\n",
    "            print(f\"[{variant_overrides['tag']}] Epoch {ep_now:03d}/{ep_total:03d}\")\n",
    "            print(\n",
    "                \"  train | \"\n",
    "                f\"total={train_total:.4f}  \"\n",
    "                f\"ce={train_ce:.4f}  \"\n",
    "                f\"ct={train_ct:.4f}  \"\n",
    "                f\"acc={train_acc:.4f}  \"\n",
    "                f\"f1={train_f1:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                \"  val   | \"\n",
    "                f\"total={val_total:.4f}  \"\n",
    "                f\"ce={val_ce:.4f}  \"\n",
    "                f\"ct={val_ct:.4f}  \"\n",
    "                f\"acc={val_acc:.4f}  \"\n",
    "                f\"f1={val_f1:.4f}\"\n",
    "            )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 9) Best ckpt로 교체 후 test 평가\n",
    "    # -------------------------------------------------\n",
    "    assert best_state is not None, \"No best_state saved??\"\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    test_total, test_acc, test_f1, test_preds, test_labels, test_ce, test_ct = evaluate(\n",
    "        model,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        DEVICE,\n",
    "        use_contrast=cfg[\"use_contrast\"],\n",
    "        contrast_weight=cfg[\"contrast_weight\"],\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[{variant_overrides['tag']}] Training Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(\n",
    "        f\"  Test(best ckpt): \"\n",
    "        f\"acc={test_acc:.4f}, f1={test_f1:.4f}, \"\n",
    "        f\"total_loss={test_total:.4f}, ce={test_ce:.4f}, ct={test_ct:.4f}\"\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 10) 모델 프로파일 (params/FLOPs/추론시간)\n",
    "    # -------------------------------------------------\n",
    "    stats_profile = None\n",
    "    if cfg[\"profile_model\"]:\n",
    "        dummy_input = torch.randn(\n",
    "            1,\n",
    "            cfg[\"in_channels\"],\n",
    "            cfg[\"seq_len\"],\n",
    "        )\n",
    "        stats_profile = profile_model(model, dummy_input, DEVICE)\n",
    "\n",
    "        print(\"==== Model Profile ====\")\n",
    "        print(f\"Parameters      : {stats_profile['params_m']:.4f} M\")\n",
    "        print(f\"FLOPs / sample : {stats_profile['flops_m']}\")\n",
    "        print(f\"Infer Time     : {stats_profile['inference_ms']:.2f} ms/sample\")\n",
    "        print(\"=======================\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 12) 결과 dict 반환 (테이블/CSV용)\n",
    "    # -------------------------------------------------\n",
    "    row = {\n",
    "        \"tag\":                    variant_overrides[\"tag\"],\n",
    "        \"use_cbam\":               cfg[\"use_cbam\"],\n",
    "        \"use_crossformer\":        cfg[\"use_crossformer\"],\n",
    "        \"use_contrast\":           cfg[\"use_contrast\"],\n",
    "        \"best_val_acc\":           best_val_acc,\n",
    "        \"test_acc\":               test_acc,\n",
    "        \"test_f1\":                test_f1,\n",
    "        \"test_total_loss\":        test_total,\n",
    "        \"test_ce\":                test_ce,\n",
    "        \"test_ct\":                test_ct,\n",
    "        \"params_m\":               stats_profile[\"params_m\"]     if stats_profile else None,\n",
    "        \"flops_m\":                stats_profile[\"flops_m\"]      if stats_profile else None,\n",
    "        \"inference_ms\":           stats_profile[\"inference_ms\"] if stats_profile else None,\n",
    "        \"best_epoch\":             best_epoch,\n",
    "    }\n",
    "\n",
    "    return row, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edee82eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[Embed+CBAM] Dataset : MHEALTH\n",
      "Device  : cuda\n",
      "================================================================================\n",
      "================================================================================\n",
      "EXPERIMENT CONFIG\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size                : 128\n",
      "contrast_weight           : 0.25\n",
      "data_dir                  : C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "dataset_name              : MHEALTH\n",
      "do_tsne                   : True\n",
      "dropout                   : 0.1\n",
      "embed_dim                 : 64\n",
      "epochs                    : 100\n",
      "in_channels               : 23\n",
      "kernel_size               : 7\n",
      "learning_rate             : 0.0005\n",
      "n_classes                 : 12\n",
      "n_heads                   : 8\n",
      "n_prototypes              : 12\n",
      "print_every               : 50\n",
      "profile_model             : True\n",
      "reduced_dim               : 32\n",
      "scheduler_T_max           : 100\n",
      "scheduler_type            : cosine\n",
      "seed                      : 42\n",
      "seq_len                   : 128\n",
      "step_size                 : 64\n",
      "subject_split_train_ratio : 0.6\n",
      "subject_split_val_ratio   : 0.2\n",
      "temperature               : 0.05\n",
      "use_cbam                  : True\n",
      "use_contrast              : False\n",
      "use_crossformer           : False\n",
      "use_dim_reduction         : False\n",
      "weight_decay              : 0.0001\n",
      "window_size               : 128\n",
      "================================================================================\n",
      "Found 10 log files in C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "================================================================================\n",
      "Loaded MHEALTH dataset\n",
      "  X shape : (5361, 23, 128)  (N, C, T)\n",
      "  y shape : (5361,)  (N,)\n",
      "  Classes : 12\n",
      "================================================================================\n",
      "================================================================================\n",
      "Split sizes -> train: 3216, val: 1072, test: 1073\n",
      "================================================================================\n",
      "Parameters: 49,946\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embed+CBAM] Epoch 050/100\n",
      "  train | total=0.0232  ce=0.0232  ct=0.0000  acc=0.9953  f1=0.9953\n",
      "  val   | total=0.0683  ce=0.0683  ct=0.0000  acc=0.9879  f1=0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embed+CBAM] Epoch 100/100\n",
      "  train | total=0.0093  ce=0.0093  ct=0.0000  acc=0.9981  f1=0.9981\n",
      "  val   | total=0.0775  ce=0.0775  ct=0.0000  acc=0.9888  f1=0.9889\n",
      "================================================================================\n",
      "[Embed+CBAM] Training Complete!\n",
      "  Best Val Acc: 0.9897 @ epoch 62\n",
      "  Test(best ckpt): acc=0.9888, f1=0.9888, total_loss=0.0714, ce=0.0714, ct=0.0000\n",
      "==== Model Profile ====\n",
      "Parameters      : 0.0499 M\n",
      "FLOPs / sample : 3.523072\n",
      "Infer Time     : 1.09 ms/sample\n",
      "=======================\n",
      "================================================================================\n",
      "[CBAM+CrossFormer (noContrast)] Dataset : MHEALTH\n",
      "Device  : cuda\n",
      "================================================================================\n",
      "================================================================================\n",
      "EXPERIMENT CONFIG\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size                : 128\n",
      "contrast_weight           : 0.25\n",
      "data_dir                  : C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "dataset_name              : MHEALTH\n",
      "do_tsne                   : True\n",
      "dropout                   : 0.1\n",
      "embed_dim                 : 64\n",
      "epochs                    : 100\n",
      "in_channels               : 23\n",
      "kernel_size               : 7\n",
      "learning_rate             : 0.0005\n",
      "n_classes                 : 12\n",
      "n_heads                   : 8\n",
      "n_prototypes              : 12\n",
      "print_every               : 50\n",
      "profile_model             : True\n",
      "reduced_dim               : 32\n",
      "scheduler_T_max           : 100\n",
      "scheduler_type            : cosine\n",
      "seed                      : 42\n",
      "seq_len                   : 128\n",
      "step_size                 : 64\n",
      "subject_split_train_ratio : 0.6\n",
      "subject_split_val_ratio   : 0.2\n",
      "temperature               : 0.05\n",
      "use_cbam                  : True\n",
      "use_contrast              : False\n",
      "use_crossformer           : True\n",
      "use_dim_reduction         : False\n",
      "weight_decay              : 0.0001\n",
      "window_size               : 128\n",
      "================================================================================\n",
      "Found 10 log files in C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "================================================================================\n",
      "Loaded MHEALTH dataset\n",
      "  X shape : (5361, 23, 128)  (N, C, T)\n",
      "  y shape : (5361,)  (N,)\n",
      "  Classes : 12\n",
      "================================================================================\n",
      "================================================================================\n",
      "Split sizes -> train: 3216, val: 1072, test: 1073\n",
      "================================================================================\n",
      "Calculating initial prototypes from mean features...\n",
      "Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 26/26 [00:00<00:00, 123.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([12, 64])\n",
      "Prototypes initialized with calculated mean features.\n",
      "Parameters: 75,802\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CBAM+CrossFormer (noContrast)] Epoch 050/100\n",
      "  train | total=0.0039  ce=0.0039  ct=0.0000  acc=0.9994  f1=0.9994\n",
      "  val   | total=0.0771  ce=0.0771  ct=0.0000  acc=0.9897  f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CBAM+CrossFormer (noContrast)] Epoch 100/100\n",
      "  train | total=0.0018  ce=0.0018  ct=0.0000  acc=0.9994  f1=0.9994\n",
      "  val   | total=0.0799  ce=0.0799  ct=0.0000  acc=0.9897  f1=0.9898\n",
      "================================================================================\n",
      "[CBAM+CrossFormer (noContrast)] Training Complete!\n",
      "  Best Val Acc: 0.9916 @ epoch 33\n",
      "  Test(best ckpt): acc=0.9897, f1=0.9898, total_loss=0.0702, ce=0.0702, ct=0.0000\n",
      "==== Model Profile ====\n",
      "Parameters      : 0.0758 M\n",
      "FLOPs / sample : 4.90752\n",
      "Infer Time     : 2.15 ms/sample\n",
      "=======================\n",
      "================================================================================\n",
      "[CBAM+CrossFormer+Contrast (Full Model)] Dataset : MHEALTH\n",
      "Device  : cuda\n",
      "================================================================================\n",
      "================================================================================\n",
      "EXPERIMENT CONFIG\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size                : 128\n",
      "contrast_weight           : 0.25\n",
      "data_dir                  : C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "dataset_name              : MHEALTH\n",
      "do_tsne                   : True\n",
      "dropout                   : 0.1\n",
      "embed_dim                 : 64\n",
      "epochs                    : 100\n",
      "in_channels               : 23\n",
      "kernel_size               : 7\n",
      "learning_rate             : 0.0005\n",
      "n_classes                 : 12\n",
      "n_heads                   : 8\n",
      "n_prototypes              : 12\n",
      "print_every               : 50\n",
      "profile_model             : True\n",
      "reduced_dim               : 32\n",
      "scheduler_T_max           : 100\n",
      "scheduler_type            : cosine\n",
      "seed                      : 42\n",
      "seq_len                   : 128\n",
      "step_size                 : 64\n",
      "subject_split_train_ratio : 0.6\n",
      "subject_split_val_ratio   : 0.2\n",
      "temperature               : 0.05\n",
      "use_cbam                  : True\n",
      "use_contrast              : True\n",
      "use_crossformer           : True\n",
      "use_dim_reduction         : False\n",
      "weight_decay              : 0.0001\n",
      "window_size               : 128\n",
      "================================================================================\n",
      "Found 10 log files in C://Users/park9/CBAM_HAR/MHEALTH/MHEALTHDATASET\n",
      "================================================================================\n",
      "Loaded MHEALTH dataset\n",
      "  X shape : (5361, 23, 128)  (N, C, T)\n",
      "  y shape : (5361,)  (N,)\n",
      "  Classes : 12\n",
      "================================================================================\n",
      "================================================================================\n",
      "Split sizes -> train: 3216, val: 1072, test: 1073\n",
      "================================================================================\n",
      "Calculating initial prototypes from mean features...\n",
      "Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 26/26 [00:00<00:00, 137.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prototypes calculated. Shape: torch.Size([12, 64])\n",
      "Prototypes initialized with calculated mean features.\n",
      "Parameters: 75,802\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CBAM+CrossFormer+Contrast (Full Model)] Epoch 050/100\n",
      "  train | total=0.0032  ce=0.0025  ct=0.0026  acc=0.9997  f1=0.9997\n",
      "  val   | total=0.0889  ce=0.0716  ct=0.0692  acc=0.9897  f1=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CBAM+CrossFormer+Contrast (Full Model)] Epoch 100/100\n",
      "  train | total=0.0011  ce=0.0008  ct=0.0009  acc=1.0000  f1=1.0000\n",
      "  val   | total=0.0993  ce=0.0807  ct=0.0743  acc=0.9888  f1=0.9889\n",
      "================================================================================\n",
      "[CBAM+CrossFormer+Contrast (Full Model)] Training Complete!\n",
      "  Best Val Acc: 0.9916 @ epoch 24\n",
      "  Test(best ckpt): acc=0.9916, f1=0.9916, total_loss=0.0582, ce=0.0473, ct=0.0435\n",
      "==== Model Profile ====\n",
      "Parameters      : 0.0758 M\n",
      "FLOPs / sample : 4.90752\n",
      "Infer Time     : 2.28 ms/sample\n",
      "=======================\n",
      "\n",
      "================================================================================\n",
      "MHEALTH Ablation Summary\n",
      "================================================================================\n",
      "                                   tag  use_cbam  use_crossformer  use_contrast  best_val_acc  test_acc  test_f1  params_m  flops_m  inference_ms  best_epoch\n",
      "                            Embed+CBAM      True            False         False      0.989739  0.988816 0.988803  0.049946 3.523072      1.087646          62\n",
      "         CBAM+CrossFormer (noContrast)      True             True         False      0.991604  0.989748 0.989793  0.075802 4.907520      2.154675          33\n",
      "CBAM+CrossFormer+Contrast (Full Model)      True             True          True      0.991604  0.991612 0.991636  0.075802 4.907520      2.282825          24\n",
      "Saved ablation_results_MHEALTH.csv\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# 11-C. Ablation main for MHEALTH\n",
    "# =====================================================================\n",
    "\n",
    "def main_ablation():\n",
    "    \"\"\"\n",
    "    MHEALTH 데이터셋에 대해 3개 variant:\n",
    "      1) Embed+CBAM\n",
    "      2) CBAM+CrossFormer (noContrast)\n",
    "      3) CBAM+CrossFormer+Contrast (Full Model)\n",
    "    각각 독립 실행하고 결과 요약표를 CSV로 저장.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    variants = [\n",
    "        {\n",
    "            # 가장 라이트: Conv Embedding + CBAM + Global Pool + Classifier\n",
    "            # no CrossFormer, no Contrast\n",
    "            \"tag\": \"Embed+CBAM\",\n",
    "            \"use_cbam\": True,\n",
    "            \"use_crossformer\": False,\n",
    "            \"use_contrast\": False,\n",
    "        },\n",
    "        {\n",
    "            # CrossFormer까지, contrast 없음\n",
    "            \"tag\": \"CBAM+CrossFormer (noContrast)\",\n",
    "            \"use_cbam\": True,\n",
    "            \"use_crossformer\": True,\n",
    "            \"use_contrast\": False,\n",
    "        },\n",
    "        {\n",
    "            # 풀모델: CrossFormer + Contrastive Prototype Loss\n",
    "            \"tag\": \"CBAM+CrossFormer+Contrast (Full Model)\",\n",
    "            \"use_cbam\": True,\n",
    "            \"use_crossformer\": True,\n",
    "            \"use_contrast\": True,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    all_rows = []\n",
    "    all_histories = {}\n",
    "\n",
    "    for v in variants:\n",
    "        row, hist = run_experiment(CONFIG, v, device)\n",
    "        all_rows.append(row)\n",
    "        all_histories[v[\"tag\"]] = hist  # epoch curve 보고 싶으면 나중에 쓰면 됨\n",
    "\n",
    "    df = pd.DataFrame(all_rows, columns=[\n",
    "        \"tag\",\n",
    "        \"use_cbam\",\n",
    "        \"use_crossformer\",\n",
    "        \"use_contrast\",\n",
    "        \"best_val_acc\",\n",
    "        \"test_acc\",\n",
    "        \"test_f1\",\n",
    "        \"params_m\",\n",
    "        \"flops_m\",\n",
    "        \"inference_ms\",\n",
    "        \"best_epoch\",\n",
    "    ])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MHEALTH Ablation Summary\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    df.to_csv(\"ablation_results_MHEALTH.csv\", index=False)\n",
    "    print(\"Saved ablation_results_MHEALTH.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_ablation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
