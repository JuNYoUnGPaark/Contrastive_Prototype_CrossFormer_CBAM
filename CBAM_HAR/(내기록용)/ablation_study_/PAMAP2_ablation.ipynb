{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7340188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-1. Library Import \n",
    "# =================================================================================\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import io\n",
    "import contextlib\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# fvcore (optional)\n",
    "try:\n",
    "    from fvcore.nn import FlopCountAnalysis\n",
    "    FVCORE_AVAILABLE = True\n",
    "except Exception:\n",
    "    FlopCountAnalysis = None\n",
    "    FVCORE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9262ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-2. Define CONFIG \n",
    "# =================================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # ---------------------------\n",
    "    # Reproducibility / Experiment ID\n",
    "    # ---------------------------\n",
    "    \"seed\": 42,\n",
    "    \"dataset_name\": \"PAMAP2\",\n",
    "\n",
    "    # ---------------------------\n",
    "    # Data / Split\n",
    "    # ---------------------------\n",
    "    \"data_dir\": \"C://Users/park9/CBAM_HAR/PAMAP2\", \n",
    "    \"train_subject_ratio\": 0.6,\n",
    "    \"val_subject_ratio\": 0.25,\n",
    "\n",
    "    \"batch_size\": 128,  # dataloader\n",
    "\n",
    "    \"window_size\": 250,  # 500, 250 \n",
    "    \"step_size\": 125,\n",
    "\n",
    "    # ---------------------------\n",
    "    # Training\n",
    "    # ---------------------------\n",
    "    \"epochs\": 50,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"contrast_weight\": 0.35,  # total_loss = CE + contrast_weight * contrast_loss\n",
    "    \"scheduler_type\": \"cosine\", # scheduler (CosineAnnealingLR)\n",
    "    \"scheduler_T_max\": 100,  # CosineAnnealingLR(T_max=EPOCHS)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Model architecture (PAMAP2)\n",
    "    # ---------------------------\n",
    "    \"in_channels\": 36,        # 9 inertial signals (acc/gyro/total xyz)\n",
    "    \"seq_len\": 250,          # window length\n",
    "    \"n_classes\": 12,          # HAR classes\n",
    "    \"n_prototypes\": 12,       # prototype counts\n",
    "\n",
    "    \"embed_dim\": 64,         # Conv1d -> Transformer base dim\n",
    "    \"reduced_dim\": 32,       # if we use_dim_reduction == True\n",
    "    \"use_dim_reduction\": False,\n",
    "\n",
    "    \"n_heads\": 8,            # multi-head attention heads in CrossFormer block\n",
    "    \"dropout\": 0.1,\n",
    "\n",
    "    \"kernel_size\": 7,       # kernel sizes used in Conv1d embedding and CBAM temporal attention\n",
    "\n",
    "    # ---------------------------\n",
    "    # Feature toggles (ablations)\n",
    "    # ---------------------------\n",
    "    \"use_cbam\": True,        # CBAM\n",
    "    \"use_crossformer\": True, # CrossFormerBlock\n",
    "    \"use_contrast\": True,    # include contrastive prototype loss during training\n",
    "\n",
    "    # ---------------------------\n",
    "    # Contrast / Prototype behavior\n",
    "    # ---------------------------\n",
    "    \"temperature\": 0.05,     # temperature in contrastive loss\n",
    "\n",
    "    # ---------------------------\n",
    "    # Logging / Debug convenience\n",
    "    # ---------------------------\n",
    "    \"print_every\": 50,        # print every or bumped epoch\n",
    "    \"do_tsne\": True,        # t-SNE\n",
    "    \"profile_model\": True,  # FLOPs / Params\n",
    "}\n",
    "\n",
    "def pretty_print_config(cfg: dict):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXPERIMENT CONFIG\")\n",
    "    print(\"-\" * 80)\n",
    "    # key alignment\n",
    "    max_k = max(len(k) for k in cfg.keys())\n",
    "    for k in sorted(cfg.keys()):\n",
    "        print(f\"{k.ljust(max_k)} : {cfg[k]}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8cbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-3. Reproducibility helpers\n",
    "# =================================================================================\n",
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Fix random seeds for reproducibility across random, numpy, torch (cpu & cuda).\n",
    "    Also configures CuDNN for deterministic behavior.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # cudnn deterministic mode: reproducible but may be slower\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    To make DataLoader workers deterministic.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4a0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pamap2_windows(df: pd.DataFrame, window_size: int, step_size: int):\n",
    "    \"\"\"\n",
    "    subject별로 timestamp 순서대로 전체 시계열을 따라가며 슬라이딩 윈도우 생성.\n",
    "    한 윈도우의 라벨은 마지막 프레임의 activityID.\n",
    "    마지막 라벨이 0(Null/기타) 이면 그 윈도우는 버린다.\n",
    "\n",
    "    Returns:\n",
    "        X:          (N, C, T) float32\n",
    "        y:          (N,) int64  (0..11로 리맵된 레이블)\n",
    "        subj_ids:   (N,) int64\n",
    "        label_names:list[str] 길이 12, new_index -> human-readable\n",
    "    \"\"\"\n",
    "\n",
    "    # 사용할 피처들 (orientation*, heartrate, *_Temperature 등은 제외)\n",
    "    feature_cols = [\n",
    "        # hand\n",
    "        \"handAcc16_1\",\"handAcc16_2\",\"handAcc16_3\",\n",
    "        \"handAcc6_1\",\"handAcc6_2\",\"handAcc6_3\",\n",
    "        \"handGyro1\",\"handGyro2\",\"handGyro3\",\n",
    "        \"handMagne1\",\"handMagne2\",\"handMagne3\",\n",
    "        # chest\n",
    "        \"chestAcc16_1\",\"chestAcc16_2\",\"chestAcc16_3\",\n",
    "        \"chestAcc6_1\",\"chestAcc6_2\",\"chestAcc6_3\",\n",
    "        \"chestGyro1\",\"chestGyro2\",\"chestGyro3\",\n",
    "        \"chestMagne1\",\"chestMagne2\",\"chestMagne3\",\n",
    "        # ankle\n",
    "        \"ankleAcc16_1\",\"ankleAcc16_2\",\"ankleAcc16_3\",\n",
    "        \"ankleAcc6_1\",\"ankleAcc6_2\",\"ankleAcc6_3\",\n",
    "        \"ankleGyro1\",\"ankleGyro2\",\"ankleGyro3\",\n",
    "        \"ankleMagne1\",\"ankleMagne2\",\"ankleMagne3\",\n",
    "    ]\n",
    "\n",
    "    # PAMAP2 실제 activityID들 중 우리가 쓰는 12개 클래스만 남김\n",
    "    # 순서 고정: 이 순서가 new class index 0..11이 된다.\n",
    "    ORDERED_IDS = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "\n",
    "    # 원본 activityID -> new index(0..11)\n",
    "    old2new = {\n",
    "        1: 0,   # Lying\n",
    "        2: 1,   # Sitting\n",
    "        3: 2,   # Standing\n",
    "        4: 3,   # Walking\n",
    "        5: 4,   # Running\n",
    "        6: 5,   # Cycling\n",
    "        7: 6,   # Nordic walking\n",
    "        12: 7,  # Ascending stairs\n",
    "        13: 8,  # Descending stairs\n",
    "        16: 9,  # Vacuum cleaning\n",
    "        17: 10, # Ironing\n",
    "        24: 11, # Rope jumping\n",
    "    }\n",
    "\n",
    "    # new index -> 사람이 읽는 이름\n",
    "    label_names = [\n",
    "        \"Lying\",              # 0 -> orig 1\n",
    "        \"Sitting\",            # 1 -> orig 2\n",
    "        \"Standing\",           # 2 -> orig 3\n",
    "        \"Walking\",            # 3 -> orig 4\n",
    "        \"Running\",            # 4 -> orig 5\n",
    "        \"Cycling\",            # 5 -> orig 6\n",
    "        \"Nordic walking\",     # 6 -> orig 7\n",
    "        \"Ascending stairs\",   # 7 -> orig 12\n",
    "        \"Descending stairs\",  # 8 -> orig 13\n",
    "        \"Vacuum cleaning\",    # 9 -> orig 16\n",
    "        \"Ironing\",            # 10 -> orig 17\n",
    "        \"Rope jumping\",       # 11 -> orig 24\n",
    "    ]\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    subj_list = []\n",
    "\n",
    "    # subject별로 끊어서 시간 순 정렬 후 슬라이딩 윈도우\n",
    "    for subj_id, g in df.groupby(\"subject_id\"):\n",
    "        # 시간순 정렬\n",
    "        if \"timestamp\" in g.columns:\n",
    "            g = g.sort_values(\"timestamp\")\n",
    "        else:\n",
    "            g = g.sort_index()\n",
    "\n",
    "        data_arr  = g[feature_cols].to_numpy(dtype=np.float32)   # (L, C)\n",
    "        label_arr = g[\"activityID\"].to_numpy(dtype=np.int64)     # (L,)\n",
    "        L = data_arr.shape[0]\n",
    "\n",
    "        start = 0\n",
    "        while start + window_size <= L:\n",
    "            end = start + window_size\n",
    "\n",
    "            last_label_orig = int(label_arr[end - 1])\n",
    "\n",
    "            # 0 = \"other / null\" → 버림\n",
    "            if last_label_orig == 0:\n",
    "                start += step_size\n",
    "                continue\n",
    "\n",
    "            # 우리가 쓰는 12개 클래스에 없는 라벨이면 버림\n",
    "            if last_label_orig not in old2new:\n",
    "                start += step_size\n",
    "                continue\n",
    "\n",
    "            # 윈도우 추출\n",
    "            window_ct = data_arr[start:end].T  # (T, C) -> (C, T)\n",
    "\n",
    "            X_list.append(window_ct)\n",
    "            y_list.append(old2new[last_label_orig])\n",
    "            subj_list.append(int(subj_id))\n",
    "\n",
    "            start += step_size\n",
    "\n",
    "    # numpy 변환\n",
    "    X = np.stack(X_list, axis=0).astype(np.float32)      # (N, C, T)\n",
    "    y = np.asarray(y_list, dtype=np.int64)               # (N,)\n",
    "    subj_ids = np.asarray(subj_list, dtype=np.int64)     # (N,)\n",
    "\n",
    "    return X, y, subj_ids, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae708afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 1-4. Dataset: PAMAP2\n",
    "# =================================================================================\n",
    "class PAMAP2Dataset(Dataset):\n",
    "    def __init__(self, data_dir, window_size, step_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) CSV 전부 읽어서 concat\n",
    "        csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "        if len(csv_files) == 0:\n",
    "            raise RuntimeError(f\"No CSV files found under {data_dir}\")\n",
    "\n",
    "        dfs = []\n",
    "        for fpath in sorted(csv_files):\n",
    "            df_i = pd.read_csv(fpath)\n",
    "\n",
    "            # subject_id 없으면 파일명에서 추정\n",
    "            if \"subject_id\" not in df_i.columns:\n",
    "                m = re.findall(r\"\\d+\", os.path.basename(fpath))\n",
    "                subj_guess = int(m[0]) if len(m) > 0 else 0\n",
    "                df_i[\"subject_id\"] = subj_guess\n",
    "\n",
    "            dfs.append(df_i)\n",
    "\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # ---------- (A) 우선 activityID / subject_id 를 숫자로 안전하게 변환 ----------\n",
    "        # 문자열, 빈칸 등은 NaN으로 처리\n",
    "        df[\"activityID\"] = pd.to_numeric(df[\"activityID\"], errors=\"coerce\")\n",
    "        df[\"subject_id\"] = pd.to_numeric(df[\"subject_id\"], errors=\"coerce\")\n",
    "\n",
    "        # timestamp도 숫자로\n",
    "        if \"timestamp\" in df.columns:\n",
    "            df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "        # ---------- (B) subject_id는 NaN이면 버리는 게 맞고, activityID는 NaN이면 0으로 두는 게 편함 ----------\n",
    "        # 이유:\n",
    "        #   - 아래 create_pamap2_windows()에서 last_label_orig == 0 이면 그냥 윈도우 스킵하거든\n",
    "        #   - 즉 0은 \"기타/라벨없음\" 취급이라 안전한 더미 클래스\n",
    "        df = df.dropna(subset=[\"subject_id\"])  # subject_id 없는 row는 쓸 수가 없음\n",
    "        df[\"activityID\"] = df[\"activityID\"].fillna(0)\n",
    "\n",
    "        # 이제 안전하게 int 캐스팅\n",
    "        df[\"activityID\"] = df[\"activityID\"].astype(np.int64)\n",
    "        df[\"subject_id\"] = df[\"subject_id\"].astype(np.int64)\n",
    "\n",
    "        # ---------- (C) 나머지 feature 결측치 처리 / 보간 ----------\n",
    "        feature_cols = [\n",
    "            \"handAcc16_1\",\"handAcc16_2\",\"handAcc16_3\",\n",
    "            \"handAcc6_1\",\"handAcc6_2\",\"handAcc6_3\",\n",
    "            \"handGyro1\",\"handGyro2\",\"handGyro3\",\n",
    "            \"handMagne1\",\"handMagne2\",\"handMagne3\",\n",
    "            \"chestAcc16_1\",\"chestAcc16_2\",\"chestAcc16_3\",\n",
    "            \"chestAcc6_1\",\"chestAcc6_2\",\"chestAcc6_3\",\n",
    "            \"chestGyro1\",\"chestGyro2\",\"chestGyro3\",\n",
    "            \"chestMagne1\",\"chestMagne2\",\"chestMagne3\",\n",
    "            \"ankleAcc16_1\",\"ankleAcc16_2\",\"ankleAcc16_3\",\n",
    "            \"ankleAcc6_1\",\"ankleAcc6_2\",\"ankleAcc6_3\",\n",
    "            \"ankleGyro1\",\"ankleGyro2\",\"ankleGyro3\",\n",
    "            \"ankleMagne1\",\"ankleMagne2\",\"ankleMagne3\",\n",
    "        ]\n",
    "\n",
    "        def _fill_subject_group(g):\n",
    "            # subject별로 시간 순 정렬\n",
    "            if \"timestamp\" in g.columns:\n",
    "                g = g.sort_values(\"timestamp\")\n",
    "            else:\n",
    "                g = g.sort_index()\n",
    "\n",
    "            # 센서값 결측치 보간 + ffill/bfill\n",
    "            g[feature_cols] = (\n",
    "                g[feature_cols]\n",
    "                .interpolate(method=\"linear\", limit_direction=\"both\", axis=0)\n",
    "                .ffill()\n",
    "                .bfill()\n",
    "            )\n",
    "            return g\n",
    "\n",
    "        df = df.groupby(\"subject_id\", group_keys=False).apply(_fill_subject_group)\n",
    "\n",
    "        # 혹시 남은 NaN safety net\n",
    "        df[feature_cols] = df[feature_cols].fillna(0.0)\n",
    "\n",
    "        # ---------- (D) 표준화 ----------\n",
    "        scaler = StandardScaler()\n",
    "        df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "        # ---------- (E) 윈도우 생성 ----------\n",
    "        X, y, subj_ids, label_names = create_pamap2_windows(\n",
    "            df,\n",
    "            window_size=window_size,\n",
    "            step_size=step_size,\n",
    "        )\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.subject_ids = subj_ids\n",
    "        self.label_names = label_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]).float(),\n",
    "            torch.tensor(self.y[idx], dtype=torch.long),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c9182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2-1. CBAM1D\n",
    "# =================================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Channel attention for 1D multichannel sensor windows.\n",
    "\n",
    "    Input :  (B, C, T)\n",
    "             C = embedding dim after first Conv1d (e.g. 64)\n",
    "             T = temporal length of the window (e.g. 500 for PAMAP2)\n",
    "    Output:  (B, C, T) reweighted per channel\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x : (B, C, T)\n",
    "        avg_out = self.avg_pool(x).squeeze(-1)  # (B, C)\n",
    "        max_out = self.max_pool(x).squeeze(-1)  # (B, C)\n",
    "\n",
    "        avg_out = self.fc(avg_out)  # (B, C)\n",
    "        max_out = self.fc(max_out)  # (B, C)\n",
    "\n",
    "        out = (avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        scale = self.sigmoid(out)                # (B, C, 1)\n",
    "        return x * scale                         # broadcast over T\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention for 1D multichannel sensor windows.\n",
    "\n",
    "    Input : (B, C, T)\n",
    "    Output: (B, C, T) reweighted per timestep.\n",
    "\n",
    "    Mechanism:\n",
    "      - pool along channels (avg & max) → concat → 1D conv over time.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size: int = 7):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=2,\n",
    "            out_channels=1,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            bias=False\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, T)\n",
    "\n",
    "        attn_in = torch.cat([avg_out, max_out], dim=1)   # (B, 2, T)\n",
    "        attn_map = self.conv(attn_in)                    # (B, 1, T)\n",
    "        attn_map = self.sigmoid(attn_map)                # (B, 1, T)\n",
    "        return x * attn_map                              # broadcast over C\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    \"\"\"\n",
    "    CBAM for 1D sensor time-series.\n",
    "    Applies:\n",
    "      1) ChannelAttention1D  (what channels are important?)\n",
    "      2) TemporalAttention1D (when in time is important?)\n",
    "\n",
    "    Input / Output: (B, C, T)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, reduction: int = 16, kernel_size: int = 7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction=reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size=kernel_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7715cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2-2. CrossFormer Block (Cross-Attn between tokens and learnable prototypes)\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 n_prototypes: int = 6,\n",
    "                 n_heads: int = 4,\n",
    "                 mlp_ratio: float = 2.0,\n",
    "                 dropout: float = 0.1,\n",
    "                 initial_prototypes: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: token embedding dim\n",
    "            n_prototypes: number of learnable class prototypes\n",
    "            n_heads: attention heads (must divide dim)\n",
    "            mlp_ratio: FFN expansion ratio\n",
    "            dropout: dropout inside MHA/MLP\n",
    "            initial_prototypes: optional (n_prototypes, dim) tensor to init prototypes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable prototypes\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\"Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\"Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        # Cross-attention (tokens Q) x (prototypes K,V)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=n_heads,\n",
    "                                                dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Self-attention on tokens\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=n_heads,\n",
    "                                               dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # FFN\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # Projection for contrastive proto features\n",
    "        self.proto_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                return_proto_features: bool = False,\n",
    "                skip_cross_attention: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, C=dim)\n",
    "            return_proto_features: if True, also returns pooled/proj features for contrast\n",
    "            skip_cross_attention: if True, bypass cross-attn (used for proto init feature extraction)\n",
    "        Returns:\n",
    "            If return_proto_features:\n",
    "                (x_out, proto_features, cross_attn_weights)\n",
    "            else:\n",
    "                x_out\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        attn_weights = None\n",
    "\n",
    "        # 1) Cross-Attention (optional)\n",
    "        if not skip_cross_attention:\n",
    "            # normalize prototypes for stable attention keys/values\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1, eps=1e-6)  # (P, C)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).expand(B, -1, -1)  # (B, P, C)\n",
    "\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out  # residual\n",
    "\n",
    "        # 2) Self-Attention\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out  # residual\n",
    "\n",
    "        # 3) FFN\n",
    "        x = x + self.mlp(self.norm3(x))  # residual\n",
    "\n",
    "        if return_proto_features:\n",
    "            proto_features = x.mean(dim=1)  # (B, C)\n",
    "            proto_features = self.proto_proj(proto_features)  # (B, C)\n",
    "            return x, proto_features, attn_weights\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f56fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2-3. Contrastive Prototype Loss\n",
    "# =================================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised prototype contrast loss.\n",
    "\n",
    "    For each sample embedding f_i and class prototypes P (1 per class),\n",
    "    we compute a softmax over cosine similarities and apply cross-entropy\n",
    "    against the ground truth label.\n",
    "\n",
    "    Intuition:\n",
    "      - Pull sample features closer to their class prototype.\n",
    "      - Push them away from other class prototypes.\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature: float = 0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,    # (B, D)\n",
    "        prototypes: torch.Tensor,  # (num_classes, D)\n",
    "        labels: torch.Tensor       # (B,)\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features:  batch embeddings (B, D)\n",
    "            prototypes: class prototype matrix (num_classes, D)\n",
    "                        usually num_classes == n_prototypes\n",
    "            labels:    ground-truth class indices, shape (B,), dtype long\n",
    "\n",
    "        Returns:\n",
    "            scalar loss (tensor)\n",
    "        \"\"\"\n",
    "        # L2 normalize\n",
    "        features = F.normalize(features, dim=1, eps=1e-6)\n",
    "        prototypes = F.normalize(prototypes, dim=1, eps=1e-6)\n",
    "\n",
    "        # cosine similarity\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature  # (B, num_classes)\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d911c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2-4. Final Model: embedding + (CBAM) + CrossFormer + classifier\n",
    "# =================================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    \"\"\"\n",
    "    Sensor sequence classifier with:\n",
    "      - Conv1d embedding (+ BatchNorm + GELU + Dropout)\n",
    "      - Optional CBAM (channel & temporal attention)\n",
    "      - Either:\n",
    "          (A) CrossFormer block with learnable prototypes\n",
    "        or\n",
    "          (B) TransformerEncoderLayer-only self-attention fallback\n",
    "      - Global average pooling over time\n",
    "      - MLP classifier head\n",
    "      - (Optional) contrastive prototype loss\n",
    "\n",
    "    Args:\n",
    "        in_channels:   # sensor channels (e.g. 9 for UCI-HAR)\n",
    "        seq_len:       # sequence length (e.g. 128 for UCI-HAR); mostly for reference / profiling\n",
    "        embed_dim:     # conv embedding dim (and final feature dim if no reduction)\n",
    "        reduced_dim:   # reduced dim if use_dim_reduction=True\n",
    "        n_classes:     # num activity classes\n",
    "        n_prototypes:  # number of learnable prototypes in CrossFormer\n",
    "        n_heads:       # attention heads for CrossFormer/self-attn\n",
    "        kernel_size:   # conv1d kernel size for embedding, and CBAM temporal kernel\n",
    "        dropout:       # dropout rate\n",
    "        temperature:   # temperature for contrastive loss\n",
    "        initial_prototypes:  # tensor to init CrossFormerBlock.prototypes, or None\n",
    "        use_cbam:      # if True, apply CBAM after embedding\n",
    "        use_crossformer:     # if True, use CrossFormerBlock; else use vanilla self-attn block\n",
    "        use_contrast:        # if True, model can return contrastive loss\n",
    "        use_dim_reduction:   # if True, reduce dim before attention and restore after\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 9,\n",
    "                 seq_len: int = 128,\n",
    "                 embed_dim: int = 64,\n",
    "                 reduced_dim: int = 32,\n",
    "                 n_classes: int = 6,\n",
    "                 n_prototypes: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 kernel_size: int = 7,\n",
    "                 dropout: float = 0.1,\n",
    "                 temperature: float = 0.07,\n",
    "                 initial_prototypes: torch.Tensor = None,\n",
    "                 use_cbam: bool = True,\n",
    "                 use_crossformer: bool = True,\n",
    "                 use_contrast: bool = True,\n",
    "                 use_dim_reduction: bool = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save config\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.reduced_dim = reduced_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        # 1) Embedding: Conv1d -> BN -> GELU -> Dropout\n",
    "        #    Input:  (B, in_channels, T)\n",
    "        #    Output: (B, embed_dim, T)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels,\n",
    "                embed_dim,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=(kernel_size - 1) // 2,  # \"same\" padding for odd kernel\n",
    "            ),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # 2) Optional CBAM\n",
    "        #    Still (B, embed_dim, T)\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(\n",
    "                channels=embed_dim,\n",
    "                reduction=8,\n",
    "                kernel_size=kernel_size,\n",
    "            )\n",
    "\n",
    "        # 3) (Optional) Dim Reduction before attention\n",
    "        #    We'll call this dimension 'working_dim'.\n",
    "        #    If use_dim_reduction=False, working_dim == embed_dim.\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        # 4) Attention backbone\n",
    "        #    A) CrossFormerBlock (our prototype-based block)\n",
    "        #    B) Fallback: vanilla TransformerEncoderLayer\n",
    "        #    Input to these blocks: (B, T, working_dim)\n",
    "        #    Output shape stays (B, T, working_dim)\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim,\n",
    "                n_prototypes=n_prototypes,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=2.0,\n",
    "                dropout=dropout,\n",
    "                initial_prototypes=initial_prototypes,\n",
    "            )\n",
    "        else:\n",
    "            # TransformerEncoderLayer returns same shape (B, T, working_dim)\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "\n",
    "        # 5) (Optional) Dim restore after attention\n",
    "        #    Back to embed_dim if we reduced.\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        # 6) Temporal pooling + classifier head\n",
    "        #    After attention we get (B, T, embed_dim)\n",
    "        #    -> transpose to (B, embed_dim, T)\n",
    "        #    -> AdaptiveAvgPool1d(1) -> (B, embed_dim)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes),\n",
    "        )\n",
    "\n",
    "        # 7) Contrastive loss module (optional)\n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                labels: torch.Tensor = None,\n",
    "                return_contrast_loss: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, C_in, T)  e.g. (B, 9, 128)\n",
    "            labels: (B,) long tensor with class indices [0..n_classes-1]\n",
    "            return_contrast_loss: if True, we also compute contrastive loss\n",
    "\n",
    "        Returns:\n",
    "            if return_contrast_loss and use_contrast:\n",
    "                (logits, contrast_loss)\n",
    "            else:\n",
    "                logits\n",
    "        \"\"\"\n",
    "        # 1) Conv embedding (+CBAM)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "\n",
    "        # 2) Prepare for attention\n",
    "        #    (B, embed_dim, T) -> (B, T, embed_dim)\n",
    "        #    Optionally reduce dim\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "\n",
    "        # 3) Attention backbone\n",
    "        proto_features = None\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, _ = self.crossformer(x, return_proto_features=True,\n",
    "                                                        skip_cross_attention=False)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False,\n",
    "                                     skip_cross_attention=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "\n",
    "        # 4) Restore dim if reduced\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "\n",
    "        # 5) Pool over time\n",
    "        #    (B, T, embed_dim) -> (B, embed_dim, T) -> pool -> (B, embed_dim)\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        feat_vec = self.pool(x).squeeze(-1)\n",
    "\n",
    "        # 6) Classifier\n",
    "        logits = self.classifier(feat_vec)\n",
    "\n",
    "        # 7) Optional contrastive term\n",
    "        if (\n",
    "            return_contrast_loss\n",
    "            and self.use_contrast\n",
    "            and proto_features is not None\n",
    "            and labels is not None\n",
    "        ):\n",
    "            contrast_loss = self.contrast_loss(\n",
    "                proto_features,                # (B, dim)\n",
    "                self.crossformer.prototypes,   # (n_prototypes, dim)\n",
    "                labels                         # (B,)\n",
    "            )\n",
    "            return logits, contrast_loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 2-5. Prototype Initialization\n",
    "# =================================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, config):\n",
    "\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=config['in_channels'],\n",
    "        seq_len=config['seq_len'],\n",
    "        n_classes=config['n_classes'],\n",
    "        n_prototypes=config['n_prototypes'],\n",
    "        embed_dim=config['embed_dim'],\n",
    "        reduced_dim=config['reduced_dim'], \n",
    "        n_heads=config['n_heads'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout'],\n",
    "        temperature=config['temperature'],\n",
    "        initial_prototypes=None,\n",
    "        use_cbam=config[\"use_cbam\"],\n",
    "        use_crossformer=config[\"use_crossformer\"],\n",
    "        use_contrast=False,  # 중요: 여기서는 contrast loss 안 씀\n",
    "        use_dim_reduction=config['use_dim_reduction']\n",
    "    ).to(device)\n",
    "\n",
    "    temp_model.eval()\n",
    "\n",
    "    temp_loader = DataLoader(\n",
    "        train_full_dataset,\n",
    "        batch_size=config[\"batch_size\"],  # CONFIG 키 맞춤 (BATCH_SIZE -> batch_size)\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    all_features, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(temp_loader, desc=\"Prototype Init\"):\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "\n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "\n",
    "            if temp_model.use_crossformer:\n",
    "                x = temp_model.crossformer(\n",
    "                    x,\n",
    "                    return_proto_features=False,\n",
    "                    skip_cross_attention=True\n",
    "                )                                   # (B, T, working_dim)\n",
    "            else:\n",
    "                x = temp_model.self_attn(x)         # (B, T, working_dim)\n",
    "\n",
    "            # Dim restore (if reduction was used)\n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_restore(x)       # (B, T, embed_dim)\n",
    "\n",
    "            x = x.transpose(1, 2).contiguous()  # (B, embed_dim, T)\n",
    "\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1)  # (B, embed_dim)\n",
    "\n",
    "            all_features.append(pooled_features.cpu())  # (N, embed_dim)\n",
    "            all_labels.append(batch_y.cpu())  # (N,)\n",
    "\n",
    "    num_classes = config[\"n_classes\"]\n",
    "    feature_dim = config[\"embed_dim\"]  # pooled_features의 dim과 맞춰줌\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    mean_prototypes = torch.zeros(num_classes, feature_dim, dtype=torch.float32)\n",
    "    for i in range(num_classes):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            mean_prototypes[i] = torch.randn(feature_dim)\n",
    "    \n",
    "    return mean_prototypes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada2ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 3-1. train & evaluation\n",
    "# =================================================================================\n",
    "def train_epoch(model,\n",
    "                dataloader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                device,\n",
    "                use_contrast=True,\n",
    "                contrast_weight=0.5):\n",
    "    model.train()\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    ce_loss_sum = 0.0\n",
    "    contrast_loss_sum = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        batch_x = batch_x.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            total_loss = ce_loss + contrast_weight * contrast_loss\n",
    "            contrast_loss_sum  += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            total_loss  = ce_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_sum  += total_loss.item()\n",
    "        ce_loss_sum  += ce_loss.item()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(batch_y.detach().cpu().numpy())\n",
    "    \n",
    "    torch.cuda.synchronize() # 한 에폭 끝에서 동기화\n",
    "\n",
    "    avg_total_loss = total_loss_sum / len(dataloader)\n",
    "    avg_ce_loss = ce_loss_sum  / len(dataloader)\n",
    "    avg_contrast_loss = contrast_loss_sum / len(dataloader) if contrast_loss_sum  > 0 else 0.0\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_total_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model,\n",
    "             dataloader,\n",
    "             criterion,\n",
    "             device,\n",
    "             use_contrast=True,\n",
    "             contrast_weight=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    ce_loss_sum = 0.0\n",
    "    contrast_loss_sum = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device, non_blocking=True)\n",
    "            batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward (eval 모드에서는 no_grad)\n",
    "            if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "                logits, contrast_loss = model(\n",
    "                    batch_x,\n",
    "                    batch_y,\n",
    "                    return_contrast_loss=True\n",
    "                )\n",
    "                ce_loss = criterion(logits, batch_y)\n",
    "                total_loss = ce_loss + contrast_weight * contrast_loss\n",
    "                contrast_loss_sum += contrast_loss.item()\n",
    "            else:\n",
    "                logits = model(batch_x)\n",
    "                ce_loss = criterion(logits, batch_y)\n",
    "                total_loss = ce_loss\n",
    "\n",
    "            total_loss_sum  += total_loss.item()\n",
    "            ce_loss_sum += ce_loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    avg_total_loss = total_loss_sum / len(dataloader)\n",
    "    avg_ce_loss = ce_loss_sum / len(dataloader)\n",
    "    avg_contrast_loss = contrast_loss_sum / len(dataloader) if contrast_loss_sum > 0 else 0.0\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_total_loss, acc, f1, all_preds, all_labels, avg_ce_loss, avg_contrast_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f770ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# 4-2. Model profiling: Param(M), FLOPs(M), Inference Time(ms)\n",
    "# =================================================================================\n",
    "def profile_model(model, sample_input, device, warmup=10, iters=50):\n",
    "    \"\"\"\n",
    "    모델 구조/비용 측정:\n",
    "      - 파라미터 수 (M)\n",
    "      - FLOPs per sample (M)  ← fvcore 가능할 때만\n",
    "      - 평균 추론 시간 (ms/sample)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 1) 파라미터 수\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    params_m = total_params / 1e6\n",
    "\n",
    "    # 2) FLOPs (optional)\n",
    "    flops_m = None\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            fake_out = io.StringIO()\n",
    "            fake_err = io.StringIO()\n",
    "            with contextlib.redirect_stdout(fake_out), contextlib.redirect_stderr(fake_err):\n",
    "                flops = FlopCountAnalysis(model, (sample_input.to(device),))\n",
    "                total_flops = flops.total()\n",
    "        flops_m = total_flops / 1e6\n",
    "    except Exception:\n",
    "        flops_m = None\n",
    "\n",
    "    # 3) 추론 시간 측정\n",
    "    with torch.no_grad():\n",
    "        # warmup\n",
    "        for _ in range(warmup):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            _ = model(sample_input.to(device))\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "    avg_sec = (end - start) / iters\n",
    "    inference_ms = avg_sec * 1000.0\n",
    "\n",
    "    return {\n",
    "        \"params_m\": params_m,\n",
    "        \"flops_m\": flops_m,\n",
    "        \"inference_ms\": inference_ms,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1005f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subjects_train_test(subject_ids, seed=42, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    subject_ids: (N,) array-like of subject_id for each window\n",
    "    train_ratio: 비율만큼의 subject를 train쪽에 할당, 나머지는 test쪽.\n",
    "\n",
    "    반환:\n",
    "      train_subjects, test_subjects\n",
    "    \"\"\"\n",
    "    uniq = np.unique(subject_ids)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(uniq)\n",
    "\n",
    "    n_subj = len(uniq)\n",
    "    n_train_subj = int(train_ratio * n_subj)\n",
    "    if n_train_subj < 1:\n",
    "        n_train_subj = 1\n",
    "    if n_train_subj >= n_subj:\n",
    "        n_train_subj = n_subj - 1  # 최소 한 명은 test에 남겨\n",
    "\n",
    "    train_subjects = uniq[:n_train_subj]\n",
    "    test_subjects  = uniq[n_train_subj:]\n",
    "\n",
    "    return train_subjects, test_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16b6c4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\park9\\AppData\\Local\\Temp\\ipykernel_15536\\1393571807.py:79: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"subject_id\", group_keys=False).apply(_fill_subject_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[Embed+CBAM] Random split summary (subject-dependent)\n",
      " total windows = 15544\n",
      " train=9326  val=3108  test=3110\n",
      "================================================================================\n",
      "================================================================================\n",
      "EXPERIMENT CONFIG\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size          : 128\n",
      "contrast_weight     : 0.35\n",
      "data_dir            : C://Users/park9/CBAM_HAR/PAMAP2\n",
      "dataset_name        : PAMAP2\n",
      "do_tsne             : True\n",
      "dropout             : 0.1\n",
      "embed_dim           : 64\n",
      "epochs              : 50\n",
      "in_channels         : 36\n",
      "kernel_size         : 7\n",
      "learning_rate       : 0.0001\n",
      "n_classes           : 12\n",
      "n_heads             : 8\n",
      "n_prototypes        : 12\n",
      "print_every         : 50\n",
      "profile_model       : True\n",
      "reduced_dim         : 32\n",
      "scheduler_T_max     : 100\n",
      "scheduler_type      : cosine\n",
      "seed                : 42\n",
      "seq_len             : 250\n",
      "step_size           : 125\n",
      "temperature         : 0.05\n",
      "train_subject_ratio : 0.6\n",
      "use_cbam            : True\n",
      "use_contrast        : False\n",
      "use_crossformer     : False\n",
      "use_dim_reduction   : False\n",
      "val_subject_ratio   : 0.25\n",
      "weight_decay        : 0.001\n",
      "window_size         : 250\n",
      "================================================================================\n",
      "Parameters: 55,770\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embed+CBAM] Epoch 050/050\n",
      "  train | total=0.0603  ce=0.0603  ct=0.0000  acc=0.9838  f1=0.9838\n",
      "  val   | total=0.1160  ce=0.1160  ct=0.0000  acc=0.9678  f1=0.9679\n",
      "================================================================================\n",
      "[Embed+CBAM] Training Complete!\n",
      "  Best Val Acc: 0.9685 @ epoch 47\n",
      "  Test(best ckpt): acc=0.9653, f1=0.9652, total_loss=0.1318, ce=0.1318, ct=0.0000\n",
      "==== Model Profile ====\n",
      "Parameters      : 0.0558 M\n",
      "FLOPs / sample : 8.330412\n",
      "Infer Time     : 1.16 ms/sample\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\park9\\AppData\\Local\\Temp\\ipykernel_15536\\1393571807.py:79: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"subject_id\", group_keys=False).apply(_fill_subject_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[CBAM+CrossFormer (noContrast)] Random split summary (subject-dependent)\n",
      " total windows = 15544\n",
      " train=9326  val=3108  test=3110\n",
      "================================================================================\n",
      "================================================================================\n",
      "EXPERIMENT CONFIG\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size          : 128\n",
      "contrast_weight     : 0.35\n",
      "data_dir            : C://Users/park9/CBAM_HAR/PAMAP2\n",
      "dataset_name        : PAMAP2\n",
      "do_tsne             : True\n",
      "dropout             : 0.1\n",
      "embed_dim           : 64\n",
      "epochs              : 50\n",
      "in_channels         : 36\n",
      "kernel_size         : 7\n",
      "learning_rate       : 0.0001\n",
      "n_classes           : 12\n",
      "n_heads             : 8\n",
      "n_prototypes        : 12\n",
      "print_every         : 50\n",
      "profile_model       : True\n",
      "reduced_dim         : 32\n",
      "scheduler_T_max     : 100\n",
      "scheduler_type      : cosine\n",
      "seed                : 42\n",
      "seq_len             : 250\n",
      "step_size           : 125\n",
      "temperature         : 0.05\n",
      "train_subject_ratio : 0.6\n",
      "use_cbam            : True\n",
      "use_contrast        : False\n",
      "use_crossformer     : True\n",
      "use_dim_reduction   : False\n",
      "val_subject_ratio   : 0.25\n",
      "weight_decay        : 0.001\n",
      "window_size         : 250\n",
      "================================================================================\n",
      "Prototypes initialized with Xavier Uniform.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prototype Init: 100%|██████████| 73/73 [00:01<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototypes initialized with calculated mean features.\n",
      "Parameters: 81,626\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CBAM+CrossFormer (noContrast)] Epoch 050/050\n",
      "  train | total=0.0596  ce=0.0596  ct=0.0000  acc=0.9822  f1=0.9823\n",
      "  val   | total=0.1497  ce=0.1497  ct=0.0000  acc=0.9611  f1=0.9612\n",
      "================================================================================\n",
      "[CBAM+CrossFormer (noContrast)] Training Complete!\n",
      "  Best Val Acc: 0.9636 @ epoch 49\n",
      "  Test(best ckpt): acc=0.9614, f1=0.9614, total_loss=0.1492, ce=0.1492, ct=0.0000\n",
      "==== Model Profile ====\n",
      "Parameters      : 0.0816 M\n",
      "FLOPs / sample : 10.940716\n",
      "Infer Time     : 2.29 ms/sample\n",
      "=======================\n",
      "\n",
      "================================================================================\n",
      "PAMAP2 Ablation Summary\n",
      "================================================================================\n",
      "                          tag  use_cbam  use_crossformer  use_contrast  best_val_acc  test_acc  test_f1  params_m   flops_m  inference_ms  best_epoch\n",
      "                   Embed+CBAM      True            False         False      0.968468  0.965273 0.965228  0.055770  8.330412      1.162448          47\n",
      "CBAM+CrossFormer (noContrast)      True             True         False      0.963642  0.961415 0.961389  0.081626 10.940716      2.285876          49\n",
      "Saved ablation_results_PAMAP2.csv\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# 5-B. Single variant runner for PAMAP2\n",
    "# =====================================================================\n",
    "\n",
    "def run_experiment(base_config, variant_overrides, device):\n",
    "    \"\"\"\n",
    "    하나의 variant (예: 'Embed+CBAM')만 독립적으로 학습/평가해서 결과를 리턴한다.\n",
    "    - 랜덤 split (윈도우 셔플 후 60/20/20)\n",
    "    - best val ckpt 기준으로 test 성능 측정\n",
    "    - confusion matrix / t-SNE / profile까지 저장\n",
    "    - 결과 dict 리턴 (acc, f1, params, FLOPs 등)\n",
    "    \"\"\"\n",
    "\n",
    "    # 0) config 준비\n",
    "    cfg = copy.deepcopy(base_config)\n",
    "    for k, v in variant_overrides.items():\n",
    "        if k == \"tag\":\n",
    "            continue\n",
    "        cfg[k] = v\n",
    "\n",
    "    seed_everything(cfg[\"seed\"])\n",
    "    DEVICE = device\n",
    "\n",
    "    # 1) 전체 PAMAP2 데이터 로드\n",
    "    full_dataset = PAMAP2Dataset(\n",
    "        data_dir=cfg[\"data_dir\"],\n",
    "        window_size=cfg[\"window_size\"],\n",
    "        step_size=cfg[\"step_size\"],\n",
    "    )\n",
    "\n",
    "    label_names = full_dataset.label_names\n",
    "\n",
    "    # 실제 데이터 기반으로 갱신 (in_channels, seq_len, n_classes, n_prototypes)\n",
    "    cfg[\"in_channels\"]   = full_dataset.X.shape[1]           # (N, C, T)\n",
    "    cfg[\"seq_len\"]       = full_dataset.X.shape[2]           # T = window_size\n",
    "    cfg[\"n_classes\"]     = len(full_dataset.label_names)     # 보통 12\n",
    "    cfg[\"n_prototypes\"]  = cfg[\"n_classes\"]                  # 클래스당 1개 프로토타입\n",
    "\n",
    "    N = len(full_dataset)\n",
    "    all_indices = np.arange(N)\n",
    "\n",
    "    rng = np.random.default_rng(cfg[\"seed\"])\n",
    "    rng.shuffle(all_indices)\n",
    "\n",
    "    n_train = int(0.6 * N)\n",
    "    n_val   = int(0.2 * N)\n",
    "    # 나머지 전부 test\n",
    "    train_idx = all_indices[:n_train]\n",
    "    val_idx   = all_indices[n_train : n_train + n_val]\n",
    "    test_idx  = all_indices[n_train + n_val :]\n",
    "\n",
    "    # 이제 PyTorch Subset으로 변환\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset   = Subset(full_dataset, val_idx)\n",
    "    test_dataset  = Subset(full_dataset, test_idx)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[{variant_overrides['tag']}] Random split summary (subject-dependent)\")\n",
    "    print(f\" total windows = {N}\")\n",
    "    print(f\" train={len(train_dataset)}  val={len(val_dataset)}  test={len(test_dataset)}\")\n",
    "    print(\"=\" * 80)\n",
    "    pretty_print_config(cfg)\n",
    "\n",
    "    # 3) DataLoader\n",
    "    g = torch.Generator().manual_seed(cfg[\"seed\"])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # 4) 프로토타입 초기화\n",
    "    # CrossFormer를 쓰는 variant만 mean prototype init 필요\n",
    "    if cfg[\"use_crossformer\"]:\n",
    "        initial_prototypes = get_mean_prototypes(\n",
    "            train_dataset,\n",
    "            DEVICE,\n",
    "            cfg\n",
    "        )\n",
    "    else:\n",
    "        initial_prototypes = None\n",
    "\n",
    "    # 5) 모델 생성\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=cfg[\"in_channels\"],\n",
    "        seq_len=cfg[\"seq_len\"],\n",
    "        embed_dim=cfg[\"embed_dim\"],\n",
    "        reduced_dim=cfg[\"reduced_dim\"],\n",
    "        n_classes=cfg[\"n_classes\"],\n",
    "        n_prototypes=cfg[\"n_prototypes\"],\n",
    "        n_heads=cfg[\"n_heads\"],\n",
    "        kernel_size=cfg[\"kernel_size\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "        temperature=cfg[\"temperature\"],\n",
    "        initial_prototypes=initial_prototypes,\n",
    "        use_cbam=cfg[\"use_cbam\"],\n",
    "        use_crossformer=cfg[\"use_crossformer\"],\n",
    "        use_contrast=cfg[\"use_contrast\"],\n",
    "        use_dim_reduction=cfg[\"use_dim_reduction\"],\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 6) optimizer / scheduler / loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg[\"learning_rate\"],\n",
    "        weight_decay=cfg[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    if cfg[\"scheduler_type\"] == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=cfg[\"scheduler_T_max\"],\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # 7) 학습 루프 (val acc best 추적)\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch   = -1\n",
    "    best_state   = None\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        train_total, train_ce, train_ct, train_acc, train_f1 = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            DEVICE,\n",
    "            use_contrast=cfg[\"use_contrast\"],\n",
    "            contrast_weight=cfg[\"contrast_weight\"],\n",
    "        )\n",
    "\n",
    "        val_total, val_acc, val_f1, _, _, val_ce, val_ct = evaluate(\n",
    "            model,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            DEVICE,\n",
    "            use_contrast=cfg[\"use_contrast\"],\n",
    "            contrast_weight=cfg[\"contrast_weight\"],\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_total\": train_total,\n",
    "            \"train_ce\": train_ce,\n",
    "            \"train_ct\": train_ct,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"train_f1\": train_f1,\n",
    "            \"val_total\": val_total,\n",
    "            \"val_ce\": val_ce,\n",
    "            \"val_ct\": val_ct,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch   = epoch + 1\n",
    "            best_state   = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % cfg[\"print_every\"] == 0:\n",
    "            ep_now   = epoch + 1\n",
    "            ep_total = cfg[\"epochs\"]\n",
    "            print(f\"[{variant_overrides['tag']}] Epoch {ep_now:03d}/{ep_total:03d}\")\n",
    "            print(\n",
    "                \"  train | \"\n",
    "                f\"total={train_total:.4f}  \"\n",
    "                f\"ce={train_ce:.4f}  \"\n",
    "                f\"ct={train_ct:.4f}  \"\n",
    "                f\"acc={train_acc:.4f}  \"\n",
    "                f\"f1={train_f1:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                \"  val   | \"\n",
    "                f\"total={val_total:.4f}  \"\n",
    "                f\"ce={val_ce:.4f}  \"\n",
    "                f\"ct={val_ct:.4f}  \"\n",
    "                f\"acc={val_acc:.4f}  \"\n",
    "                f\"f1={val_f1:.4f}\"\n",
    "            )\n",
    "\n",
    "    # 8) best ckpt 로드 후 test 평가\n",
    "    assert best_state is not None, \"No best_state saved??\"\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    test_total, test_acc, test_f1, test_preds, test_labels, test_ce, test_ct = evaluate(\n",
    "        model,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        DEVICE,\n",
    "        use_contrast=cfg[\"use_contrast\"],\n",
    "        contrast_weight=cfg[\"contrast_weight\"],\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[{variant_overrides['tag']}] Training Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(\n",
    "        f\"  Test(best ckpt): \"\n",
    "        f\"acc={test_acc:.4f}, f1={test_f1:.4f}, \"\n",
    "        f\"total_loss={test_total:.4f}, ce={test_ce:.4f}, ct={test_ct:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 9) 모델 프로파일링\n",
    "    stats_profile = None\n",
    "    if cfg[\"profile_model\"]:\n",
    "        dummy_input = torch.randn(\n",
    "            1,\n",
    "            cfg[\"in_channels\"],\n",
    "            cfg[\"seq_len\"],\n",
    "        )\n",
    "        stats_profile = profile_model(model, dummy_input, DEVICE)\n",
    "        # print_model_profile가 따로 정의돼 있지 않아서 여기선 stats만 쓴다.\n",
    "        print(\"==== Model Profile ====\")\n",
    "        print(f\"Parameters      : {stats_profile['params_m']:.4f} M\")\n",
    "        print(f\"FLOPs / sample : {stats_profile['flops_m']}\")\n",
    "        print(f\"Infer Time     : {stats_profile['inference_ms']:.2f} ms/sample\")\n",
    "        print(\"=======================\")\n",
    "\n",
    "    # 11) 결과 dict 리턴 (테이블/CSV용)\n",
    "    row = {\n",
    "        \"tag\":                    variant_overrides[\"tag\"],\n",
    "        \"use_cbam\":               cfg[\"use_cbam\"],\n",
    "        \"use_crossformer\":        cfg[\"use_crossformer\"],\n",
    "        \"use_contrast\":           cfg[\"use_contrast\"],\n",
    "        \"best_val_acc\":           best_val_acc,\n",
    "        \"test_acc\":               test_acc,\n",
    "        \"test_f1\":                test_f1,\n",
    "        \"test_total_loss\":        test_total,\n",
    "        \"test_ce\":                test_ce,\n",
    "        \"test_ct\":                test_ct,\n",
    "        \"params_m\":               stats_profile[\"params_m\"]     if stats_profile else None,\n",
    "        \"flops_m\":                stats_profile[\"flops_m\"]      if stats_profile else None,\n",
    "        \"inference_ms\":           stats_profile[\"inference_ms\"] if stats_profile else None,\n",
    "        \"best_epoch\":             best_epoch,\n",
    "    }\n",
    "\n",
    "    return row, history\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5-C. Ablation main for PAMAP2\n",
    "# =====================================================================\n",
    "\n",
    "def main_ablation():\n",
    "    \"\"\"\n",
    "    PAMAP2 데이터셋에 대해 세 가지 모델 변형을 독립적으로 실행하고\n",
    "    최종 요약표를 출력 & CSV로 저장한다.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    variants = [\n",
    "        {\n",
    "            # No crossformer, no contrast\n",
    "            \"tag\": \"Embed+CBAM\",\n",
    "            \"use_cbam\": True,\n",
    "            \"use_crossformer\": False,\n",
    "            \"use_contrast\": False,\n",
    "        },\n",
    "        {\n",
    "            # CrossFormer but contrast off\n",
    "            \"tag\": \"CBAM+CrossFormer (noContrast)\",\n",
    "            \"use_cbam\": True,\n",
    "            \"use_crossformer\": True,\n",
    "            \"use_contrast\": False,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    all_rows = []\n",
    "    all_histories = {}\n",
    "\n",
    "    for v in variants:\n",
    "        row, hist = run_experiment(CONFIG, v, device)\n",
    "        all_rows.append(row)\n",
    "        all_histories[v[\"tag\"]] = hist  # epoch별 로그 필요하면 나중에 그래프용으로 쓸 수 있음\n",
    "\n",
    "    df = pd.DataFrame(all_rows, columns=[\n",
    "        \"tag\",\n",
    "        \"use_cbam\",\n",
    "        \"use_crossformer\",\n",
    "        \"use_contrast\",\n",
    "        \"best_val_acc\",\n",
    "        \"test_acc\",\n",
    "        \"test_f1\",\n",
    "        \"params_m\",\n",
    "        \"flops_m\",\n",
    "        \"inference_ms\",\n",
    "        \"best_epoch\",\n",
    "    ])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PAMAP2 Ablation Summary\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    df.to_csv(\"ablation_results_PAMAP2.csv\", index=False)\n",
    "    print(\"Saved ablation_results_PAMAP2.csv\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 6. Entry point\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main_ablation()\n",
    "    # main()  # <- 단일 full model만 다시 돌리고 싶으면 이걸 잠깐 열어도 됨\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
