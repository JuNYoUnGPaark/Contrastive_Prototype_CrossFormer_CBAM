{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a4f79d",
   "metadata": {},
   "source": [
    "`Prototype 초기화 방식 변경, temparture 변경, contrastive_weight 변경, Batch_size 변경, use_dim_reduction 변경`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca1099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading UCI HAR Dataset from: C://Users/park9/CBAM_HAR/data\n",
      "Loaded train data: X shape=(7352, 9, 128), y shape=(7352,)\n",
      "Loaded test data: X shape=(2947, 9, 128), y shape=(2947,)\n",
      "Train: 5881, Validation: 1471, Test: 2947\n",
      "Calculating initial prototypes from mean features...\n",
      ">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\n",
      "Initial prototypes calculated. Shape: torch.Size([6, 32])\n",
      "\n",
      "================================================================================\n",
      "Training: + CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\n",
      "Config: {'use_cbam': True, 'use_crossformer': True, 'use_contrast': True, 'use_dim_reduction': True}\n",
      "================================================================================\n",
      ">>> [Main Model] Prototypes initialized with calculated mean features.\n",
      "Parameters: 29,140\n",
      "  Epoch [10/100] Loss: 0.1572 (CE: 0.1201, CT: 0.1485) | Val Acc: 0.9497\n",
      "  Epoch [20/100] Loss: 0.1419 (CE: 0.1117, CT: 0.1208) | Val Acc: 0.9619\n",
      "  Epoch [30/100] Loss: 0.1306 (CE: 0.1034, CT: 0.1089) | Val Acc: 0.9585\n",
      "  Epoch [40/100] Loss: 0.1163 (CE: 0.0920, CT: 0.0973) | Val Acc: 0.9680\n",
      "  Epoch [50/100] Loss: 0.1026 (CE: 0.0816, CT: 0.0838) | Val Acc: 0.9680\n",
      "  Epoch [60/100] Loss: 0.0952 (CE: 0.0755, CT: 0.0786) | Val Acc: 0.9694\n",
      "  Epoch [70/100] Loss: 0.0826 (CE: 0.0661, CT: 0.0663) | Val Acc: 0.9721\n",
      "  Epoch [80/100] Loss: 0.0771 (CE: 0.0616, CT: 0.0621) | Val Acc: 0.9728\n",
      "  Epoch [90/100] Loss: 0.0744 (CE: 0.0591, CT: 0.0615) | Val Acc: 0.9755\n",
      "  Epoch [100/100] Loss: 0.0756 (CE: 0.0598, CT: 0.0629) | Val Acc: 0.9748\n",
      "\n",
      "✓ + CBAM + CrossFormer + Contrast (Full + Mean Proto Init) Complete!\n",
      "  Best Val Acc: 0.9776 @ epoch 87\n",
      "  Final Test (Best-VAL ckpt): Acc=0.9216 | F1=0.9217\n",
      "\n",
      "================================================================================\n",
      "PROCESS COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os, copy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    재현성을 위해 Python, NumPy, PyTorch의 Seed를 고정합니다.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    \n",
    "    # cuDNN 설정 (재현성은 보장되나, 속도가 느려질 수 있음)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader의 worker process를 위한 Seed 설정\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. UCI HAR 데이터 로더\n",
    "# =====================================================================\n",
    "class UCIHARDataset(Dataset):\n",
    "    def __init__(self, data_dir, train=True):\n",
    "        \"\"\"\n",
    "        UCI HAR Dataset 로더\n",
    "        data_dir: UCI HAR Dataset 폴더 경로\n",
    "        train: True면 train 데이터, False면 test 데이터\n",
    "        \"\"\"\n",
    "        subset = 'train' if train else 'test'\n",
    "\n",
    "        # Inertial Signals 로드 (9개 센서)\n",
    "        signals = []\n",
    "        signal_types = [\n",
    "            'body_acc_x', 'body_acc_y', 'body_acc_z',\n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'\n",
    "        ]\n",
    "\n",
    "        for signal in signal_types:\n",
    "            filename = os.path.join(data_dir, subset, 'Inertial Signals',\n",
    "                                f'{signal}_{subset}.txt')\n",
    "            # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "            with open(filename, 'r') as f:\n",
    "                # 2. np.loadtxt에 파일 이름 대신 파일 객체(f)를 전달합니다.\n",
    "                data = np.loadtxt(f)\n",
    "                \n",
    "            signals.append(data)\n",
    "\n",
    "        # (N, 9, 128) 형태로 변환\n",
    "        self.X = np.stack(signals, axis=1)\n",
    "\n",
    "        # 레이블 로드 (1~6 -> 0~5로 변환)\n",
    "        label_file = os.path.join(data_dir, subset, f'y_{subset}.txt')\n",
    "        # 1. 파일을 'r' (읽기) 모드로 직접 엽니다.\n",
    "        with open(label_file, 'r') as f:\n",
    "            # 2. np.loadtxt에 파일 객체(f)를 전달합니다.\n",
    "            self.y = np.loadtxt(f, dtype=np.int32) - 1\n",
    "\n",
    "        print(f\"Loaded {subset} data: X shape={self.X.shape}, y shape={self.y.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. 1D-CBAM (Channel + Temporal Attention)\n",
    "# =====================================================================\n",
    "class ChannelAttention1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = self.fc(self.avg_pool(x).squeeze(-1))  # (B, C)\n",
    "        max_out = self.fc(self.max_pool(x).squeeze(-1))  # (B, C)\n",
    "        out = self.sigmoid(avg_out + max_out).unsqueeze(-1)  # (B, C, 1)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class TemporalAttention1D(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, T)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)  # (B, 2, T)\n",
    "        out = self.sigmoid(self.conv(out))  # (B, 1, T)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention1D(channels, reduction)\n",
    "        self.temporal_att = TemporalAttention1D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.temporal_att(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Contrastive Prototype Loss\n",
    "# =====================================================================\n",
    "class ContrastivePrototypeLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, prototypes, labels):\n",
    "        \"\"\"\n",
    "        Contrastive Loss between features and prototypes\n",
    "\n",
    "        Args:\n",
    "            features: (B, D) - 샘플 특징\n",
    "            prototypes: (N_class, D) - 클래스별 프로토타입\n",
    "            labels: (B,) - 레이블\n",
    "\n",
    "        Returns:\n",
    "            loss: contrastive loss\n",
    "        \"\"\"\n",
    "        # L2 정규화\n",
    "        features = F.normalize(features, dim=1)\n",
    "        prototypes = F.normalize(prototypes, dim=1)\n",
    "\n",
    "        # 유사도 계산 (B, N_class)\n",
    "        logits = torch.matmul(features, prototypes.t()) / self.temperature\n",
    "\n",
    "        # InfoNCE Loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4. CrossFormer with Contrast Prototypes\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerBlock(nn.Module):\n",
    "    def __init__(self, dim, n_prototypes=6, n_heads=4, mlp_ratio=2.0, dropout=0.1,\n",
    "                 initial_prototypes=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable prototypes (L2 정규화 적용)\n",
    "        self.prototypes = nn.Parameter(torch.randn(n_prototypes, dim))\n",
    "\n",
    "        # Xavier 초기화 대신, 전달받은 값으로 초기화 (없으면 Xavier 유지)\n",
    "        if initial_prototypes is not None:\n",
    "            assert initial_prototypes.shape == self.prototypes.shape, \\\n",
    "                f\"Shape mismatch: initial_prototypes {initial_prototypes.shape} vs self.prototypes {self.prototypes.shape}\"\n",
    "            self.prototypes.data.copy_(initial_prototypes)\n",
    "            print(\">>> [Main Model] Prototypes initialized with calculated mean features.\")\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.prototypes)\n",
    "            print(\">>> [Temporary Model or No Init Provided] Prototypes initialized with Xavier Uniform.\")\n",
    "\n",
    "        # Cross-Attention: Input(Q) x Prototypes(K, V)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Self-Attention\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.self_attn = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # FFN\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # Prototype projection (contrastive learning용)\n",
    "        self.proto_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_proto_features=False, skip_cross_attention=False):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # 1. Cross-Attention (선택적 실행)\n",
    "        if not skip_cross_attention:\n",
    "            normalized_prototypes = F.normalize(self.prototypes, dim=1)\n",
    "            prototypes = normalized_prototypes.unsqueeze(0).expand(B, -1, -1)\n",
    "            x_norm = self.norm1(x)\n",
    "            cross_out, attn_weights = self.cross_attn(x_norm, prototypes, prototypes)\n",
    "            x = x + cross_out\n",
    "        else: # Cross-Attention을 건너뛸 경우, attn_weights는 None\n",
    "            attn_weights = None\n",
    "\n",
    "        # 2. Self-Attention\n",
    "        x_norm = self.norm2(x)\n",
    "        self_out, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self_out\n",
    "\n",
    "        # 3. FFN\n",
    "        x = x + self.mlp(self.norm3(x))\n",
    "\n",
    "        # Prototype features for contrastive loss\n",
    "        if return_proto_features:\n",
    "            # Global average pooling\n",
    "            proto_features = x.mean(dim=1)  # (B, C)\n",
    "            proto_features = self.proto_proj(proto_features)  # projection\n",
    "            return x, proto_features, attn_weights\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5. 메인 모델: CrossFormer + 1D-CBAM + Contrast Prototype\n",
    "# =====================================================================\n",
    "class ContrastCrossFormerCBAM_HAR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=9,\n",
    "                 seq_len=128,\n",
    "                 embed_dim=64,\n",
    "                 reduced_dim=32,\n",
    "                 n_classes=6,\n",
    "                 n_prototypes=6,\n",
    "                 n_heads=4,\n",
    "                 dropout=0.1,\n",
    "                 temperature=0.07,\n",
    "                 initial_prototypes=None,\n",
    "                 # Ablation 옵션\n",
    "                 use_cbam=True,\n",
    "                 use_crossformer=True,\n",
    "                 use_contrast=True,\n",
    "                 use_dim_reduction=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.use_cbam = use_cbam\n",
    "        self.use_crossformer = use_crossformer\n",
    "        self.use_contrast = use_contrast\n",
    "        self.use_dim_reduction = use_dim_reduction\n",
    "\n",
    "        # 1. Input Embedding (1D Conv)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, embed_dim, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM1D(embed_dim, reduction=8, kernel_size=7)\n",
    "\n",
    "        # 3. 차원 축소 (선택적)\n",
    "        working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_reduce = nn.Linear(embed_dim, reduced_dim)\n",
    "\n",
    "        # 4. CrossFormer Block (선택적)\n",
    "        if self.use_crossformer:\n",
    "            self.crossformer = ContrastCrossFormerBlock(\n",
    "                dim=working_dim,\n",
    "                n_prototypes=n_prototypes,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=2.0,\n",
    "                dropout=dropout,\n",
    "                initial_prototypes=initial_prototypes\n",
    "            )\n",
    "        else:\n",
    "            # CrossFormer 없이 Self-Attention만 사용\n",
    "            self.self_attn = nn.TransformerEncoderLayer(\n",
    "                d_model=working_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(working_dim * 2),\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "\n",
    "        # 5. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            self.dim_restore = nn.Linear(reduced_dim, embed_dim)\n",
    "\n",
    "        # 6. Global Pooling + Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "\n",
    "        # 7. Contrastive Loss (선택적)\n",
    "        if self.use_contrast and self.use_crossformer:\n",
    "            self.contrast_loss = ContrastivePrototypeLoss(temperature=temperature)\n",
    "\n",
    "    def forward(self, x, labels=None, return_contrast_loss=False):\n",
    "        # x: (B, C, T) = (B, 9, 128)\n",
    "\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(x)  # (B, embed_dim, T)\n",
    "\n",
    "        # 2. CBAM (선택적)\n",
    "        if self.use_cbam:\n",
    "            x = self.cbam(x)\n",
    "\n",
    "        # 3. Reshape for Transformer\n",
    "        x = x.transpose(1, 2)  # (B, T, embed_dim)\n",
    "\n",
    "        # 4. 차원 축소 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_reduce(x)\n",
    "\n",
    "        # 5. CrossFormer 또는 Self-Attention\n",
    "        proto_features = None\n",
    "        attn_weights = None\n",
    "\n",
    "        if self.use_crossformer:\n",
    "            if return_contrast_loss and self.use_contrast:\n",
    "                x, proto_features, attn_weights = self.crossformer(x, return_proto_features=True)\n",
    "            else:\n",
    "                x = self.crossformer(x, return_proto_features=False)\n",
    "        else:\n",
    "            x = self.self_attn(x)\n",
    "\n",
    "        # 6. 차원 복원 (선택적)\n",
    "        if self.use_dim_reduction:\n",
    "            x = self.dim_restore(x)\n",
    "\n",
    "        # 7. Pooling + Classification\n",
    "        x = x.transpose(1, 2)  # (B, embed_dim, T)\n",
    "        x = self.pool(x).squeeze(-1)  # (B, embed_dim)\n",
    "        logits = self.classifier(x)  # (B, n_classes)\n",
    "\n",
    "        # Contrastive Loss 계산\n",
    "        if return_contrast_loss and self.use_contrast and proto_features is not None and labels is not None:\n",
    "            contrast_loss = self.contrast_loss(\n",
    "                proto_features,\n",
    "                self.crossformer.prototypes,\n",
    "                labels\n",
    "            )\n",
    "            return logits, contrast_loss\n",
    "\n",
    "        return logits\n",
    "\n",
    "# =====================================================================\n",
    "# 6. 평균 프로토타입 계산 함수\n",
    "# =====================================================================\n",
    "def get_mean_prototypes(train_full_dataset, device, embed_dim=64, \n",
    "                        reduced_dim=32, batch_size=128, use_dim_reduction=False):\n",
    "    \"\"\"\n",
    "    훈련 데이터셋 전체를 사용하여 클래스별 평균 특징 벡터를 계산합니다.\n",
    "    (Cross-Attention 제외하고 특징 추출)\n",
    "    \"\"\"\n",
    "    print(\"Calculating initial prototypes from mean features...\")\n",
    "\n",
    "    # 1. 임시 특징 추출 모델 정의 (Embedding ~ Pooling까지만)\n",
    "    #    (주의: 실제 모델 구조와 파라미터(dropout 등) 일치시킬 것)\n",
    "    #    (여기서는 use_dim_reduction=False라고 가정)\n",
    "    temp_model = ContrastCrossFormerCBAM_HAR(\n",
    "        embed_dim=embed_dim, dropout=0.1, # Baseline 값 사용\n",
    "        use_cbam=True, use_crossformer=True, use_contrast=False, # Contrast False로!\n",
    "        use_dim_reduction=use_dim_reduction # 평균 계산 시 차원 축소 안 함\n",
    "    ).to(device)\n",
    "    temp_model.eval() # 평가 모드로 설정\n",
    "\n",
    "    # 2. 전체 훈련 데이터 로더 (섞지 않음)\n",
    "    temp_loader = DataLoader(train_full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 3. 특징 추출 루프\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in temp_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            # --- 특징 추출 (ContrastCrossFormerCBAM_HAR의 forward 참고) ---\n",
    "            # 1. Embedding\n",
    "            x = temp_model.embedding(batch_x)\n",
    "            # 2. CBAM\n",
    "            if temp_model.use_cbam:\n",
    "                x = temp_model.cbam(x)\n",
    "            # 3. Reshape\n",
    "            x = x.transpose(1, 2)\n",
    "            # 4. 차원 축소 \n",
    "            if temp_model.use_dim_reduction:\n",
    "                x = temp_model.dim_reduce(x)\n",
    "\n",
    "            # 5. Self-Attention (CrossFormer 없이)\n",
    "            # CrossFormer 블록을 호출하되, cross-attention 건너뛰기 옵션 활성화\n",
    "            x = temp_model.crossformer(x, skip_cross_attention=True)\n",
    "\n",
    "            # 6. 차원 복원 (여기서는 안 함)\n",
    "            # 7. Pooling (Classifier 직전)\n",
    "            x = x.transpose(1, 2)\n",
    "            pooled_features = temp_model.pool(x).squeeze(-1) # (B, embed_dim)\n",
    "            # -----------------------------------------------------------\n",
    "\n",
    "            all_features.append(pooled_features.cpu())\n",
    "            all_labels.append(batch_y.cpu())\n",
    "\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # 4. 클래스별 평균 계산\n",
    "    n_classes = temp_model.classifier[-1].out_features # 모델 정의에서 클래스 수 가져오기\n",
    "    # ⬇️ 프로토타입 차원을 working_dim에 맞게 동적으로 설정\n",
    "    working_dim = reduced_dim if use_dim_reduction else embed_dim\n",
    "    mean_prototypes = torch.zeros(n_classes, working_dim)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        class_features = all_features[all_labels == i]\n",
    "        if len(class_features) > 0:\n",
    "            mean_prototypes[i] = class_features.mean(dim=0)\n",
    "        else:\n",
    "            print(f\"Warning: No samples found for class {i} during prototype initialization.\")\n",
    "            # (샘플 없는 경우 랜덤 초기화 또는 0 벡터 사용 등 처리 필요)\n",
    "            mean_prototypes[i] = torch.randn(working_dim) # 임시로 랜덤 사용\n",
    "\n",
    "    print(f\"Initial prototypes calculated. Shape: {mean_prototypes.shape}\")\n",
    "    return mean_prototypes.to(device) # GPU로 다시 보냄\n",
    "\n",
    "# =====================================================================\n",
    "# 7. 학습 및 평가 (Contrastive Loss 포함)\n",
    "# =====================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_contrast=True, contrast_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    total_contrast_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        if use_contrast and model.use_contrast and model.use_crossformer:\n",
    "            logits, contrast_loss = model(batch_x, batch_y, return_contrast_loss=True)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss + contrast_weight * contrast_loss\n",
    "            total_contrast_loss += contrast_loss.item()\n",
    "        else:\n",
    "            logits = model(batch_x)\n",
    "            ce_loss = criterion(logits, batch_y)\n",
    "            loss = ce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    avg_contrast_loss = total_contrast_loss / len(dataloader) if total_contrast_loss > 0 else 0\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, avg_ce_loss, avg_contrast_loss, acc, f1\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, acc, f1, all_preds, all_labels\n",
    "\n",
    "# =====================================================================\n",
    "# 8. 메인 실행\n",
    "# =====================================================================\n",
    "def main():\n",
    "    # 하이퍼파라미터\n",
    "    DATA_DIR = 'C://Users/park9/CBAM_HAR/data'\n",
    "    BATCH_SIZE = 128  # 최소 256\n",
    "    EPOCHS = 100  # 100으로 고정 \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SEED = 42\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading UCI HAR Dataset from: {DATA_DIR}\")\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_full_dataset = UCIHARDataset(DATA_DIR, train=True)\n",
    "    test_dataset = UCIHARDataset(DATA_DIR, train=False)\n",
    "\n",
    "    # Train을 Train/Validation으로 분할 (80:20)\n",
    "    train_size = int(0.8 * len(train_full_dataset))\n",
    "    val_size = len(train_full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_full_dataset, [train_size, val_size],\n",
    "                                               generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              worker_init_fn=seed_worker, generator=g)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            worker_init_fn=seed_worker)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             worker_init_fn=seed_worker)\n",
    "\n",
    "    # Ablation Study 대신, \"Full Model\" 직접 생성 및 훈련/테스트\n",
    "    config_name = \"+ CBAM + CrossFormer + Contrast (Full + Mean Proto Init)\"\n",
    "    config_params = dict(use_cbam=True, use_crossformer=True, use_contrast=True, use_dim_reduction=True)\n",
    "\n",
    "    # 평균 프로토타입 계산 (모델 생성 전)\n",
    "    # (주의: embed_dim=64는 모델 생성 시 사용할 값과 일치해야 함)\n",
    "    initial_prototypes = get_mean_prototypes(train_full_dataset, DEVICE, embed_dim=64, reduced_dim=32,\n",
    "                                             batch_size=BATCH_SIZE, use_dim_reduction=config_params['use_dim_reduction'])\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training: {config_name}\")\n",
    "    print(f\"Config: {config_params}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 모델 생성 시 initial_prototypes 전달\n",
    "    model = ContrastCrossFormerCBAM_HAR(\n",
    "        in_channels=9, seq_len=128, embed_dim=64, reduced_dim=32,\n",
    "        n_classes=6, n_prototypes=6, n_heads=4, dropout=0.1, temperature=0.05, # Baseline 값들\n",
    "        initial_prototypes=initial_prototypes, # ⬅️ 계산된 값 전달\n",
    "        **config_params\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4) # Baseline 옵티마이저\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 학습 루프 (기존 run_ablation_study 내부 로직과 유사하게)\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_ce, train_contrast, train_acc, train_f1 = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, DEVICE,\n",
    "            use_contrast=config_params['use_contrast'], contrast_weight=0.25 # Baseline contrast_weight\n",
    "        )\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "             print(f\"  Epoch [{epoch+1:2d}/{EPOCHS}] Loss: {train_loss:.4f} (CE: {train_ce:.4f}, CT: {train_contrast:.4f}) | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 최종 테스트\n",
    "    assert best_state is not None\n",
    "    model.load_state_dict(best_state)\n",
    "    test_loss, test_acc, test_f1, _, _ = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "    print(f\"\\n✓ {config_name} Complete!\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.4f} @ epoch {best_epoch}\")\n",
    "    print(f\"  Final Test (Best-VAL ckpt): Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESS COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
