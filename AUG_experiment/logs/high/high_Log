================================================================================
   🧪 UCI-HAR Comprehensive Comparison
   SUPERVISED vs TRUE SELF-SUPERVISED LEARNING
   Architecture: ResNet + Transformer Encoder
================================================================================

   📋 실험 설계:
   1. 동일한 백본 (ResNet + Transformer)
   2. 동일한 전이 데이터셋 (4가지 시나리오)
   3. 6가지 설정 비교:
      ├─ Supervised × (Linear, Hyperbolic)
      ├─ SSL Linear Eval × (Linear, Hyperbolic)
      └─ SSL Fine-tune × (Linear, Hyperbolic)
================================================================================

   ⚙️  Supervised 설정:
   - Epochs: 50
   - Batch size: 128
   - Learning rate: 0.0003
   - Training: End-to-end with labels

   ⚙️  SSL 설정:
   - Stage 1 (Pretrain): 100 epochs, batch=256, lr=0.001
     → Contrastive learning only (NO LABELS)
     → Label-independent augmentation
   - Stage 2 (Eval/FT): 50 epochs, batch=128, lr=0.0003
     → Linear Eval: Freeze backbone
     → Fine-tune: Train all

   🔧 Augmentations (SSL):
   - Jitter (scale=0.05)
   - Scaling (range=(0.8, 1.2))
   - Channel Drop (prob=0.2)
   - Time Warp (prob=0.3)
   - Cutout (prob=0.3, ratio=0.2)
   - ALL label-independent!

   🏗️  Architecture:
   - Backbone: ResNet(layers=[2,2,2]) + Transformer(heads=4, layers=2)
   - d_model: 128, dropout: 0.1
   - Classifier: Linear vs Hyperbolic (c=1.0)
   - Projection dim (SSL): 128

   🔬 SSL Contrastive Learning:
   - Loss: NT-Xent (InfoNCE)
   - Temperature: 0.07
   - Negative samples: 2*batch_size - 2
================================================================================


📦 Loading UCI-HAR Dataset...
[OK] train: X(7352, 9, 128), y(7352,)
[OK] test: X(2947, 9, 128), y(2947,)
   - Train samples: 7352
   - Test samples: 2947

================================================================================
    🔬 TRANSITIONAL TEST SETS 생성
================================================================================
   - STANDING↔SITTING (p=0.60, mix=0.50): 613개 샘플 변형
   - STANDING↔SITTING (p=0.70, mix=0.55): 715개 샘플 변형
   - WALKING↔WALKING_UPSTAIRS (p=0.65, mix=0.52): 628개 샘플 변형
   - SITTING↔LAYING (p=0.75, mix=0.58): 770개 샘플 변형

================================================================================
   실험: Supervised_Linear
================================================================================

📚 Supervised Learning (With Labels)
--------------------------------------------------------------------------------
Training for 50 epochs...
[Supervised 01/50] Train L:0.5038 A:0.8893 | Test A:0.9308 F1:0.9305
[Supervised 10/50] Train L:0.3114 A:0.9635 | Test A:0.9196 F1:0.9200
[Supervised 20/50] Train L:0.3061 A:0.9655 | Test A:0.9216 F1:0.9215
[Supervised 30/50] Train L:0.2893 A:0.9754 | Test A:0.9423 F1:0.9421
[Supervised 40/50] Train L:0.2761 A:0.9837 | Test A:0.9444 F1:0.9456
[Supervised 50/50] Train L:0.2714 A:0.9878 | Test A:0.9430 F1:0.9426
✅ Best Test Acc: 0.9583

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.5029 (Drop=0.4554)
     - Scenario 2: Acc=0.4930 (Drop=0.4652)
     - Scenario 3: Acc=0.5202 (Drop=0.4381)
     - Scenario 4: Acc=0.5148 (Drop=0.4435)

================================================================================
   실험: Supervised_Hyperbolic
================================================================================

📚 Supervised Learning (With Labels)
--------------------------------------------------------------------------------
Training for 50 epochs...
[Supervised 01/50] Train L:1.4057 A:0.8456 | Test A:0.9355 F1:0.9366
[Supervised 10/50] Train L:0.5620 A:0.9561 | Test A:0.9274 F1:0.9297
[Supervised 20/50] Train L:0.3646 A:0.9672 | Test A:0.9192 F1:0.9205
[Supervised 30/50] Train L:0.3068 A:0.9767 | Test A:0.9281 F1:0.9299
[Supervised 40/50] Train L:0.2953 A:0.9773 | Test A:0.9352 F1:0.9367
[Supervised 50/50] Train L:0.2748 A:0.9856 | Test A:0.9437 F1:0.9435
✅ Best Test Acc: 0.9555

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.5931 (Drop=0.3624)
     - Scenario 2: Acc=0.5789 (Drop=0.3767)
     - Scenario 3: Acc=0.5942 (Drop=0.3614)
     - Scenario 4: Acc=0.6230 (Drop=0.3325)

================================================================================
   실험: SSL_LinearEval_Linear
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 4.1587
[Pretrain 010/100] SSL Loss: 1.4873
[Pretrain 020/100] SSL Loss: 1.2154
[Pretrain 030/100] SSL Loss: 0.9347
[Pretrain 040/100] SSL Loss: 0.8517
[Pretrain 050/100] SSL Loss: 0.8010
[Pretrain 060/100] SSL Loss: 0.7262
[Pretrain 070/100] SSL Loss: 0.7045
[Pretrain 080/100] SSL Loss: 0.6291
[Pretrain 090/100] SSL Loss: 0.5481
[Pretrain 100/100] SSL Loss: 0.5901
✅ Pretraining Complete!

📚 Stage 2: LINEAR_EVAL (With Labels)
--------------------------------------------------------------------------------
linear_eval for 50 epochs...
[linear_eval 01/50] Train L:1.6684 A:0.3119 | Test A:0.5962 F1:0.5916
[linear_eval 10/50] Train L:0.5436 A:0.9125 | Test A:0.9101 F1:0.9095
[linear_eval 20/50] Train L:0.4602 A:0.9308 | Test A:0.9121 F1:0.9119
[linear_eval 30/50] Train L:0.4378 A:0.9399 | Test A:0.9186 F1:0.9183
[linear_eval 40/50] Train L:0.4269 A:0.9431 | Test A:0.9196 F1:0.9193
[linear_eval 50/50] Train L:0.4197 A:0.9442 | Test A:0.9216 F1:0.9214
✅ Best Test Acc: 0.9223

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.4323 (Drop=0.4900)
     - Scenario 2: Acc=0.4354 (Drop=0.4869)
     - Scenario 3: Acc=0.4306 (Drop=0.4917)
     - Scenario 4: Acc=0.4099 (Drop=0.5124)

================================================================================
   실험: SSL_LinearEval_Hyperbolic
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 4.1587
[Pretrain 010/100] SSL Loss: 1.4873
[Pretrain 020/100] SSL Loss: 1.2154
[Pretrain 030/100] SSL Loss: 0.9347
[Pretrain 040/100] SSL Loss: 0.8517
[Pretrain 050/100] SSL Loss: 0.8010
[Pretrain 060/100] SSL Loss: 0.7262
[Pretrain 070/100] SSL Loss: 0.7045
[Pretrain 080/100] SSL Loss: 0.6291
[Pretrain 090/100] SSL Loss: 0.5481
[Pretrain 100/100] SSL Loss: 0.5901
✅ Pretraining Complete!

📚 Stage 2: LINEAR_EVAL (With Labels)
--------------------------------------------------------------------------------
linear_eval for 50 epochs...
[linear_eval 01/50] Train L:1.6625 A:0.5447 | Test A:0.8147 F1:0.8097
[linear_eval 10/50] Train L:0.6732 A:0.9328 | Test A:0.9128 F1:0.9124
[linear_eval 20/50] Train L:0.4411 A:0.9459 | Test A:0.9179 F1:0.9176
[linear_eval 30/50] Train L:0.3819 A:0.9512 | Test A:0.9243 F1:0.9242
[linear_eval 40/50] Train L:0.3615 A:0.9546 | Test A:0.9233 F1:0.9232
[linear_eval 50/50] Train L:0.3523 A:0.9573 | Test A:0.9226 F1:0.9227
✅ Best Test Acc: 0.9267

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.4907 (Drop=0.4360)
     - Scenario 2: Acc=0.4907 (Drop=0.4360)
     - Scenario 3: Acc=0.4791 (Drop=0.4476)
     - Scenario 4: Acc=0.4900 (Drop=0.4367)

================================================================================
   실험: SSL_FineTune_Linear
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 4.1587
[Pretrain 010/100] SSL Loss: 1.4873
[Pretrain 020/100] SSL Loss: 1.2154
[Pretrain 030/100] SSL Loss: 0.9347
[Pretrain 040/100] SSL Loss: 0.8517
[Pretrain 050/100] SSL Loss: 0.8010
[Pretrain 060/100] SSL Loss: 0.7262
[Pretrain 070/100] SSL Loss: 0.7045
[Pretrain 080/100] SSL Loss: 0.6291
[Pretrain 090/100] SSL Loss: 0.5481
[Pretrain 100/100] SSL Loss: 0.5901
✅ Pretraining Complete!

📚 Stage 2: FINETUNE (With Labels)
--------------------------------------------------------------------------------
finetune for 50 epochs...
[finetune 01/50] Train L:0.6259 A:0.8575 | Test A:0.9447 F1:0.9456
[finetune 10/50] Train L:0.2670 A:0.9887 | Test A:0.9732 F1:0.9732
[finetune 20/50] Train L:0.2516 A:0.9952 | Test A:0.9654 F1:0.9654
[finetune 30/50] Train L:0.2471 A:0.9973 | Test A:0.9678 F1:0.9675
[finetune 40/50] Train L:0.2458 A:0.9974 | Test A:0.9688 F1:0.9686
[finetune 50/50] Train L:0.2419 A:0.9993 | Test A:0.9705 F1:0.9703
✅ Best Test Acc: 0.9732

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.4547 (Drop=0.5185)
     - Scenario 2: Acc=0.4455 (Drop=0.5277)
     - Scenario 3: Acc=0.4842 (Drop=0.4890)
     - Scenario 4: Acc=0.4747 (Drop=0.4985)

================================================================================
   실험: SSL_FineTune_Hyperbolic
================================================================================

📚 Stage 1: Self-Supervised Pretraining (No Labels)
--------------------------------------------------------------------------------
Pretraining for 100 epochs...
[Pretrain 001/100] SSL Loss: 4.1587
[Pretrain 010/100] SSL Loss: 1.4873
[Pretrain 020/100] SSL Loss: 1.2154
[Pretrain 030/100] SSL Loss: 0.9347
[Pretrain 040/100] SSL Loss: 0.8517
[Pretrain 050/100] SSL Loss: 0.8010
[Pretrain 060/100] SSL Loss: 0.7262
[Pretrain 070/100] SSL Loss: 0.7045
[Pretrain 080/100] SSL Loss: 0.6291
[Pretrain 090/100] SSL Loss: 0.5481
[Pretrain 100/100] SSL Loss: 0.5901
✅ Pretraining Complete!

📚 Stage 2: FINETUNE (With Labels)
--------------------------------------------------------------------------------
finetune for 50 epochs...
[finetune 01/50] Train L:1.4537 A:0.8058 | Test A:0.9376 F1:0.9388
[finetune 10/50] Train L:0.5116 A:0.9871 | Test A:0.9708 F1:0.9711
[finetune 20/50] Train L:0.3055 A:0.9947 | Test A:0.9701 F1:0.9701
[finetune 30/50] Train L:0.2606 A:0.9966 | Test A:0.9722 F1:0.9721
[finetune 40/50] Train L:0.2474 A:0.9978 | Test A:0.9705 F1:0.9703
[finetune 50/50] Train L:0.2497 A:0.9961 | Test A:0.9732 F1:0.9731
✅ Best Test Acc: 0.9803

   🔍 전이 테스트셋 평가...
     - Scenario 1: Acc=0.4218 (Drop=0.5585)
     - Scenario 2: Acc=0.4099 (Drop=0.5704)
     - Scenario 3: Acc=0.4516 (Drop=0.5287)
     - Scenario 4: Acc=0.4333 (Drop=0.5470)

================================================================================
   📊 SUPERVISED vs TRUE SSL 실험 결과
================================================================================
Config                              Method       Mode         Classifier   Orig Acc   Trans Acc   Drop       Retention 
-------------------------------------------------------------------------------------------------------------------
Supervised_Linear                   supervised   supervised   Linear       0.9583     0.5077      0.4505   52.98%
Supervised_Hyperbolic               supervised   supervised   Hyperbolic   0.9555     0.5973      0.3582   62.51%
SSL_LinearEval_Linear               ssl          linear_eval  Linear       0.9223     0.4270      0.4952   46.30%
SSL_LinearEval_Hyperbolic           ssl          linear_eval  Hyperbolic   0.9267     0.4876      0.4391   52.62%
SSL_FineTune_Linear                 ssl          finetune     Linear       0.9732     0.4648      0.5084   47.76%
SSL_FineTune_Hyperbolic             ssl          finetune     Hyperbolic   0.9803     0.4292      0.5512   43.78%

================================================================================
📊 상세 비교 분석
================================================================================

🏆 최종 성능 랭킹 (Retention 기준)
--------------------------------------------------------------------------------
   1. Supervised_Hyperbolic               (supervised          ) Retention: 62.51%
   2. Supervised_Linear                   (supervised          ) Retention: 52.98%
   3. SSL_LinearEval_Hyperbolic           (ssl-linear_eval     ) Retention: 52.62%
   4. SSL_FineTune_Linear                 (ssl-finetune        ) Retention: 47.76%
   5. SSL_LinearEval_Linear               (ssl-linear_eval     ) Retention: 46.30%
   6. SSL_FineTune_Hyperbolic             (ssl-finetune        ) Retention: 43.78%

================================================================================
🎯 결론
================================================================================
   - 최고 성능: Supervised_Hyperbolic (Retention: 62.51%)
   - Supervised baseline: 62.51%
   - SSL best: 52.62%
   - Performance gap: 9.89pp